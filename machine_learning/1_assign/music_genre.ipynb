{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcb0642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:01.238455Z",
     "iopub.status.busy": "2024-01-11T05:45:01.237988Z",
     "iopub.status.idle": "2024-01-11T05:45:22.452939Z",
     "shell.execute_reply": "2024-01-11T05:45:22.451641Z"
    },
    "papermill": {
     "duration": 21.228331,
     "end_time": "2024-01-11T05:45:22.456076",
     "exception": false,
     "start_time": "2024-01-11T05:45:01.227745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 1 - music genre classification\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import pdb\n",
    "sys.path.append(\"C:\\\\users\\\\mccar\\\\miniconda3\\\\lib\\\\site-packages\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import validation_curve, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from utils import learn_curve, val_curve\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1deffdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:22.476225Z",
     "iopub.status.busy": "2024-01-11T05:45:22.475656Z",
     "iopub.status.idle": "2024-01-11T05:45:23.739387Z",
     "shell.execute_reply": "2024-01-11T05:45:23.736447Z"
    },
    "papermill": {
     "duration": 1.277192,
     "end_time": "2024-01-11T05:45:23.742359",
     "exception": false,
     "start_time": "2024-01-11T05:45:22.465167",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features_30_sec.csv']\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "file_path = \"data/gtzan_music_genre/\"\n",
    "print(os.listdir(f'{file_path}/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3bcf8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:23.769832Z",
     "iopub.status.busy": "2024-01-11T05:45:23.769185Z",
     "iopub.status.idle": "2024-01-11T05:45:38.438753Z",
     "shell.execute_reply": "2024-01-11T05:45:38.437541Z"
    },
    "papermill": {
     "duration": 14.686168,
     "end_time": "2024-01-11T05:45:38.441264",
     "exception": false,
     "start_time": "2024-01-11T05:45:23.755096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sound, sample_rate = librosa.load(f'{file_path}/genres_original/classical/classical.00005.wav')\n",
    "# print(sound[:5])\n",
    "# print(sample_rate)\n",
    "\n",
    "# plt.figure(figsize=(16, 6))\n",
    "# librosa.display.waveshow(y=sound, sr=sample_rate, color=\"darkred\")\n",
    "# plt.title(\"Waveform of classical.00005.wav\", fontsize=12)  \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aed6c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:38.472531Z",
     "iopub.status.busy": "2024-01-11T05:45:38.471893Z",
     "iopub.status.idle": "2024-01-11T05:45:39.554517Z",
     "shell.execute_reply": "2024-01-11T05:45:39.553259Z"
    },
    "papermill": {
     "duration": 1.10268,
     "end_time": "2024-01-11T05:45:39.557909",
     "exception": false,
     "start_time": "2024-01-11T05:45:38.455229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sound_rock, sample_rate_rock = librosa.load(f'{file_path}/genres_original/rock/rock.00017.wav')\n",
    "# print(sound_rock[:5])\n",
    "# print(sample_rate_rock)\n",
    "\n",
    "# plt.figure(figsize = (16,6))\n",
    "# librosa.display.waveshow(y = sound_rock, sr = sample_rate_rock, color = 'darkred')\n",
    "# plt.title('Wavefrom of rock.00017.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b1b9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.592249Z",
     "iopub.status.busy": "2024-01-11T05:45:39.591810Z",
     "iopub.status.idle": "2024-01-11T05:45:39.657703Z",
     "shell.execute_reply": "2024-01-11T05:45:39.655729Z"
    },
    "papermill": {
     "duration": 0.086344,
     "end_time": "2024-01-11T05:45:39.660995",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.574651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_fft = 2048 # FFT window size\n",
    "# hop_length = 512 # number audio of frames between STFT columns (looks like a good default)\n",
    "\n",
    "# # Short-time Fourier transform (STFT)\n",
    "# D = np.abs(librosa.stft(sound_rock, n_fft = n_fft, hop_length = hop_length))\n",
    "\n",
    "# print('Shape of D object:', np.shape(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e617f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.695494Z",
     "iopub.status.busy": "2024-01-11T05:45:39.695066Z",
     "iopub.status.idle": "2024-01-11T05:45:39.796498Z",
     "shell.execute_reply": "2024-01-11T05:45:39.795102Z"
    },
    "papermill": {
     "duration": 0.121206,
     "end_time": "2024-01-11T05:45:39.799409",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.678203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 60)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 60 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   filename                 1000 non-null   object \n",
      " 1   length                   1000 non-null   int64  \n",
      " 2   chroma_stft_mean         1000 non-null   float64\n",
      " 3   chroma_stft_var          1000 non-null   float64\n",
      " 4   rms_mean                 1000 non-null   float64\n",
      " 5   rms_var                  1000 non-null   float64\n",
      " 6   spectral_centroid_mean   1000 non-null   float64\n",
      " 7   spectral_centroid_var    1000 non-null   float64\n",
      " 8   spectral_bandwidth_mean  1000 non-null   float64\n",
      " 9   spectral_bandwidth_var   1000 non-null   float64\n",
      " 10  rolloff_mean             1000 non-null   float64\n",
      " 11  rolloff_var              1000 non-null   float64\n",
      " 12  zero_crossing_rate_mean  1000 non-null   float64\n",
      " 13  zero_crossing_rate_var   1000 non-null   float64\n",
      " 14  harmony_mean             1000 non-null   float64\n",
      " 15  harmony_var              1000 non-null   float64\n",
      " 16  perceptr_mean            1000 non-null   float64\n",
      " 17  perceptr_var             1000 non-null   float64\n",
      " 18  tempo                    1000 non-null   float64\n",
      " 19  mfcc1_mean               1000 non-null   float64\n",
      " 20  mfcc1_var                1000 non-null   float64\n",
      " 21  mfcc2_mean               1000 non-null   float64\n",
      " 22  mfcc2_var                1000 non-null   float64\n",
      " 23  mfcc3_mean               1000 non-null   float64\n",
      " 24  mfcc3_var                1000 non-null   float64\n",
      " 25  mfcc4_mean               1000 non-null   float64\n",
      " 26  mfcc4_var                1000 non-null   float64\n",
      " 27  mfcc5_mean               1000 non-null   float64\n",
      " 28  mfcc5_var                1000 non-null   float64\n",
      " 29  mfcc6_mean               1000 non-null   float64\n",
      " 30  mfcc6_var                1000 non-null   float64\n",
      " 31  mfcc7_mean               1000 non-null   float64\n",
      " 32  mfcc7_var                1000 non-null   float64\n",
      " 33  mfcc8_mean               1000 non-null   float64\n",
      " 34  mfcc8_var                1000 non-null   float64\n",
      " 35  mfcc9_mean               1000 non-null   float64\n",
      " 36  mfcc9_var                1000 non-null   float64\n",
      " 37  mfcc10_mean              1000 non-null   float64\n",
      " 38  mfcc10_var               1000 non-null   float64\n",
      " 39  mfcc11_mean              1000 non-null   float64\n",
      " 40  mfcc11_var               1000 non-null   float64\n",
      " 41  mfcc12_mean              1000 non-null   float64\n",
      " 42  mfcc12_var               1000 non-null   float64\n",
      " 43  mfcc13_mean              1000 non-null   float64\n",
      " 44  mfcc13_var               1000 non-null   float64\n",
      " 45  mfcc14_mean              1000 non-null   float64\n",
      " 46  mfcc14_var               1000 non-null   float64\n",
      " 47  mfcc15_mean              1000 non-null   float64\n",
      " 48  mfcc15_var               1000 non-null   float64\n",
      " 49  mfcc16_mean              1000 non-null   float64\n",
      " 50  mfcc16_var               1000 non-null   float64\n",
      " 51  mfcc17_mean              1000 non-null   float64\n",
      " 52  mfcc17_var               1000 non-null   float64\n",
      " 53  mfcc18_mean              1000 non-null   float64\n",
      " 54  mfcc18_var               1000 non-null   float64\n",
      " 55  mfcc19_mean              1000 non-null   float64\n",
      " 56  mfcc19_var               1000 non-null   float64\n",
      " 57  mfcc20_mean              1000 non-null   float64\n",
      " 58  mfcc20_var               1000 non-null   float64\n",
      " 59  label                    1000 non-null   object \n",
      "dtypes: float64(57), int64(1), object(2)\n",
      "memory usage: 468.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('display.max_columns', 60)\n",
    "train_df = pd.read_csv(f'{file_path}/features_30_sec.csv')\n",
    "train_df.head()\n",
    "print(train_df.shape)\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ebfd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.833663Z",
     "iopub.status.busy": "2024-01-11T05:45:39.832566Z",
     "iopub.status.idle": "2024-01-11T05:45:40.641774Z",
     "shell.execute_reply": "2024-01-11T05:45:40.640665Z"
    },
    "papermill": {
     "duration": 0.829401,
     "end_time": "2024-01-11T05:45:40.644815",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.815414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# label_tempo_df= train_df[['label', 'tempo']]\n",
    "\n",
    "# f, ax = plt.subplots(figsize = (16,9))\n",
    "# sns.boxplot(x = 'label', y = 'tempo', data = label_tempo_df, palette = 'rocket' )\n",
    "\n",
    "# plt.title('BPM Boxplot for Genres', fontsize = 15)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.xlabel('Genre', fontsize = 20)\n",
    "# plt.ylabel('BPM', fontsize = 20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7497a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "train_df = train_df.drop(['filename', 'length'], axis = 1)\n",
    "y = train_df['label']\n",
    "X = train_df.drop('label', axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82a823f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:40.680821Z",
     "iopub.status.busy": "2024-01-11T05:45:40.680116Z",
     "iopub.status.idle": "2024-01-11T05:45:41.294675Z",
     "shell.execute_reply": "2024-01-11T05:45:41.292817Z"
    },
    "papermill": {
     "duration": 0.640956,
     "end_time": "2024-01-11T05:45:41.302621",
     "exception": false,
     "start_time": "2024-01-11T05:45:40.661665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cols = X.columns\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# np_scaled = min_max_scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(np_scaled, columns = cols)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components = 2)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "# finalDf = pd.concat([principalDf, y], axis = 1)\n",
    "# print('variance ratio : ', pca.explained_variance_ratio_)\n",
    "# print('sum : ', sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341d4d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:41.411559Z",
     "iopub.status.busy": "2024-01-11T05:45:41.411130Z",
     "iopub.status.idle": "2024-01-11T05:45:41.744452Z",
     "shell.execute_reply": "2024-01-11T05:45:41.743084Z"
    },
    "papermill": {
     "duration": 0.382564,
     "end_time": "2024-01-11T05:45:41.747565",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.365001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pca = PCA(whiten = True).fit(X)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d078f89",
   "metadata": {
    "papermill": {
     "duration": 0.016425,
     "end_time": "2024-01-11T05:45:41.780771",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.764346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1efdb122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:41.816931Z",
     "iopub.status.busy": "2024-01-11T05:45:41.815973Z",
     "iopub.status.idle": "2024-01-11T05:45:42.199666Z",
     "shell.execute_reply": "2024-01-11T05:45:42.198158Z"
    },
    "papermill": {
     "duration": 0.405254,
     "end_time": "2024-01-11T05:45:42.202781",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.797527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e63aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:42.240883Z",
     "iopub.status.busy": "2024-01-11T05:45:42.240160Z",
     "iopub.status.idle": "2024-01-11T05:45:42.716199Z",
     "shell.execute_reply": "2024-01-11T05:45:42.715014Z"
    },
    "papermill": {
     "duration": 0.498045,
     "end_time": "2024-01-11T05:45:42.718870",
     "exception": false,
     "start_time": "2024-01-11T05:45:42.220825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba895e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:42.756639Z",
     "iopub.status.busy": "2024-01-11T05:45:42.756172Z",
     "iopub.status.idle": "2024-01-11T05:45:42.776635Z",
     "shell.execute_reply": "2024-01-11T05:45:42.775324Z"
    },
    "papermill": {
     "duration": 0.042967,
     "end_time": "2024-01-11T05:45:42.779761",
     "exception": false,
     "start_time": "2024-01-11T05:45:42.736794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# More preprocessing\n",
    "scale = MinMaxScaler()\n",
    "scaled_data = scale.fit_transform(x_train)\n",
    "x_train_sc = pd.DataFrame(scaled_data, columns = x_train.columns).values\n",
    "scaled_data = scale.fit_transform(x_test)\n",
    "x_test_sc = pd.DataFrame(scaled_data, columns = x_test.columns).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e16493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "# Curve based on value of K - Validation curve\n",
    "val_knn = False\n",
    "if val_knn:\n",
    "    k_accs = {}\n",
    "    for k_val in range(1,24):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "        knn.fit(x_train_sc, y_train)\n",
    "        y_pred = knn.predict(x_test_sc)\n",
    "        k_accs[k_val] = accuracy_score(y_test, y_pred)\n",
    "        print(\"K val: {}   acc: {}\".format(k_val, k_accs[k_val]))\n",
    "    val_curve(list(k_accs.keys()), list(k_accs.values()), \"knn_music\", \"value for K\")\n",
    "\n",
    "learn_knn = False\n",
    "if learn_knn:\n",
    "    # Shuffle the data without replacement - Learning curve\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        # shuffled_data = shuffle(x_train, random_state=RANDOM_SEED)\n",
    "        x_percent_index = int(x_perc * len(x_train_sc))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "        knn = KNeighborsClassifier(n_neighbors=7)\n",
    "        knn.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = knn.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = knn.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"K val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"knn_music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9404c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - hyperparameter tuning - Validation curve\n",
    "dt_max_depth = False\n",
    "\n",
    "if dt_max_depth:\n",
    "    # Max Depth\n",
    "    # Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "    param_range = np.arange(1, 31)\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train, y_train, param_name=\"max_depth\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Max Depth\")\n",
    "    plt.xlabel(\"Max Depth\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_max_depth_music.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "058beef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min samples to split\n",
    "# Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "dt_min_split = False\n",
    "\n",
    "if dt_min_split:\n",
    "    param_range = np.arange(0, 15)\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train_sc, y_train, param_name=\"min_samples_split\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    print(test_scores_mean)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Min Samples Split\")\n",
    "    plt.xlabel(\"Min Samples Split\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_min_samples_split_music.png\", dpi=300)\n",
    "    # plt.savefig(\"pngs/validation_curve_dt_min_samples_leaf.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c30b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion\n",
    "crit = False\n",
    "\n",
    "if crit:\n",
    "    # Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "    param_range = ['gini', 'entropy']\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=13)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train, y_train, param_name=\"criterion\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    print(test_scores_mean)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Criterion\")\n",
    "    plt.xlabel(\"Criterion\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.xticks(['gini', 'entropy'])\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_criterion_music.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "493883e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - Amount of data - Learning curve\n",
    "l_curve = False\n",
    "\n",
    "if l_curve:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        print(x_perc)\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "        dec_tree = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "        dec_tree.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = dec_tree.predict(x_test)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = dec_tree.predict(x_train)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"dec_tree_music\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1bdcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - epochs - Learning curve\n",
    "dt_epoch = False\n",
    "\n",
    "if dt_epoch:\n",
    "    # Number of epochs\n",
    "    epochs = 5\n",
    "\n",
    "    # Initialize the decision tree classifier\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    # Loop through epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "\n",
    "        # Train the decision tree on the training set\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        x_accs[epoch+1] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = dec_tree.predict(x_train)\n",
    "        train_accs[epoch+1] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(epoch+1, x_accs[epoch+1]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"dec_tree_epochs_music\", x_axis=\"Epochs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f82d2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Tree - Hyperparameter tuning - Validation curve\n",
    "boost_gscv = False\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "if boost_gscv:\n",
    "    # Create XGBoost classifier\n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    # Define hyperparameters to tune\n",
    "    param_grid = {\n",
    "        'n_estimators': [15, 50, 150, 200, 250],\n",
    "        'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "        'min_child_weight': [1, 5, 10, 15],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200],\n",
    "        'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "        'min_child_weight': [1, 5, 10, 15],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_classifier,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search.fit(x_train_sc, y_encoded)\n",
    "\n",
    "    # Display the best hyperparameters and corresponding accuracy\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    print(grid_search.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02457455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting tree - Validation curve - max depth\n",
    "bt_md = False\n",
    "\n",
    "if bt_md:\n",
    "    xgb_classifier = XGBClassifier(learning_rate=0.3, min_child_weight=1, max_depth = 7, subsample=0.9, colsample_bytree=1.0)\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": [10, 50, 100, 150, 200, 250]\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_classifier,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search.fit(x_train_sc, y_encoded)\n",
    "\n",
    "    # Display the best hyperparameters and corresponding accuracy\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    param_range = [10, 50, 100, 150, 200, 250]\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    # train_scores_mean = grid_search.cv_results_['mean_train_score']\n",
    "    # train_scores_std = grid_search.cv_results_['std_train_score']\n",
    "    test_scores_mean = grid_search.cv_results_['mean_test_score']\n",
    "    test_scores_std = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Boosting Tree - N Estimators\")\n",
    "    plt.xlabel(\"N Estimators\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    # plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # # Fill the area around the mean training scores\n",
    "    # plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "    #                 train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_bt_n_estimators_music.png\", dpi=300)\n",
    "    # plt.savefig(\"pngs/validation_curve_dt_min_samples_leaf.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b710809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BT - Learning Curve - amount of data\n",
    "bt_lc = False\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "if bt_lc:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_encoded[:x_percent_index]\n",
    "        xgb_classifier = XGBClassifier(n_estimators=200, learning_rate=0.3, max_depth=7,\n",
    "                                       min_child_weight=1, subsample=0.9, colsample_bytree=1.0)\n",
    "        xgb_classifier.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = xgb_classifier.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test_encoded, y_pred)\n",
    "        y_pred_train = xgb_classifier.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_encoded, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"boost_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf6b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Validation curve - C / kernel func\n",
    "hyper = False\n",
    "\n",
    "\n",
    "if hyper:\n",
    "    # Run through the kernel functions and get validation curves for each hyperparameter\n",
    "    for kern_func in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "\n",
    "        x_perc = 1.0\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "\n",
    "        # Define the hyperparameter values to be tested\n",
    "        param_range = np.logspace(-2, 6, 9)\n",
    "        svm_model = SVC(kernel=kern_func)\n",
    "\n",
    "        # Create a validation curve\n",
    "        train_scores, test_scores = validation_curve(\n",
    "            svm_model, first_x_percent, y_train_iter, param_name=\"C\", param_range=param_range,\n",
    "            cv=3, scoring=\"accuracy\", n_jobs=-1\n",
    "        )\n",
    "        # Plot the validation curves\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Validation Curve for SVM - {}\".format(kern_func))\n",
    "        plt.xlabel(\"C Parameter\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=2)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\", lw=2)\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.savefig(\"pngs/validation_curve_svm_{}_music.png\".format(kern_func), dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0542d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Learning Curve - amount of data\n",
    "svm_lc = False\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "if svm_lc:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_encoded[:x_percent_index]\n",
    "        svm_model = SVC(kernel=\"rbf\", C=100)\n",
    "        svm_model.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = svm_model.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test_encoded, y_pred)\n",
    "        y_pred_train = svm_model.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_encoded, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f82e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN - hyperparameter tuning - GridSearchCV\n",
    "nn_hyper = False\n",
    "\n",
    "if nn_hyper:\n",
    "    # Define a function to create the Keras model\n",
    "    def create_model(optimizer='adam', activation='relu', neurons=16):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=x_train_sc.shape[1], activation=activation))\n",
    "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # Wrap Keras model into a function for compatibility with GridSearchCV\n",
    "    keras_model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "        'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "        'neurons': [8, 16, 32]\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=3, \n",
    "                        scoring='accuracy', verbose=9, n_jobs=-1)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    grid_result = grid.fit(x_train_sc, y_train, callbacks=[EarlyStopping(monitor='val_loss', patience=2)])\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "    # Evaluate the model on the test set with the best hyperparameters\n",
    "    best_model = grid_result.best_estimator_\n",
    "    test_accuracy = best_model.score(x_test_sc, y_test)\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4442e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.1875 - loss: 2.3345Test Accuracy after Epoch 1: 18.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1493 - loss: 2.2995 - val_accuracy: 0.1750 - val_loss: 2.2628\n",
      "Epoch 2/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1562 - loss: 2.2563Test Accuracy after Epoch 2: 20.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1508 - loss: 2.2494 - val_accuracy: 0.2125 - val_loss: 2.2087\n",
      "Epoch 3/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1875 - loss: 2.1555Test Accuracy after Epoch 3: 25.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1930 - loss: 2.1687 - val_accuracy: 0.2125 - val_loss: 2.1243\n",
      "Epoch 4/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1250 - loss: 2.1216Test Accuracy after Epoch 4: 17.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1761 - loss: 2.1054 - val_accuracy: 0.2500 - val_loss: 2.0530\n",
      "Epoch 5/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1250 - loss: 2.0187Test Accuracy after Epoch 5: 20.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2062 - loss: 1.9995 - val_accuracy: 0.2500 - val_loss: 2.0122\n",
      "Epoch 6/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2188 - loss: 1.9119Test Accuracy after Epoch 6: 19.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2547 - loss: 1.9163 - val_accuracy: 0.2500 - val_loss: 1.9402\n",
      "Epoch 7/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2188 - loss: 1.8778Test Accuracy after Epoch 7: 18.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2419 - loss: 1.8963 - val_accuracy: 0.1875 - val_loss: 1.9275\n",
      "Epoch 8/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2188 - loss: 1.9466Test Accuracy after Epoch 8: 18.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2720 - loss: 1.8218 - val_accuracy: 0.2250 - val_loss: 1.8513\n",
      "Epoch 9/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2188 - loss: 1.8833Test Accuracy after Epoch 9: 22.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3041 - loss: 1.7501 - val_accuracy: 0.2750 - val_loss: 1.7670\n",
      "Epoch 10/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3125 - loss: 1.6586Test Accuracy after Epoch 10: 22.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3384 - loss: 1.6518 - val_accuracy: 0.2750 - val_loss: 1.7612\n",
      "Epoch 11/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2500 - loss: 1.7792Test Accuracy after Epoch 11: 29.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3388 - loss: 1.6429 - val_accuracy: 0.3875 - val_loss: 1.7153\n",
      "Epoch 12/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4688 - loss: 1.4960Test Accuracy after Epoch 12: 33.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4181 - loss: 1.5867 - val_accuracy: 0.4875 - val_loss: 1.6597\n",
      "Epoch 13/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 1.2394Test Accuracy after Epoch 13: 33.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5291 - loss: 1.4693 - val_accuracy: 0.4625 - val_loss: 1.5873\n",
      "Epoch 14/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 1.5227Test Accuracy after Epoch 14: 35.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4861 - loss: 1.4907 - val_accuracy: 0.4000 - val_loss: 1.5226\n",
      "Epoch 15/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4375 - loss: 1.4607Test Accuracy after Epoch 15: 36.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 1.3821 - val_accuracy: 0.5125 - val_loss: 1.4179\n",
      "Epoch 16/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5317 - loss: 1.2332 Test Accuracy after Epoch 16: 39.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5300 - loss: 1.2412 - val_accuracy: 0.6000 - val_loss: 1.4072\n",
      "Epoch 17/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5938 - loss: 1.2769Test Accuracy after Epoch 17: 39.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5866 - loss: 1.2026 - val_accuracy: 0.5250 - val_loss: 1.3332\n",
      "Epoch 18/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 1.2071Test Accuracy after Epoch 18: 41.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6229 - loss: 1.1330 - val_accuracy: 0.5000 - val_loss: 1.3644\n",
      "Epoch 19/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 0.9168Test Accuracy after Epoch 19: 45.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6070 - loss: 1.1013 - val_accuracy: 0.5625 - val_loss: 1.2956\n",
      "Epoch 20/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 1.2655Test Accuracy after Epoch 20: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6052 - loss: 1.1289 - val_accuracy: 0.5875 - val_loss: 1.2427\n",
      "Epoch 21/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5312 - loss: 1.1915Test Accuracy after Epoch 21: 47.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6484 - loss: 1.0446 - val_accuracy: 0.6000 - val_loss: 1.4110\n",
      "Epoch 22/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 0.9746Test Accuracy after Epoch 22: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6198 - loss: 1.0587 - val_accuracy: 0.6000 - val_loss: 1.3092\n",
      "Epoch 23/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5312 - loss: 1.4558Test Accuracy after Epoch 23: 46.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6344 - loss: 1.0732 - val_accuracy: 0.6000 - val_loss: 1.1948\n",
      "Epoch 24/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5625 - loss: 0.9494Test Accuracy after Epoch 24: 49.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6638 - loss: 0.9605 - val_accuracy: 0.6125 - val_loss: 1.1604\n",
      "Epoch 25/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7812 - loss: 1.0521Test Accuracy after Epoch 25: 49.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6685 - loss: 0.9876 - val_accuracy: 0.5875 - val_loss: 1.1290\n",
      "Epoch 26/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 1.0088Test Accuracy after Epoch 26: 48.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6441 - loss: 1.0283 - val_accuracy: 0.6000 - val_loss: 1.1577\n",
      "Epoch 27/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6875 - loss: 1.0232Test Accuracy after Epoch 27: 45.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6850 - loss: 0.9281 - val_accuracy: 0.6375 - val_loss: 1.0899\n",
      "Epoch 28/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8438 - loss: 0.5803Test Accuracy after Epoch 28: 49.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6963 - loss: 0.8493 - val_accuracy: 0.5625 - val_loss: 1.3823\n",
      "Epoch 29/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.9071Test Accuracy after Epoch 29: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6743 - loss: 0.9123 - val_accuracy: 0.6000 - val_loss: 1.1290\n",
      "Epoch 30/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.8930Test Accuracy after Epoch 30: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7183 - loss: 0.8556 - val_accuracy: 0.6125 - val_loss: 1.2090\n",
      "Epoch 31/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6250 - loss: 1.0986Test Accuracy after Epoch 31: 49.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7024 - loss: 0.8586 - val_accuracy: 0.6125 - val_loss: 1.0646\n",
      "Epoch 32/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6250 - loss: 0.9882Test Accuracy after Epoch 32: 46.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6884 - loss: 0.8983 - val_accuracy: 0.6250 - val_loss: 1.0711\n",
      "Epoch 33/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7188 - loss: 1.0507Test Accuracy after Epoch 33: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7285 - loss: 0.8541 - val_accuracy: 0.6000 - val_loss: 1.1175\n",
      "Epoch 34/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6875 - loss: 0.6796Test Accuracy after Epoch 34: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6848 - loss: 0.8233 - val_accuracy: 0.6375 - val_loss: 1.0117\n",
      "Epoch 35/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5312 - loss: 1.3898Test Accuracy after Epoch 35: 50.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6861 - loss: 0.9037 - val_accuracy: 0.6375 - val_loss: 1.0435\n",
      "Epoch 36/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.7611Test Accuracy after Epoch 36: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7123 - loss: 0.7960 - val_accuracy: 0.6625 - val_loss: 1.0363\n",
      "Epoch 37/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6410Test Accuracy after Epoch 37: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6985 - loss: 0.8013 - val_accuracy: 0.6125 - val_loss: 1.0363\n",
      "Epoch 38/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7188 - loss: 0.6899Test Accuracy after Epoch 38: 47.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7220 - loss: 0.8067 - val_accuracy: 0.6375 - val_loss: 0.9911\n",
      "Epoch 39/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7188 - loss: 1.0098Test Accuracy after Epoch 39: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7135 - loss: 0.8041 - val_accuracy: 0.6125 - val_loss: 1.1018\n",
      "Epoch 40/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 0.7636Test Accuracy after Epoch 40: 48.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.7938 - val_accuracy: 0.6750 - val_loss: 1.0029\n",
      "Epoch 41/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8750 - loss: 0.4967Test Accuracy after Epoch 41: 49.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - loss: 0.6830 - val_accuracy: 0.6750 - val_loss: 1.0112\n",
      "Epoch 42/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.5298Test Accuracy after Epoch 42: 49.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.7133 - val_accuracy: 0.7000 - val_loss: 1.0287\n",
      "Epoch 43/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.5710Test Accuracy after Epoch 43: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7512 - loss: 0.7135 - val_accuracy: 0.5750 - val_loss: 1.1127\n",
      "Epoch 44/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5312 - loss: 0.9755Test Accuracy after Epoch 44: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7148 - loss: 0.7455 - val_accuracy: 0.6375 - val_loss: 1.0013\n",
      "Epoch 45/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.5997Test Accuracy after Epoch 45: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7373 - loss: 0.6710 - val_accuracy: 0.6625 - val_loss: 1.1280\n",
      "Epoch 46/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.7000Test Accuracy after Epoch 46: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7617 - loss: 0.6970 - val_accuracy: 0.6625 - val_loss: 1.0259\n",
      "Epoch 47/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 0.7041Test Accuracy after Epoch 47: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6692 - val_accuracy: 0.7125 - val_loss: 1.1044\n",
      "Epoch 48/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6250 - loss: 0.8024Test Accuracy after Epoch 48: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7432 - loss: 0.6900 - val_accuracy: 0.6000 - val_loss: 1.0134\n",
      "Epoch 49/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.5314Test Accuracy after Epoch 49: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7563 - loss: 0.6849 - val_accuracy: 0.6500 - val_loss: 0.9736\n",
      "Epoch 50/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.5697Test Accuracy after Epoch 50: 50.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7483 - loss: 0.6978 - val_accuracy: 0.6625 - val_loss: 1.0697\n",
      "Epoch 51/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5938 - loss: 1.2771Test Accuracy after Epoch 51: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7265 - loss: 0.7843 - val_accuracy: 0.6625 - val_loss: 1.0571\n",
      "Epoch 52/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.6064Test Accuracy after Epoch 52: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7608 - loss: 0.6919 - val_accuracy: 0.6000 - val_loss: 1.0500\n",
      "Epoch 53/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 0.8303Test Accuracy after Epoch 53: 51.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7473 - loss: 0.7057 - val_accuracy: 0.6875 - val_loss: 1.0647\n",
      "Epoch 54/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.4697Test Accuracy after Epoch 54: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7751 - loss: 0.6170 - val_accuracy: 0.6375 - val_loss: 1.0465\n",
      "Epoch 55/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9062 - loss: 0.3892Test Accuracy after Epoch 55: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.5839 - val_accuracy: 0.6250 - val_loss: 1.2148\n",
      "Epoch 56/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.6341Test Accuracy after Epoch 56: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7276 - loss: 0.6936 - val_accuracy: 0.6875 - val_loss: 0.9950\n",
      "Epoch 57/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7188 - loss: 0.5880Test Accuracy after Epoch 57: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 0.5992 - val_accuracy: 0.6750 - val_loss: 0.9545\n",
      "Epoch 58/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5938 - loss: 1.0412Test Accuracy after Epoch 58: 50.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7842 - loss: 0.6181 - val_accuracy: 0.7000 - val_loss: 0.9666\n",
      "Epoch 59/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.4035Test Accuracy after Epoch 59: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7938 - loss: 0.5772 - val_accuracy: 0.7000 - val_loss: 0.9864\n",
      "Epoch 60/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.4962Test Accuracy after Epoch 60: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7960 - loss: 0.6028 - val_accuracy: 0.6500 - val_loss: 1.0993\n",
      "Epoch 61/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7812 - loss: 0.5113Test Accuracy after Epoch 61: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.5823 - val_accuracy: 0.6250 - val_loss: 1.0300\n",
      "Epoch 62/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.4671Test Accuracy after Epoch 62: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7940 - loss: 0.5689 - val_accuracy: 0.6500 - val_loss: 1.1171\n",
      "Epoch 63/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.4944Test Accuracy after Epoch 63: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.5746 - val_accuracy: 0.6000 - val_loss: 1.1406\n",
      "Epoch 64/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.3806Test Accuracy after Epoch 64: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8369 - loss: 0.5263 - val_accuracy: 0.6500 - val_loss: 1.0965\n",
      "Epoch 65/250\n",
      "\u001b[1m11/23\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8294 - loss: 0.4905 Test Accuracy after Epoch 65: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8291 - loss: 0.5081 - val_accuracy: 0.6875 - val_loss: 1.1295\n",
      "Epoch 66/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.4637Test Accuracy after Epoch 66: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8058 - loss: 0.5288 - val_accuracy: 0.6500 - val_loss: 1.0257\n",
      "Epoch 67/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.4134Test Accuracy after Epoch 67: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.5319 - val_accuracy: 0.6500 - val_loss: 1.0130\n",
      "Epoch 68/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.6426Test Accuracy after Epoch 68: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8310 - loss: 0.5125 - val_accuracy: 0.6750 - val_loss: 0.9875\n",
      "Epoch 69/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.2749Test Accuracy after Epoch 69: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8563 - loss: 0.4452 - val_accuracy: 0.6750 - val_loss: 1.0613\n",
      "Epoch 70/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.3587Test Accuracy after Epoch 70: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8259 - loss: 0.4565 - val_accuracy: 0.6625 - val_loss: 1.0275\n",
      "Epoch 71/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.3751Test Accuracy after Epoch 71: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8316 - loss: 0.4875 - val_accuracy: 0.6125 - val_loss: 1.1188\n",
      "Epoch 72/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7812 - loss: 0.5539Test Accuracy after Epoch 72: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8326 - loss: 0.4812 - val_accuracy: 0.6250 - val_loss: 1.1441\n",
      "Epoch 73/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.3485Test Accuracy after Epoch 73: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.4688 - val_accuracy: 0.6375 - val_loss: 1.0091\n",
      "Epoch 74/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.3346Test Accuracy after Epoch 74: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8463 - loss: 0.4672 - val_accuracy: 0.6625 - val_loss: 1.0342\n",
      "Epoch 75/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.4876Test Accuracy after Epoch 75: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8281 - loss: 0.4894 - val_accuracy: 0.6500 - val_loss: 1.0785\n",
      "Epoch 76/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6128Test Accuracy after Epoch 76: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8156 - loss: 0.4855 - val_accuracy: 0.6000 - val_loss: 1.2912\n",
      "Epoch 77/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8750 - loss: 0.4880Test Accuracy after Epoch 77: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8327 - loss: 0.5015 - val_accuracy: 0.6375 - val_loss: 1.2279\n",
      "Epoch 78/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.5093Test Accuracy after Epoch 78: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8143 - loss: 0.5153 - val_accuracy: 0.7500 - val_loss: 0.9360\n",
      "Epoch 79/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.5579Test Accuracy after Epoch 79: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8361 - loss: 0.4702 - val_accuracy: 0.7125 - val_loss: 0.9924\n",
      "Epoch 80/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9062 - loss: 0.3330Test Accuracy after Epoch 80: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.4335 - val_accuracy: 0.6500 - val_loss: 1.1660\n",
      "Epoch 81/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7812 - loss: 0.3777Test Accuracy after Epoch 81: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8144 - loss: 0.4478 - val_accuracy: 0.7125 - val_loss: 1.0419\n",
      "Epoch 82/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.3756Test Accuracy after Epoch 82: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 0.4350 - val_accuracy: 0.6750 - val_loss: 1.1205\n",
      "Epoch 83/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.3474Test Accuracy after Epoch 83: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.4490 - val_accuracy: 0.7125 - val_loss: 1.0535\n",
      "Epoch 84/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.3282Test Accuracy after Epoch 84: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8441 - loss: 0.4498 - val_accuracy: 0.6375 - val_loss: 1.1359\n",
      "Epoch 85/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.3143Test Accuracy after Epoch 85: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8308 - loss: 0.4300 - val_accuracy: 0.6625 - val_loss: 1.1805\n",
      "Epoch 86/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8125 - loss: 0.3852Test Accuracy after Epoch 86: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.4190 - val_accuracy: 0.6375 - val_loss: 1.1047\n",
      "Epoch 87/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.5645Test Accuracy after Epoch 87: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8238 - loss: 0.4781 - val_accuracy: 0.7125 - val_loss: 1.0169\n",
      "Epoch 88/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.3019Test Accuracy after Epoch 88: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8653 - loss: 0.4337 - val_accuracy: 0.6875 - val_loss: 1.0807\n",
      "Epoch 89/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8750 - loss: 0.3994Test Accuracy after Epoch 89: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8502 - loss: 0.4203 - val_accuracy: 0.6875 - val_loss: 1.0398\n",
      "Epoch 90/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1660Test Accuracy after Epoch 90: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8831 - loss: 0.3666 - val_accuracy: 0.6625 - val_loss: 1.0516\n",
      "Epoch 91/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9688 - loss: 0.1570Test Accuracy after Epoch 91: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8684 - loss: 0.3968 - val_accuracy: 0.6625 - val_loss: 1.2172\n",
      "Epoch 92/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.3356Test Accuracy after Epoch 92: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8698 - loss: 0.3834 - val_accuracy: 0.6750 - val_loss: 1.0238\n",
      "Epoch 93/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2368Test Accuracy after Epoch 93: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.3551 - val_accuracy: 0.6375 - val_loss: 1.0913\n",
      "Epoch 94/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.3874Test Accuracy after Epoch 94: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8606 - loss: 0.3908 - val_accuracy: 0.7125 - val_loss: 1.0000\n",
      "Epoch 95/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2713Test Accuracy after Epoch 95: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.3394 - val_accuracy: 0.7000 - val_loss: 1.1486\n",
      "Epoch 96/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9375 - loss: 0.2786Test Accuracy after Epoch 96: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8809 - loss: 0.3597 - val_accuracy: 0.7375 - val_loss: 1.1470\n",
      "Epoch 97/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.3404Test Accuracy after Epoch 97: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8855 - loss: 0.3184 - val_accuracy: 0.7500 - val_loss: 1.0655\n",
      "Epoch 98/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1970Test Accuracy after Epoch 98: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9239 - loss: 0.2938 - val_accuracy: 0.6625 - val_loss: 1.1241\n",
      "Epoch 99/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.2076Test Accuracy after Epoch 99: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.3275 - val_accuracy: 0.7250 - val_loss: 1.0683\n",
      "Epoch 100/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1712Test Accuracy after Epoch 100: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8967 - loss: 0.3360 - val_accuracy: 0.6625 - val_loss: 1.2545\n",
      "Epoch 101/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.5010Test Accuracy after Epoch 101: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8489 - loss: 0.3888 - val_accuracy: 0.6625 - val_loss: 1.1923\n",
      "Epoch 102/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2917Test Accuracy after Epoch 102: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8732 - loss: 0.3654 - val_accuracy: 0.6625 - val_loss: 1.1996\n",
      "Epoch 103/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8125 - loss: 0.4356Test Accuracy after Epoch 103: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8478 - loss: 0.3777 - val_accuracy: 0.6875 - val_loss: 1.0070\n",
      "Epoch 104/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7812 - loss: 0.4401Test Accuracy after Epoch 104: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8700 - loss: 0.3584 - val_accuracy: 0.7250 - val_loss: 1.1238\n",
      "Epoch 105/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.3568Test Accuracy after Epoch 105: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.3102 - val_accuracy: 0.6625 - val_loss: 1.0817\n",
      "Epoch 106/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8750 - loss: 0.3625Test Accuracy after Epoch 106: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8716 - loss: 0.3799 - val_accuracy: 0.7625 - val_loss: 1.0753\n",
      "Epoch 107/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.3821Test Accuracy after Epoch 107: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8899 - loss: 0.3277 - val_accuracy: 0.6875 - val_loss: 1.1428\n",
      "Epoch 108/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8438 - loss: 0.3414Test Accuracy after Epoch 108: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8817 - loss: 0.3231 - val_accuracy: 0.7250 - val_loss: 1.1209\n",
      "Epoch 109/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - accuracy: 0.8125 - loss: 0.4522Test Accuracy after Epoch 109: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.3057 - val_accuracy: 0.7000 - val_loss: 1.0539\n",
      "Epoch 110/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8750 - loss: 0.2574Test Accuracy after Epoch 110: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.2759 - val_accuracy: 0.7500 - val_loss: 1.0896\n",
      "Epoch 111/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9062 - loss: 0.2654Test Accuracy after Epoch 111: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9039 - loss: 0.2885 - val_accuracy: 0.6750 - val_loss: 1.2166\n",
      "Epoch 112/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2366Test Accuracy after Epoch 112: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8854 - loss: 0.3064 - val_accuracy: 0.7375 - val_loss: 1.1283\n",
      "Epoch 113/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9688 - loss: 0.2267Test Accuracy after Epoch 113: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9110 - loss: 0.2714 - val_accuracy: 0.7500 - val_loss: 1.1934\n",
      "Epoch 114/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9062 - loss: 0.2990Test Accuracy after Epoch 114: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.2858 - val_accuracy: 0.7625 - val_loss: 1.0799\n",
      "Epoch 115/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2802Test Accuracy after Epoch 115: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2575 - val_accuracy: 0.7500 - val_loss: 1.1282\n",
      "Epoch 116/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.1290Test Accuracy after Epoch 116: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.2281 - val_accuracy: 0.6500 - val_loss: 1.3740\n",
      "Epoch 117/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9375 - loss: 0.3205Test Accuracy after Epoch 117: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9166 - loss: 0.2660 - val_accuracy: 0.7250 - val_loss: 1.3142\n",
      "Epoch 118/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2545Test Accuracy after Epoch 118: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.2519 - val_accuracy: 0.7500 - val_loss: 1.1268\n",
      "Epoch 119/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.2988Test Accuracy after Epoch 119: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2672 - val_accuracy: 0.7125 - val_loss: 1.1878\n",
      "Epoch 120/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1926Test Accuracy after Epoch 120: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.2652 - val_accuracy: 0.7500 - val_loss: 1.1244\n",
      "Epoch 121/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.2460Test Accuracy after Epoch 121: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.2250 - val_accuracy: 0.7375 - val_loss: 1.2423\n",
      "Epoch 122/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.2744Test Accuracy after Epoch 122: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8947 - loss: 0.2580 - val_accuracy: 0.7500 - val_loss: 1.2119\n",
      "Epoch 123/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.2544Test Accuracy after Epoch 123: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9320 - loss: 0.2148 - val_accuracy: 0.7500 - val_loss: 1.1299\n",
      "Epoch 124/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9688 - loss: 0.1234Test Accuracy after Epoch 124: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.2158 - val_accuracy: 0.7500 - val_loss: 1.2631\n",
      "Epoch 125/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1907Test Accuracy after Epoch 125: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9323 - loss: 0.1951 - val_accuracy: 0.7500 - val_loss: 1.1753\n",
      "Epoch 126/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.3089Test Accuracy after Epoch 126: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9218 - loss: 0.2337 - val_accuracy: 0.7625 - val_loss: 1.2568\n",
      "Epoch 127/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.2111Test Accuracy after Epoch 127: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.2047 - val_accuracy: 0.7500 - val_loss: 1.3484\n",
      "Epoch 128/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.3890Test Accuracy after Epoch 128: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2199 - val_accuracy: 0.7375 - val_loss: 1.2308\n",
      "Epoch 129/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.1230Test Accuracy after Epoch 129: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 0.1851 - val_accuracy: 0.7750 - val_loss: 1.2784\n",
      "Epoch 130/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1484Test Accuracy after Epoch 130: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.1981 - val_accuracy: 0.7250 - val_loss: 1.3358\n",
      "Epoch 131/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9375 - loss: 0.1983Test Accuracy after Epoch 131: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9204 - loss: 0.2156 - val_accuracy: 0.7250 - val_loss: 1.3652\n",
      "Epoch 132/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.1618Test Accuracy after Epoch 132: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9138 - loss: 0.2428 - val_accuracy: 0.7750 - val_loss: 1.2650\n",
      "Epoch 133/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.2011Test Accuracy after Epoch 133: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.1918 - val_accuracy: 0.6750 - val_loss: 1.5950\n",
      "Epoch 134/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2067Test Accuracy after Epoch 134: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.2546 - val_accuracy: 0.7125 - val_loss: 1.4368\n",
      "Epoch 135/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.1386Test Accuracy after Epoch 135: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9465 - loss: 0.1647 - val_accuracy: 0.7250 - val_loss: 1.3486\n",
      "Epoch 136/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.1094Test Accuracy after Epoch 136: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.1630 - val_accuracy: 0.7000 - val_loss: 1.5518\n",
      "Epoch 137/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.2057Test Accuracy after Epoch 137: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9364 - loss: 0.1781 - val_accuracy: 0.7875 - val_loss: 1.3765\n",
      "Epoch 138/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1056Test Accuracy after Epoch 138: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9690 - loss: 0.1454 - val_accuracy: 0.7375 - val_loss: 1.4432\n",
      "Epoch 139/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1105Test Accuracy after Epoch 139: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9570 - loss: 0.1502 - val_accuracy: 0.6875 - val_loss: 1.3659\n",
      "Epoch 140/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1199Test Accuracy after Epoch 140: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.1934 - val_accuracy: 0.7000 - val_loss: 1.4171\n",
      "Epoch 141/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9688 - loss: 0.2145Test Accuracy after Epoch 141: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.1752 - val_accuracy: 0.7125 - val_loss: 1.4719\n",
      "Epoch 142/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8750 - loss: 0.1886Test Accuracy after Epoch 142: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.1574 - val_accuracy: 0.7750 - val_loss: 1.3642\n",
      "Epoch 143/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2065Test Accuracy after Epoch 143: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.1487 - val_accuracy: 0.7625 - val_loss: 1.4412\n",
      "Epoch 144/250\n",
      "\u001b[1m 7/23\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9522 - loss: 0.1644 Test Accuracy after Epoch 144: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9581 - loss: 0.1466 - val_accuracy: 0.7625 - val_loss: 1.4211\n",
      "Epoch 145/250\n",
      "\u001b[1m20/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.1003 Test Accuracy after Epoch 145: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.1039 - val_accuracy: 0.7375 - val_loss: 1.4874\n",
      "Epoch 146/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0266Test Accuracy after Epoch 146: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9543 - loss: 0.1440 - val_accuracy: 0.7500 - val_loss: 1.3928\n",
      "Epoch 147/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.0902Test Accuracy after Epoch 147: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9570 - loss: 0.1416 - val_accuracy: 0.7500 - val_loss: 1.4277\n",
      "Epoch 148/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0352Test Accuracy after Epoch 148: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.1412 - val_accuracy: 0.7500 - val_loss: 1.4927\n",
      "Epoch 149/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0324Test Accuracy after Epoch 149: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9654 - loss: 0.1242 - val_accuracy: 0.7000 - val_loss: 1.6290\n",
      "Epoch 150/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1119Test Accuracy after Epoch 150: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.1285 - val_accuracy: 0.6625 - val_loss: 1.7566\n",
      "Epoch 151/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0332Test Accuracy after Epoch 151: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.2351 - val_accuracy: 0.6875 - val_loss: 1.5275\n",
      "Epoch 152/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9062 - loss: 0.2563Test Accuracy after Epoch 152: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2365 - val_accuracy: 0.6875 - val_loss: 1.7314\n",
      "Epoch 153/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9688 - loss: 0.0918Test Accuracy after Epoch 153: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9443 - loss: 0.1617 - val_accuracy: 0.7125 - val_loss: 1.6407\n",
      "Epoch 154/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.1665Test Accuracy after Epoch 154: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2056 - val_accuracy: 0.6750 - val_loss: 1.7210\n",
      "Epoch 155/250\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1416 Test Accuracy after Epoch 155: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9598 - loss: 0.1431 - val_accuracy: 0.6875 - val_loss: 1.6178\n",
      "Epoch 156/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0688Test Accuracy after Epoch 156: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9718 - loss: 0.1279 - val_accuracy: 0.7625 - val_loss: 1.5060\n",
      "Epoch 157/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1303Test Accuracy after Epoch 157: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9713 - loss: 0.1302 - val_accuracy: 0.7625 - val_loss: 1.4570\n",
      "Epoch 158/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9688 - loss: 0.0915Test Accuracy after Epoch 158: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0983 - val_accuracy: 0.7250 - val_loss: 1.6095\n",
      "Epoch 159/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0628Test Accuracy after Epoch 159: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.1006 - val_accuracy: 0.7500 - val_loss: 1.5374\n",
      "Epoch 160/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0609Test Accuracy after Epoch 160: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0755 - val_accuracy: 0.7500 - val_loss: 1.5894\n",
      "Epoch 161/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1144Test Accuracy after Epoch 161: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9780 - loss: 0.1015 - val_accuracy: 0.7125 - val_loss: 1.5911\n",
      "Epoch 162/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0822Test Accuracy after Epoch 162: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.1005 - val_accuracy: 0.7375 - val_loss: 1.5963\n",
      "Epoch 163/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9688 - loss: 0.0924Test Accuracy after Epoch 163: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.0900 - val_accuracy: 0.7250 - val_loss: 1.6208\n",
      "Epoch 164/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0381Test Accuracy after Epoch 164: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0909 - val_accuracy: 0.7250 - val_loss: 1.7144\n",
      "Epoch 165/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1099Test Accuracy after Epoch 165: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9608 - loss: 0.1071 - val_accuracy: 0.7125 - val_loss: 1.6858\n",
      "Epoch 166/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0412Test Accuracy after Epoch 166: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0869 - val_accuracy: 0.7125 - val_loss: 1.6943\n",
      "Epoch 167/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0228Test Accuracy after Epoch 167: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0773 - val_accuracy: 0.7250 - val_loss: 1.5169\n",
      "Epoch 168/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0185Test Accuracy after Epoch 168: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9767 - loss: 0.0944 - val_accuracy: 0.7625 - val_loss: 1.6582\n",
      "Epoch 169/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9688 - loss: 0.0980Test Accuracy after Epoch 169: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.0836 - val_accuracy: 0.6875 - val_loss: 1.9377\n",
      "Epoch 170/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0823Test Accuracy after Epoch 170: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0841 - val_accuracy: 0.7375 - val_loss: 1.7082\n",
      "Epoch 171/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0584Test Accuracy after Epoch 171: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0744 - val_accuracy: 0.7250 - val_loss: 1.7393\n",
      "Epoch 172/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0561Test Accuracy after Epoch 172: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 0.0635 - val_accuracy: 0.7250 - val_loss: 1.7223\n",
      "Epoch 173/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1189Test Accuracy after Epoch 173: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0797 - val_accuracy: 0.7750 - val_loss: 1.7891\n",
      "Epoch 174/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0795Test Accuracy after Epoch 174: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0751 - val_accuracy: 0.7375 - val_loss: 1.7836\n",
      "Epoch 175/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.0954Test Accuracy after Epoch 175: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0673 - val_accuracy: 0.6875 - val_loss: 1.8376\n",
      "Epoch 176/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0353Test Accuracy after Epoch 176: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0798 - val_accuracy: 0.7375 - val_loss: 1.8242\n",
      "Epoch 177/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0292Test Accuracy after Epoch 177: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.0803 - val_accuracy: 0.7375 - val_loss: 1.7667\n",
      "Epoch 178/250\n",
      "\u001b[1m18/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0785 Test Accuracy after Epoch 178: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0803 - val_accuracy: 0.7375 - val_loss: 1.8104\n",
      "Epoch 179/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.0971Test Accuracy after Epoch 179: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1049 - val_accuracy: 0.7375 - val_loss: 1.8047\n",
      "Epoch 180/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1717Test Accuracy after Epoch 180: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9700 - loss: 0.1206 - val_accuracy: 0.7375 - val_loss: 1.7526\n",
      "Epoch 181/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1022Test Accuracy after Epoch 181: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9750 - loss: 0.0839 - val_accuracy: 0.7125 - val_loss: 1.8342\n",
      "Epoch 182/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1116Test Accuracy after Epoch 182: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.0881 - val_accuracy: 0.6875 - val_loss: 2.0738\n",
      "Epoch 183/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.3038Test Accuracy after Epoch 183: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9397 - loss: 0.1669 - val_accuracy: 0.7000 - val_loss: 1.8470\n",
      "Epoch 184/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1945Test Accuracy after Epoch 184: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.1378 - val_accuracy: 0.7375 - val_loss: 1.8871\n",
      "Epoch 185/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.0405Test Accuracy after Epoch 185: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9633 - loss: 0.0977 - val_accuracy: 0.7000 - val_loss: 1.9475\n",
      "Epoch 186/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0329Test Accuracy after Epoch 186: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9499 - loss: 0.1406 - val_accuracy: 0.7125 - val_loss: 1.7379\n",
      "Epoch 187/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0871Test Accuracy after Epoch 187: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9797 - loss: 0.0776 - val_accuracy: 0.7250 - val_loss: 1.8685\n",
      "Epoch 188/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.1377Test Accuracy after Epoch 188: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0668 - val_accuracy: 0.6875 - val_loss: 1.9314\n",
      "Epoch 189/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0589Test Accuracy after Epoch 189: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0633 - val_accuracy: 0.7125 - val_loss: 1.8468\n",
      "Epoch 190/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0395Test Accuracy after Epoch 190: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0634 - val_accuracy: 0.7000 - val_loss: 1.9246\n",
      "Epoch 191/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0845Test Accuracy after Epoch 191: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0855 - val_accuracy: 0.7250 - val_loss: 1.8716\n",
      "Epoch 192/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0263Test Accuracy after Epoch 192: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.0606 - val_accuracy: 0.7375 - val_loss: 1.8805\n",
      "Epoch 193/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0702Test Accuracy after Epoch 193: 60.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0617 - val_accuracy: 0.6750 - val_loss: 2.1018\n",
      "Epoch 194/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0569Test Accuracy after Epoch 194: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.1133 - val_accuracy: 0.7000 - val_loss: 1.9371\n",
      "Epoch 195/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0392Test Accuracy after Epoch 195: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0516 - val_accuracy: 0.7000 - val_loss: 1.8263\n",
      "Epoch 196/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0554Test Accuracy after Epoch 196: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0592 - val_accuracy: 0.7125 - val_loss: 1.8402\n",
      "Epoch 197/250\n",
      "\u001b[1m14/23\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0436 Test Accuracy after Epoch 197: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0447 - val_accuracy: 0.7125 - val_loss: 2.0061\n",
      "Epoch 198/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0596Test Accuracy after Epoch 198: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0758 - val_accuracy: 0.7375 - val_loss: 1.8615\n",
      "Epoch 199/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0594Test Accuracy after Epoch 199: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0566 - val_accuracy: 0.7375 - val_loss: 2.0019\n",
      "Epoch 200/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0260Test Accuracy after Epoch 200: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0425 - val_accuracy: 0.7250 - val_loss: 1.8049\n",
      "Epoch 201/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0475Test Accuracy after Epoch 201: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0463 - val_accuracy: 0.7000 - val_loss: 1.9999\n",
      "Epoch 202/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9375 - loss: 0.1347Test Accuracy after Epoch 202: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9888 - loss: 0.0555 - val_accuracy: 0.7500 - val_loss: 1.9631\n",
      "Epoch 203/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9688 - loss: 0.0638Test Accuracy after Epoch 203: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0705 - val_accuracy: 0.7250 - val_loss: 1.8049\n",
      "Epoch 204/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0511Test Accuracy after Epoch 204: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0528 - val_accuracy: 0.7250 - val_loss: 2.0553\n",
      "Epoch 205/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1124Test Accuracy after Epoch 205: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9699 - loss: 0.0875 - val_accuracy: 0.7250 - val_loss: 2.0277\n",
      "Epoch 206/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0332Test Accuracy after Epoch 206: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.0712 - val_accuracy: 0.7125 - val_loss: 2.1058\n",
      "Epoch 207/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0323Test Accuracy after Epoch 207: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0527 - val_accuracy: 0.7250 - val_loss: 2.0822\n",
      "Epoch 208/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0650Test Accuracy after Epoch 208: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.0734 - val_accuracy: 0.7250 - val_loss: 1.9637\n",
      "Epoch 209/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0309Test Accuracy after Epoch 209: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0720 - val_accuracy: 0.7000 - val_loss: 2.1344\n",
      "Epoch 210/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0392Test Accuracy after Epoch 210: 48.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9143 - loss: 0.2859 - val_accuracy: 0.6625 - val_loss: 2.2446\n",
      "Epoch 211/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7812 - loss: 0.4929Test Accuracy after Epoch 211: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8521 - loss: 0.4526 - val_accuracy: 0.7000 - val_loss: 2.2591\n",
      "Epoch 212/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2295Test Accuracy after Epoch 212: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9367 - loss: 0.1624 - val_accuracy: 0.7625 - val_loss: 1.7859\n",
      "Epoch 213/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9062 - loss: 0.1058Test Accuracy after Epoch 213: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9631 - loss: 0.1003 - val_accuracy: 0.7375 - val_loss: 1.5838\n",
      "Epoch 214/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0557Test Accuracy after Epoch 214: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0598 - val_accuracy: 0.7375 - val_loss: 1.7711\n",
      "Epoch 215/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0272Test Accuracy after Epoch 215: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0524 - val_accuracy: 0.7125 - val_loss: 1.8967\n",
      "Epoch 216/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0753Test Accuracy after Epoch 216: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0504 - val_accuracy: 0.7375 - val_loss: 1.9080\n",
      "Epoch 217/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1216Test Accuracy after Epoch 217: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0517 - val_accuracy: 0.7250 - val_loss: 1.9152\n",
      "Epoch 218/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0236Test Accuracy after Epoch 218: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0389 - val_accuracy: 0.7000 - val_loss: 1.9599\n",
      "Epoch 219/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0374Test Accuracy after Epoch 219: 60.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.0443 - val_accuracy: 0.7000 - val_loss: 1.9713\n",
      "Epoch 220/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0657Test Accuracy after Epoch 220: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.0441 - val_accuracy: 0.7250 - val_loss: 1.9427\n",
      "Epoch 221/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9688 - loss: 0.0693Test Accuracy after Epoch 221: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0364 - val_accuracy: 0.7375 - val_loss: 1.9078\n",
      "Epoch 222/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0155Test Accuracy after Epoch 222: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0250 - val_accuracy: 0.7125 - val_loss: 1.9851\n",
      "Epoch 223/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0277Test Accuracy after Epoch 223: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0276 - val_accuracy: 0.7375 - val_loss: 1.9106\n",
      "Epoch 224/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0217Test Accuracy after Epoch 224: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0249 - val_accuracy: 0.7375 - val_loss: 1.9680\n",
      "Epoch 225/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0379 Test Accuracy after Epoch 225: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0359 - val_accuracy: 0.7250 - val_loss: 1.9847\n",
      "Epoch 226/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0126Test Accuracy after Epoch 226: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0245 - val_accuracy: 0.7375 - val_loss: 2.0144\n",
      "Epoch 227/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0422Test Accuracy after Epoch 227: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0310 - val_accuracy: 0.7125 - val_loss: 2.1449\n",
      "Epoch 228/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0222Test Accuracy after Epoch 228: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0227 - val_accuracy: 0.7375 - val_loss: 2.0694\n",
      "Epoch 229/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0327Test Accuracy after Epoch 229: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0301 - val_accuracy: 0.7125 - val_loss: 2.1454\n",
      "Epoch 230/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.0477Test Accuracy after Epoch 230: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0271 - val_accuracy: 0.7500 - val_loss: 2.0274\n",
      "Epoch 231/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0162Test Accuracy after Epoch 231: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0193 - val_accuracy: 0.7250 - val_loss: 2.1360\n",
      "Epoch 232/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9688 - loss: 0.0755Test Accuracy after Epoch 232: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0325 - val_accuracy: 0.7625 - val_loss: 2.0247\n",
      "Epoch 233/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0080Test Accuracy after Epoch 233: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0236 - val_accuracy: 0.7125 - val_loss: 2.0403\n",
      "Epoch 234/250\n",
      "\u001b[1m10/23\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0258 Test Accuracy after Epoch 234: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0303 - val_accuracy: 0.7000 - val_loss: 2.4402\n",
      "Epoch 235/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0126Test Accuracy after Epoch 235: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0374 - val_accuracy: 0.7125 - val_loss: 2.2995\n",
      "Epoch 236/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0211Test Accuracy after Epoch 236: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0291 - val_accuracy: 0.7250 - val_loss: 2.2135\n",
      "Epoch 237/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0265Test Accuracy after Epoch 237: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0185 - val_accuracy: 0.7625 - val_loss: 2.0978\n",
      "Epoch 238/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0141Test Accuracy after Epoch 238: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0150 - val_accuracy: 0.7625 - val_loss: 2.1275\n",
      "Epoch 239/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0316Test Accuracy after Epoch 239: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0190 - val_accuracy: 0.7375 - val_loss: 2.1525\n",
      "Epoch 240/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0134Test Accuracy after Epoch 240: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0218 - val_accuracy: 0.7375 - val_loss: 2.2159\n",
      "Epoch 241/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0705Test Accuracy after Epoch 241: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0274 - val_accuracy: 0.7500 - val_loss: 2.1648\n",
      "Epoch 242/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0095Test Accuracy after Epoch 242: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0162 - val_accuracy: 0.7000 - val_loss: 2.2396\n",
      "Epoch 243/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0062Test Accuracy after Epoch 243: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0168 - val_accuracy: 0.7000 - val_loss: 2.3316\n",
      "Epoch 244/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9688 - loss: 0.0433Test Accuracy after Epoch 244: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0197 - val_accuracy: 0.7500 - val_loss: 2.2489\n",
      "Epoch 245/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0135Test Accuracy after Epoch 245: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0174 - val_accuracy: 0.7375 - val_loss: 2.2085\n",
      "Epoch 246/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0136Test Accuracy after Epoch 246: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0147 - val_accuracy: 0.7250 - val_loss: 2.2634\n",
      "Epoch 247/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0489Test Accuracy after Epoch 247: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0265 - val_accuracy: 0.7250 - val_loss: 2.3838\n",
      "Epoch 248/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0078Test Accuracy after Epoch 248: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0181 - val_accuracy: 0.7500 - val_loss: 2.2318\n",
      "Epoch 249/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0245Test Accuracy after Epoch 249: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0301 - val_accuracy: 0.7625 - val_loss: 2.1571\n",
      "Epoch 250/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0076Test Accuracy after Epoch 250: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0171 - val_accuracy: 0.7250 - val_loss: 2.3546\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAADZlElEQVR4nOzddXiTZ/fA8W+Seqm7C8XdfbABg7HBYOzdYAJM2PbbmDF3l3fCeJkzbD7GxhSmyBju7rTU3V2S/P64I3WBllI4n+vq1TR58uRO2qTPec65z60xGo1GhBBCCCGEEELUSdvaAxBCCCGEEEKI850ETkIIIYQQQgjRAAmchBBCCCGEEKIBEjgJIYQQQgghRAMkcBJCCCGEEEKIBkjgJIQQQgghhBANkMBJCCGEEEIIIRoggZMQQgghhBBCNEACJyGEEEIIIYRogAROQggh2rTw8HBmzZrV2sMQQghxgZPASQghBMuWLUOj0bBz587WHkqbU1JSwjvvvMOgQYNwc3PDwcGBjh07MmfOHI4fP97awxNCCNFMbFp7AEIIIcTZOHbsGFpt65wHzMjIYPz48ezatYurrrqKG264gXbt2nHs2DG++eYbFi5cSFlZWauMTQghRPOSwEkIIcR5o6KiAoPBgJ2dXaPvY29v34Ijqt+sWbPYs2cP3333HVOnTq1y20svvcRTTz3VLI9zJq+LEEKI5iWlekIIIRotMTGRW2+9FT8/P+zt7enWrRtLliypsk1ZWRnPPvss/fr1w83NDWdnZ0aMGMG6deuqbHf69Gk0Gg1vvfUW8+fPp3379tjb23P48GGef/55NBoNJ0+eZNasWbi7u+Pm5sYtt9xCUVFRlf1Un+NkLjvctGkTc+fOxcfHB2dnZ6ZMmUJ6enqV+xoMBp5//nkCAwNxcnLi0ksv5fDhw42aN7Vt2zZWrVrFbbfdViNoAhXQvfXWW5afR40axahRo2psN2vWLMLDwxt8Xfbs2YONjQ0vvPBCjX0cO3YMjUbDe++9Z7kuJyeHBx54gJCQEOzt7YmKiuK///0vBoOh3uclhBCidpJxEkII0SipqakMHjwYjUbDnDlz8PHx4bfffuO2224jLy+PBx54AIC8vDwWLVrE9OnTmT17Nvn5+SxevJhx48axfft2evfuXWW/S5cupaSkhDvuuAN7e3s8PT0tt1133XVERETw2muvsXv3bhYtWoSvry///e9/Gxzvvffei4eHB8899xynT59m/vz5zJkzh+XLl1u2eeKJJ3jjjTeYOHEi48aNY9++fYwbN46SkpIG9//zzz8DcPPNNzfi1Wu66q9LQEAAI0eO5Ntvv+W5556rsu3y5cvR6XT85z//AaCoqIiRI0eSmJjInXfeSWhoKJs3b+aJJ54gOTmZ+fPnt8iYhRDiQiaBkxBCiEZ56qmn0Ov1HDhwAC8vLwDuuusupk+fzvPPP8+dd96Jo6MjHh4enD59ukpZ2ezZs+ncuTPvvvsuixcvrrLfhIQETp48iY+PT43H7NOnT5XtMzMzWbx4caMCJy8vL/788080Gg2gsksLFiwgNzcXNzc3UlNTmTdvHpMnT+aHH36w3O+FF17g+eefb3D/R44cAaBHjx4Nbnsmantdrr/+eu68804OHjxI9+7dLdcvX76ckSNH4ufnB8C8efM4deoUe/bsoUOHDgDceeedBAYG8uabb/LQQw8REhLSIuMWQogLlZTqCSGEaJDRaOT7779n4sSJGI1GMjIyLF/jxo0jNzeX3bt3A6DT6SxBk8FgICsri4qKCvr372/ZprKpU6fWGjSBCswqGzFiBJmZmeTl5TU45jvuuMMSNJnvq9friY2NBWDNmjVUVFRw9913V7nfvffe2+C+AcsYXFxcGrV9U9X2ulxzzTXY2NhUyZodPHiQw4cPc/3111uuW7FiBSNGjMDDw6PK72rMmDHo9Xo2bNjQImMWQogLmWSchBBCNCg9PZ2cnBwWLlzIwoULa90mLS3NcvnTTz/l7bff5ujRo5SXl1uuj4iIqHG/2q4zCw0NrfKzh4cHANnZ2bi6utY75vruC1gCqKioqCrbeXp6Wratj/nx8/PzcXd3b3D7pqrtdfH29mb06NF8++23vPTSS4DKNtnY2HDNNddYtjtx4gT79++vMyCt/LsSQgjROBI4CSGEaJC5ocBNN93EzJkza92mZ8+eAHzxxRfMmjWLyZMn88gjj+Dr64tOp+O1117j1KlTNe7n6OhY5+PqdLparzcajQ2O+Wzu2xidO3cG4MCBA4wYMaLB7TUaTa2Prdfra92+rtdl2rRp3HLLLezdu5fevXvz7bffMnr0aLy9vS3bGAwGxo4dy6OPPlrrPjp27NjgeIUQQlQlgZMQQogG+fj44OLigl6vZ8yYMfVu+9133xEZGcnKlSurlMpVb2jQ2sLCwgA4efJklexOZmamJStVn4kTJ/Laa6/xxRdfNCpw8vDwIDo6usb15sxXY02ePJk777zTUq53/PhxnnjiiSrbtG/fnoKCggZ/V0IIIRpP5jgJIYRokE6nY+rUqXz//fccPHiwxu2V23ybMz2Vsyvbtm1jy5YtLT/QJhg9ejQ2NjZ8+OGHVa6v3NK7PkOGDGH8+PEsWrSIH3/8scbtZWVlPPzww5af27dvz9GjR6u8Vvv27WPTpk1NGre7uzvjxo3j22+/5ZtvvsHOzo7JkydX2ea6665jy5Yt/PHHHzXun5OTQ0VFRZMeUwghhGSchBBCVLJkyRJ+//33Gtfff//9vP7666xbt45BgwYxe/ZsunbtSlZWFrt37+bvv/8mKysLgKuuuoqVK1cyZcoUrrzySmJiYvjoo4/o2rUrBQUF5/op1cnPz4/777+ft99+m0mTJjF+/Hj27dvHb7/9hre3d5VsWV0+++wzLr/8cq655homTpzI6NGjcXZ25sSJE3zzzTckJydb1nK69dZbmTdvHuPGjeO2224jLS2Njz76iG7dujWq2UVl119/PTfddBMffPAB48aNqzHH6pFHHuHnn3/mqquuYtasWfTr14/CwkIOHDjAd999x+nTp6uU9gkhhGiYBE5CCCEsqmdfzGbNmkVwcDDbt2/nxRdfZOXKlXzwwQd4eXnRrVu3Ku3BZ82aRUpKCh9//DF//PEHXbt25YsvvmDFihWsX7/+HD2Txvnvf/+Lk5MTn3zyCX///TdDhgzhzz//ZPjw4Tg4ODR4fx8fHzZv3swHH3zA8uXLeeqppygrKyMsLIxJkyZx//33W7bt0qULn332Gc8++yxz586la9eufP7553z11VdNfl0mTZqEo6Mj+fn5VbrpmTk5OfHPP//w6quvsmLFCj777DNcXV3p2LEjL7zwAm5ubk16PCGEEKAxNtcsWSGEEOICkJOTg4eHBy+//DJPPfVUaw9HCCHEeULmOAkhhLhoFRcX17hu/vz5AIwaNercDkYIIcR5TUr1hBBCXLSWL1/OsmXLmDBhAu3atWPjxo18/fXXXH755QwbNqy1hyeEEOI8IoGTEEKIi1bPnj2xsbHhjTfeIC8vz9Iw4uWXX27toQkhhDjPyBwnIYQQQgghhGiAzHESQgghhBBCiAZI4CSEEEIIIYQQDbjo5jgZDAaSkpJwcXFp1OKGQgghhBBCiAuT0WgkPz+fwMBAtNr6c0oXXeCUlJRESEhIaw9DCCGEEEIIcZ6Ij48nODi43m0uusDJxcUFUC+Oq6trK49GCCGEEEII0Vry8vIICQmxxAj1uegCJ3N5nqurqwROQgghhBBCiEZN4ZHmEEIIIYQQQgjRAAmchBBCCCGEEKIBEjgJIYQQQgghRAMuujlOjWE0GqmoqECv17f2UMQFQqfTYWNjIy3whRBCCCHaKAmcqikrKyM5OZmioqLWHoq4wDg5OREQEICdnV1rD0UIIYQQQjSRBE6VGAwGYmJi0Ol0BAYGYmdnJxkCcdaMRiNlZWWkp6cTExNDhw4dGlxgTQghhBBCnF8kcKqkrKwMg8FASEgITk5OrT0ccQFxdHTE1taW2NhYysrKcHBwaO0hCSGEEEKIJpDT3rWQbIBoCfJ3JYQQQgjRdsmRnBBCCCGEEEI0QAInIYQQQgghhGiABE6iTuHh4cyfP7+1hyGEEEIIIUSrk8DpAqDRaOr9ev75589ovzt27OCOO+5oljF+/fXX6HQ67rnnnmbZnxBCCCGEEOeSBE4XgOTkZMvX/PnzcXV1rXLdww8/bNnWvLhvY/j4+DRbd8HFixfz6KOP8vXXX1NSUtIs+zxTZWVlrfr4QgghhBCi7WnVwGnDhg1MnDiRwMBANBoNP/74Y4P3Wb9+PX379sXe3p6oqCiWLVvWomM0Go0UlVW0ypfRaGzUGP39/S1fbm5uaDQay89Hjx7FxcWF3377jX79+mFvb8/GjRs5deoUV199NX5+frRr144BAwbw999/V9lv9VI9jUbDokWLmDJlCk5OTnTo0IGff/65wfHFxMSwefNmHn/8cTp27MjKlStrbLNkyRK6deuGvb09AQEBzJkzx3JbTk4Od955J35+fjg4ONC9e3d+/fVXAJ5//nl69+5dZV/z588nPDzc8vOsWbOYPHkyr7zyCoGBgXTq1AmAzz//nP79++Pi4oK/vz833HADaWlpVfZ16NAhrrrqKlxdXXFxcWHEiBGcOnWKDRs2YGtrS0pKSpXtH3jgAUaMGNHgayKEEEIIIdqWVl3HqbCwkF69enHrrbdyzTXXNLh9TEwMV155JXfddRdffvkla9as4fbbbycgIIBx48a1yBiLy/V0ffaPFtl3Qw6/OA4nu+b5FT3++OO89dZbREZG4uHhQXx8PBMmTOCVV17B3t6ezz77jIkTJ3Ls2DFCQ0Pr3M8LL7zAG2+8wZtvvsm7777LjTfeSGxsLJ6ennXeZ+nSpVx55ZW4ublx0003sXjxYm644QbL7R9++CFz587l9ddf54orriA3N5dNmzYBalHiK664gvz8fL744gvat2/P4cOH0el0TXr+a9aswdXVlb/++styXXl5OS+99BKdOnUiLS2NuXPnMmvWLFavXg1AYmIil1xyCaNGjWLt2rW4urqyadMmKioquOSSS4iMjOTzzz/nkUcesezvyy+/5I033mjS2IQQQgghxPmvVQOnK664giuuuKLR23/00UdERETw9ttvA9ClSxc2btzIO++802KB04XixRdfZOzYsZafPT096dWrl+Xnl156iR9++IGff/65SranulmzZjF9+nQAXn31VRYsWMD27dsZP358rdsbDAaWLVvGu+++C8C0adN46KGHiImJISIiAoCXX36Zhx56iPvvv99yvwEDBgDw999/s337do4cOULHjh0BiIyMbPLzd3Z2ZtGiRdjZ2Vmuu/XWWy2XIyMjWbBgAQMGDKCgoIB27drx/vvv4+bmxjfffIOtrS2AZQwAt912G0uXLrUETr/88gslJSVcd911TR6fEEIIIYQ4v7Vq4NRUW7ZsYcyYMVWuGzduHA888ECd9yktLaW0tNTyc15eXpMe09FWx+EXWycoc7RtWlalPv3796/yc0FBAc8//zyrVq0iOTmZiooKiouLiYuLq3c/PXv2tFx2dnbG1dW1RnlbZX/99ReFhYVMmDABAG9vb8aOHcuSJUt46aWXSEtLIykpidGjR9d6/7179xIcHFwlYDkTPXr0qBI0AezatYvnn3+effv2kZ2djcFgACAuLo6uXbuyd+9eRowYYQmaqps1axZPP/00W7duZfDgwSxbtozrrrsOZ2fnsxqrEEIIIQRAbnE5cZlF9Ah2a/Z9H03Jw95GR4R3zeMWo9FIQnYxiTnF9A31wM6m/tk9ucXlHEvJp5O/C26OtR83VX/sPXE5TB9Yd5XT+ahNBU4pKSn4+flVuc7Pz4+8vDyKi4txdHSscZ/XXnuNF1544YwfU6PRNFu5XGuqfjD/8MMP89dff/HWW28RFRWFo6Mj1157bYONE6oHERqNxhJw1Gbx4sVkZWVV+d0YDAb279/PCy+8UOvvrLKGbtdqtTXmgpWXl9fYrvrzLywsZNy4cYwbN44vv/wSHx8f4uLiGDdunOU1aOixfX19mThxIkuXLiUiIoLffvuN9evX13sfIYQQQojqDiXl8sfBFLoFuTG2ix9arYZNJzO4/5u9ZBSU8tSELsy+pGkVN+V6AwcSc9kWnUV+STnX9gsm0qcdFXoD7/x9nA/WnwJgQvcA5lwWhaOtjq3RmWyLyWJbdCZJuaqZV6CbA/93aRTX9Q/G3kad1M8pKmN7TBbbYrLYGp3J4eQ8jEbwbmfHvOt6c0lHH4xGI2uOpLElOpNOfi4MivSkoLSCd9ec5PdDKdhoNQyP8ibEs3kakZ0LbT8iaMATTzzB3LlzLT/n5eUREhLSiiM6P2zatIlZs2YxZcoUQGWgTp8+3ayPkZmZyU8//cQ333xDt27dLNfr9XqGDx/On3/+yfjx4wkPD2fNmjVceumlNfbRs2dPEhISOH78eK1ZJx8fH1JSUjAajWg0GkBlqRpy9OhRMjMzef311y1/Dzt37qzx2J9++inl5eV1Zp1uv/12pk+fTnBwMO3bt2fYsGENPrYQQgghWldWYRkVBgO+Lg7Nts+0vBI++ieaLdGZjOjgzewRkfi42LPjdBbvrT3J/oQcy7Z+rg4MjPCkZ7A7vx9M4e8jqZbbOvu70D/cgy+3xWE+N/zab0fo5O/CJR19GhyH3mDkw/Un+XD9KQrL9JbrP/rnFJN6BZKQXczO2GzL9asOJLPqQHKN/dhoNTjb25CUW8IzPx7k1VVHcLDVYkRlmKr3MGtnb0NGQRkzlmznhkGh7I3L4XBy7ZVeGg2M6+7f4HM537SpwMnf35/U1NQq16WmpuLq6lpndsDe3h57e/tzMbw2pUOHDqxcuZKJEyei0Wh45pln6s0cnYnPP/8cLy8vrrvuOktQYzZhwgQWL17M+PHjef7557nrrrvw9fW1NILYtGkT9957LyNHjuSSSy5h6tSpzJs3j6ioKI4ePYpGo2H8+PGMGjWK9PR03njjDa699lp+//13fvvtN1xdXesdW2hoKHZ2drz77rvcddddHDx4kJdeeqnKNnPmzOHdd99l2rRpPPHEE7i5ubF161YGDhxo6cw3btw4XF1defnll3nxxReb9fUTQggh2hpzidfW6EwqDEau7x+CVqtp+I7niN5g5IN1J3nn7+MYjBDp7cygSE8GRXgxKNKTADfr8aTRaOR0ZhHbojPJKymnX5gHPYLcAdifkMOO09nkl6gql4yCUn7cm0RZhTqWOpKcx2dbTtPJz4V9Cbk1xpFdVM7RlHwgFgCtBkZ08GFXbDZHU/JNt8H0gSGUVRj5fncCc77azc9zhhNeS2mdWVp+CQ8u38umk5kAuDvZMjDck3K9gXXH0vlxbxIALvY2vD61J+19nXl3zUlWH0zGRquhd4g7gyK8GBzpRd8wd7QaDct3xPPh+lOk5JVQXG4NxNr7ODMo0otBEZ4MjvTCzdGWl1cd5outcXy1TU39cLbTMaFHADEZhexLyKHCYGRiz0DmXBZFRz+XM/kVtqo2FTgNGTLE0vHM7K+//mLIkCGtNKK2a968edx6660MHToUb29vHnvssSbP/2rIkiVLmDJlSo2gCWDq1KncfPPNZGRkMHPmTEpKSnjnnXd4+OGH8fb25tprr7Vs+/333/Pwww8zffp0CgsLiYqK4vXXXwdUg5APPviAV199lZdeeompU6fy8MMPs3DhwnrH5uPjw7Jly3jyySdZsGABffv25a233mLSpEmWbby8vFi7di2PPPIII0eORKfT0bt37ypZJa1Wy6xZs3j11VeZMWPG2b5kQgghxBkpLtPjaFf/3GiDwcgfh1L4blcCE3oEMLVfcLM8dmxmIVtO1SzxArDTaZvtcc5W9aACIDqjkOiMQr7eHg9AkLsj7ezV4XFWURnp+aVV9uFoq8OIkZLy2k829wvzYEqfIFbsSmBffA77EnKx1Wm4tl8INwwMxdFOi9EIp9IL2Bqdxd74HNr7tOPuS9vT3qcdOUVlLNkYwz/H07l1eARX9w6itEJPdEYBe+JyuHXZDl68ujvDorwwGuHPw6l8uvk0WYVqmkFybjF5JRU42up48epuTO0bbAlcDybm8sH6kxSW6nnp6u6EeqkSufdv7EtOURn2Nrpa/4ZmDg1n+sBQ4rKKAJVmcneyw7tdzcTEy5N7MCTSm4UbTjG8gze3D4/Ew1nNMS8qq6C8woibU8NzoM5XGmNjFwtqAQUFBZw8eRKAPn36MG/ePC699FI8PT0JDQ3liSeeIDExkc8++wxQ7ci7d+/OPffcw6233sratWu57777WLVqVaO76uXl5eHm5kZubm6NrERJSYml25uDQ/OlbsWF7bbbbiM9Pb3BNa3k70sIIURzyy0q5/GV+/njUApPXdmV24ZH1Lrdn4dSePvP4xxLVZkMHxd7tj852nJys6C0gn+PpzM40styoNuQknK9JcNQmY1WQ4C7A/FZxXT2d+G3+0fUehL1XDqVXsANn2wlNa8UR1sdL03uztgufuw4ncW2GBX0HUzMxVDtqNjORkvvEHc8nGzZcTrbEqB4OdsxMMKaodJpYVQnX4a290Kj0WA0GtlwIoMTqflc0SOAIPf65003JC2vhInvbSQ1TwVyfUPdKSrTWzJTlXX2d+G9G/oS5dvurB7zYlFfbFBdq2acdu7cWWVei3ku0syZM1m2bBnJyclVurxFRESwatUqHnzwQf73v/8RHBzMokWLpBW5aBW5ubkcOHCAr776qlELAQshhBBny2AwUqZX2Y5DSbnc9/VeEnOKAXhl1WGifNsxsto8mMUbY3jp18OAKtEqKteTnl9KQnaxZWL+f387yudbY3G20zFjaDi3DAvH1UFlBuKyVLnazths7HRaBkV6EerpxLM/HbQcuA8M97SUvPUNc6e8wsiQ19dwNCWfjSczGNFBjanynORz5WRaPtM/2UZ6filRvu346Ka+RPmqMrExXf0Y01U1HssvKedIcj4VptfX3lZHt0BXHExdjo1GI6fSCwAN7X2c630eGo2GkR19avwuzpSvqwO/zBnOB+tP8fX2OHbH5QDq9zlrWDiDI73QALY2WnoFuzfYBU+cmVbNOLUGyTiJ5jJq1Ci2b9/OnXfeyTvvvNPg9vL3JYQQ55/tMVksWHOCI8l5XNHDn/8bFUWQuyOlFXoOJORiBHoEuVkOnltTen4pVy74l7Rq5WOhnk50CXDhj0OpuDrYVJkHs+jfaF5edQSAmUPCmDu2EzOWbGNfQi7/m9abq3sHATDs9bWWAKwpKndRq+75nw+xbPNpLunow2e3DuR4aj63LttBJz8XFs3sX2vgUVRWwb74XAZHejZLgHUiVQVNGQWldPZ34cvbB+FVS4lZW5KWV8I3O+Kxs9EyfUBomy59Ox+0mYyTEG2ZtB4XQoi2Ky6ziEe/38fW6CzLdV9sjWP5jni6B7lxOCmPUtNEfzsbLX1C3BkU6cXgSE/6hnq0SiC1LSazStCk0cCkXoG8NLk79jZapi/cyu64HGYs2U7/MA8KSiv487BqqnXvZVHMHdsRjUZD3zAP9iXksjs2m6t7BxGfVURiTjE2Wg3vXN+bT/6NZn+lhgYOtlr6hXkwMNyL4nI922IyOZyUx+BIL968tie+rrWfDLx1WASfbTnNhuPp/LwviRd+PkRmYRkJ2cXsjc+hT6hHle2zCsu44ZOtHE3J56XJ3bl5cNhZvV56g5E7v9hFRkEpXQNc+eL2QXg2sgzxfObr6sB9ozu09jAuShI4CSGEEOKci80s5P11J9kZm82rU3owONLrnD12Xkk5s5ZtJzq9EFudhuv6hzCyow9LN51mS3Qme0xlUN7t7AANGQWlqvFBTBYL1qiGB09O6MysYbXPJ2oppzMKARUsvTKlOzZabZXJ/B/d1I+J720kLqvINJFfuX90Bx4Y08GSwekb6sHSTact5V5bTqlmCb1C3JnYK5CJvQIpKK2wrJPoaKvDRle19KsxJXehXk6M6+bPbwdTuO/rPQDotBr0BiNfbourEjhlFpRy46JtltK/hRtOccPAUHRn0ZHv7yOpRKcX4upgw5e3D2r03C0h6iKBkxBCCCHOmej0At5fd4of9yaiN83Ev+uLXfwyZzghnk4YjUb+PJxKSbmeSb0Cm30+jMFg5MFv9hKdXkiAmwPf3jnEMs/n8m7+7IrNJiajkN4h7rT3UeVu0RmFamHQaNVIIDWvlJdWHaFPqAe9QtwBVRK24UQGNw8Oa7H5JTEZKhjq4NsOF4ea5Vm+rg78dM9wVh9Itry2UX7tuLSTb5Xt+oWpgOVwch5FZRVsiVaB0+BIT8s25s5ydWns72X2JZH8djAFgJ7Bbjw4piO3LNvBr/uTeObKrrg52ZJRUMoNn2zleGoBvi72lOkNxGcV88ehFCb0CGjU49Rm0b/RANw0OEyCJtEsJHASQgghRIs7mVbAe2tP8PO+JEvnslGdfMgoKOVgYh6zP9vJZ7cN5JVVR/jJtNbM0ZR8Hh3XqdEH6UajahNdOQtTUFrB3OV7KdMbGBThRXJuMWuOpmFvo+Xjm/tZgiazfmEelsDCrL1PO9r7tOPGQWEYjUbu/XoPv+5P5uEV+/jl3uEcSc5jxuLt5JdW4OJgw3X9Q87ilarb6UyVcapvHR9/NwduraOznlmguyMBbg4k55awLz6XrabAaUikd/MN1qRvqAe3DAsnJbeE16f2xNXBhs7+LhxNyWflngRuHBTGXZ/v4nhqAX6u9nw9ezA/7klkwdqTLNwQzRXd/c8oeN4br9ZZstVpmDk0vNmfl7g4SeAkhBBCiBZ1MDGXaz7cbFkcdHRnX+4b3YFeIe4k5xYz8d1NHE3JZ/h/11FWYUCrAYMRPlx/Cr3ByOPjO3M8LZ/9CbkMbe9FsIdTjccoKdczc8l2DiflsWhmfwaZSv9eWXXEMs9n/bF0y/avT+1Bz2D3Jj8XjUbDS1d3Z2t0FifSCnhw+V7+PZFBQWkFADtismoETkajkeiMQnbHZuPuZMfAcM8zmtBvLtWLqCdwaqy+oR6sOpDMD3sSSM4twVanqREwNpfnJnar8vONg0J55qdDfLktjhNpBeyMzcbFwYYvbx9MpE87bh4Szkcbotkbn8Ou2Gz6h3vWsee6fWLKNk3qFYRfHXOwhGgqCZyEEEKIC4jRaOR/a07g7mh7zufgVB5D5SzBko0xlFUY6BPqzktXd6d7kJvltgA3Rz6+uS/TFm6lrMJAoJsDC6b34XByHs/+dIiFG6L5alucJTAJ9XTi9wdG4GRnU+XxnvrhINtiVKOHu7/czc/3DudkWgFfb1fLmtw9qj0n0wo4kJjLtAGhTOlz5ouyejjb8do1PZj92U5LGZo5g7MrLrvKuF7//SgrdydWWUhVo4Eu/q48dWUXhkU1LsuTV1JOpmkNofoyTo3VN0wFTit3JwLQJ8SjwQV0m8vVfYJ4dfVRTqYVcDKtAI0GFkzrY1l3yMfFnim9g1i+M56PN0TTNVB1OnOw0VkWc61PfFYRvx1IBuD2Ea3zHhAXJgmchBBCiAvI3vgc5v99AoBJvYPOeRexW5ZuJz67mO/uGoK7kx3ZhWX8ajqIfW5itypBk1m/ME8WzxzAtphMZo+IxN3Jjv7hnmg1Gp7+8SAFpRWqQYFWQ1xWEa//dpQXr+5uuf/STaf5fncCWg2EeDoRm1nEHZ/ttCxWOmtoOI+O79ysz3NsVz+u7RfMd7sSGNrei7f+04uhr68lOr2Q7MIyPJztOJVewMf/qMyHnY2WXsFuZBaWEZ1eyOHkPN5de6LRgZM52+Tdzr7B+UeN0TfUHYAKU91k5flNLc3VwZarewfyzY54AB4Z14lLO1edh3X7iAiW74znr8OpdH32DwC6Bbry0z3DajSqqO7zrbEYjDCigzddAupvLy1EU0jgJIQQQlxAft2fbLm883QWl3fzP2ePHZ9VxDpTOdz8v0/w/KRufL87gbIKA10DXOkVXDNoMruko0+NtYBuGhxGz2A3yvVGega7sTU6k5sXb+ezLbGM6+bP4EgvftyTyCur1TpFT07owvju/kx6bxOHkvIACPdy4tHxnVrk+f53ak+mDwyhR5BacDTSx5no9EL2xGdzWWc/1h1Vr8XgSE+W3TLQ0sJ8V2wWUz/cwqHEPAwGY6OyKDGWMr2aZYpnolugG3Y2Wkv55OD2566rIajA6LeDKVzR3Z//G9m+xu0d/FwsganZoaQ80vJLCXR3rHff5jlbLTXXTFy8ZFnhC4BGo6n36/nnnz+rff/444+N3v7OO+9Ep9OxYsWKM35MIYQQZ8ZgMLL6gDVw2nE6q56tm5+5Oxuos/7HUvL5ylQqd+Pg0DOa5N8z2J1+YR7Y6rSM6ODDjYNCAXh4xT7Gzd/AQyv2oTcYuaZPELcNjyDYw4n3b+iLTqtBo4G3/tOrSllfc9JpNfQL87R00etraq+9OzYHgHXH0gC4vKt/lXWfegW7Y2+jJb+0wtLwoSGnTR31wr3OvkwPrBkw8+W+oS0zv6kuUb4u7H12LK9P7Vnn38Vb/+nFkRfHc/jFcZbMaV5Jeb37rdAbOGZqad6jluymEGdDAqcLQHJysuVr/vz5uLq6Vrnu4YcfPifjKCoq4ptvvuHRRx9lyZIl5+Qx61NWVtbaQxBCiHNqT3w2ybkllp+3n86uZ+vmt9W0HpCdToveYOT2z3YQnV6Is52Oq3sHNctjPDGhC8EejiTnlnAyrQBXBxseHNOR16b2sByAD2nvxa/3DufHu4edUWOBM2VurrArNpv8knJL4Fq9DM1Gp6Wbad7OgcRcGqMxHfWayhws9Qlxb5UFfRsTSDva6XCys8HVQQW/+SUV9W4fk1FIaYUBZzsdoZ7Nk50TwkwCp8YqK6z7q7ykCdsWN27bJvD397d8ubm5odFoqlz3zTff0KVLFxwcHOjcuTMffPCB9eHLypgzZw4BAQE4ODgQFhbGa6+9BkB4eDgAU6ZMQaPRWH6uy4oVK+jatSuPP/44GzZsID4+vsrtpaWlPPbYY4SEhGBvb09UVBSLFy+23H7o0CGuuuoqXF1dcXFxYcSIEZw6dQqAUaNG8cADD1TZ3+TJk5k1a5bl5/DwcF566SVmzJiBq6srd9xxBwCPPfYYHTt2xMnJicjISJ555hnKy6uesfrll18YMGAADg4OeHt7M2XKFABefPFFunfvTnW9e/fmmWeeqff1EEKIlrZiZzw3Ltpqmf/yyz6VbRoYoYKFQ4m5FJXVfaCZkF3EMz8e5LZlO8gtrv9MfkOMRqMl4/T8pG7Y6bTEZ6n/eZP7BDXLvBxQ6wu9f0NfBkV48tDYjmx8/DLuH9MBe5uqB/5dAlwtayydK+ZAZF9CDhuOZ1CuNxLu5VRrFzxzR7/9CY0LnGKasaOe2c1DwhjRwZv7R3dotn22FPO6VXkN/J0eTlYlmp38XRpVAilEU8gcp8Z6NbDu2zpcDjdWKk17MwrKi2rfNmw43LLK+vP8HlCUWXO75xv3QdqQL7/8kmeffZb33nuPPn36sGfPHmbPno2zszMzZ85kwYIF/Pzzz3z77beEhoYSHx9vCXh27NiBr68vS5cuZfz48eh09Z+NWrx4MTfddBNubm5cccUVLFu2rEpwMWPGDLZs2cKCBQvo1asXMTExZGRkAJCYmMgll1zCqFGjWLt2La6urmzatImKivrPLFX31ltv8eyzz/Lcc89ZrnNxcWHZsmUEBgZy4MABZs+ejYuLC48++igAq1atYsqUKTz11FN89tlnlJWVsXr1agBuvfVWXnjhBXbs2MGAAQMA2LNnD/v372flypVNGpsQQjSnknI9r6w+Qk5RObM/28n3dw+1lOndeUkkCVlFJOWWsCcup0YDgrS8Eub9dZzvdiVYmgOs2p/MDaYyuDMRm1lkaWs9pU8Q8dlFfLhenfw6m/3WpleIO8vvHNKs+2wOHXzb4WJvQ35pBR9vMJ34q7b4rJm5jOxAIwMnS8apmUr1AII9nPj8tkHNtr+W5OrYuIzTkWRVpidNIURLkMDpAvfcc8/x9ttvc8011wAQERHB4cOH+fjjj5k5cyZxcXF06NCB4cOHo9FoCAsLs9zXx0dN0nV3d8ffv/7JxSdOnGDr1q2WYOKmm25i7ty5PP3002g0Go4fP863337LX3/9xZgxYwCIjIy03P/999/Hzc2Nb775BltbdVapY8eOTX6+l112GQ899FCV655++mnL5fDwcB5++GFLSSHAK6+8wrRp03jhhRcs2/Xq1QuA4OBgxo0bx9KlSy2B09KlSxk5cmSV8QshxLm2+kAyOUXq7PuJtAKu+2gLafmluDjYMLyDNwMiPPlpbxLbY7KqBE7/HE9n7vK9ltbWXs52ZBaWsTc++6wCHPOEfHNb63sujWJffA6hnk50C7w45ppotRr6hHmw4Xi6JZNUvUzPrIdpftHBpFz0BiM6U3akeit3gJyiMsvvOryZmkO0NS72poxTA3OcjpgyThI4iZYggVNjPZlU922aapmYR07Ws2216sgHDpz5mBpQWFjIqVOnuO2225g9e7bl+oqKCtzc1Af2rFmzGDt2LJ06dWL8+PFcddVVXH755U1+rCVLljBu3Di8vdU/5wkTJnDbbbexdu1aRo8ezd69e9HpdIwcObLW++/du5cRI0ZYgqYz1b9//xrXLV++nAULFnDq1CkKCgqoqKjA1dX6gbp3794qr091s2fP5tZbb2XevHlotVq++uor3nnnnbMapxBCVJaYU8yptAJ6hbjj5ti4z8GvtqmmCxN6+PP34TSOmibEj+vmj72NjgHhKnAyz7Op0Bt4+6/jlixQZ38XXp7cnWxTxmpf/NlVOpjL9Mzd2drZ2/DV7MFntc+2qG+oOxuOq256jrY6BkXUPseqvU87HG11FJXpickoIMrXhXl/HefTzaeZO7YjM4aEWQIoc5men6t9izW6ON81PuOkAifz2k9CNKeL8913JuyakBpvqW2bqKCgAIBPPvmEQYOqpuLNZXd9+/YlJiaG3377jb///pvrrruOMWPG8N133zX6cfR6PZ9++ikpKSnY2NhUuX7JkiWMHj0aR8f6W4c2dLtWq8VoNFa5rvo8JQBn56qv55YtW7jxxht54YUXGDdunCWr9fbbbzf6sSdOnIi9vT0//PADdnZ2lJeXc+2119Z7HyGEaKyScj3/+XAzSbklloVRZw0N57oBdbdSPpqSx87YbHRaDc9P7MalnXx55Lv9AFzZMwCwznPaE5dDud7Ai78c5vOtsQDcPDiMp67sgoOtjrR8NU/3eFo+BaUVZzQXyWg0ssXUGOJcrgd0PjI3iAAYFuVVZ9MFnVZD9yBXdpzOZn9CLq4Otny4/iTleiPP/XyIzacyeGNqL9ycbFukTK+tacwcp4yCUtLyS9Fo1IkBIZqbBE4XMD8/PwIDA4mOjubGG2+scztXV1euv/56rr/+eq699lrGjx9PVlYWnp6e2Nraotfr632c1atXk5+fz549e6rMgzp48CC33HILOTk59OjRA4PBwD///GMp1ausZ8+efPrpp5SXl9eadfLx8SE52dpiV6/Xc/DgQS699NJ6x7Z582bCwsJ46qmnLNfFxsbWeOw1a9Zwyy231LoPGxsbZs6cydKlS7Gzs2PatGkNBltCCNFYX22LIym3BButhgqDkcPJeTz6/X56hbjTqY6DP3O26fKufvi6OvCf/iEUllaQkF3MJR1UmXWUTzvcnWzJKSrn2Z8O8fX2ODQaeOe63kzuY+1w5+viQJC7I4k5xexPyGFo+8YtyFpZdEYhafmlrdLW+nzTO8QdjQaMxrrnN5n1CHK3BE6n0gso1xsJcnckPb+UPw6lcijpX77/v6HEmFqRN2djiLbG1Rw41ZNxMmebwr2cL9rMnGhZ8ld1gXvhhRe47777cHNzY/z48ZSWlrJz506ys7OZO3cu8+bNIyAggD59+qDValmxYgX+/v64u7sDak7QmjVrGDZsGPb29nh41PyHuHjxYq688krLvCCzrl278uCDD/Lll19yzz33MHPmTG699VZLc4jY2FjS0tK47rrrmDNnDu+++y7Tpk3jiSeewM3Nja1btzJw4EA6derEZZddxty5c1m1ahXt27dn3rx55OTkNPj8O3ToQFxcHN988w0DBgxg1apV/PDDD1W2ee655xg9ejTt27dn2rRpVFRUsHr1ah577DHLNrfffjtdunQBYNOmTU38LQghRO2Ky/R8YCqde/Hq7ozp4stj3+9n3bF0Pvk3mrf+06vGfYrKKvhhdyJQtenCrGERVbbTajX0D/Pk7yOpfG1aS2numI5VgiazXiFuJOYUsy8+94wCJ/P8pr6hrdPW+nzi4mDL6M5+7InL5vJufvVu29M0z2lbTBZJOaoD4TNXdSXI3ZG7v9pFfFYxd36+C39XB6B5W5G3NS6mduT1zXGyzm+SbJNoGdKO/AJ3++23s2jRIpYuXUqPHj0YOXIky5YtIyJC/YN1cXHhjTfeoH///gwYMIDTp0+zevVqtFr1p/H222/z119/ERISQp8+fWrsPzU1lVWrVjF16tQat2m1WqZMmWJpOf7hhx9y7bXXcvfdd9O5c2dmz55NYaEqP/Dy8mLt2rUUFBQwcuRI+vXrxyeffGLJPt16663MnDmTGTNmWBozNJRtApg0aRIPPvggc+bMoXfv3mzevLlGG/FRo0axYsUKfv75Z3r37s1ll13G9u3bq2zToUMHhg4dSufOnWuUPQohRENyi8spraiZvf9yWywZBaUEezhybb9gfF0duNfUGvqnvYmk5akyusNJeVz74WZGvrmOy976h/zSCsK8nBjWQJAzMMJ6suuK7v7MuSyq1u16m9p2740/s3WfzGV6QyKbHnRdiBbe3I+tT47G18Wh3u3MDSKOJOeRW1xOmJcTY7v60SPYjS9uG4Sboy1743P4/VAKcJFnnExz/+qb42TpqOcv85tEy9AYq08cucDl5eXh5uZGbm5ulQYBACUlJcTExBAREYGDQ/0fduLiYjQa6dChA3fffTdz5849o33I35cQF6ddsdlM/XAz9qYytkGRngyK8KKzvwtj5v1DZmEZb0ztWWVO09QPN7MrNpt7Lm3PLcMimPTuRpJyq64Z+MKkbswcGl7vY59My2f8/H/p6OfCiruG4FzH/KVt0Zlcv3Ar/q4ObH1ydJOeX7neQP+X/ya3uJwVdw1hwDlccLatMxiM9HzhTwpKVTDw4tXdmDEk3HL7vyfSmblkO6aO8fz54CV09Ls4syl/HErhzs930TvEnR/vGVbrNuPnb+BoSj6LZvRnTNf6s31CmNUXG1QnpXpCNCA9PZ1vvvmGlJSUOudBCSFEXf49oTqslVYY2BKdaeo+d8IyDybU04kpfauWz80eEcGu2Gy+2BrH9pgsknJLiPR25r/X9kSr0eBkp2vU5PcoXxf+fexSPJ3taiwQW1mPYDe0GkjJKyEltwR/t8af3NlxOovc4nI8ne0u+vlNTaXVaugW6Mq2mCzcHG25tl9wldtHdPDhyQldeHnVEWx1GkI9L85W5GCd45RfR6leaYWek2mqKVYX6agnWogETkI0wNfXF29vbxYuXFjrHC8hhKjPqXRVkjxraDhRvu3YGp3Jtpgs0vNLAXhwbAdsdVUr58d29SfMy4nYzCJ2nM7Gxd6GhTP6E+XbrsmPH+DWcDMbJzsbOvq5cDQln73xOYx3q3/tvsr+PJQKwJguvpa1iETjjejgzbaYLG4dFlFrQ4Pbhkdgb6vD3dH2op4/Zp7jVFep3sm0AioMRlwdbAhsQuAvRFNI4CREAy6yalYhRDOLTldnwYdHeTOmqx83DQ7DaDQSk1FIdlF5lfbVZjqthtuGR/DsT4fQaGD+tN5nFDQ1RZ9Qd2vg1L1xgZPRaOSvwypwGtu18cGWsLrjkvYMi/K2zDOrTqPRcPPgsFpvu5iY1zerqznE4STr+k3VFxAWorlI4CSEEEK0EIPBSLQp4xTpY53Yr9FoiPSpPxC6rn8IJ9MK6BXszuguLT9fo1ewO19vj6+3QYTRaORoSj4d/VzQaTUcSsojMacYR1sdIzpIY4gzYWejpY+UODbInHEqKTdQVmHAzqZqlta8SPDFOgdMnBvSVa8WkmEQLUH+roRoe/JLyln0b7Rl7kRTJeeVUFyux1anIaSJ81McbHW8eHV3plab99JSeoe6A3AgIRe9ofbPqx/3JnLF//7lzs93ojdYs02XdPS+qMvIRMurvDBzbfOcsgrLAPBpZ3/OxiQuPhI4VWJufV1UVNTKIxEXIvPfVW0L/AohWl9haYWluxmokqAZS7bz8qoj3LhoK7lFda8fU5dTpoArzMu5xjym800HXxec7HQUluktZ++r++OgCpT+PpLGvL+O8aeU6YlzxEanxdlOBee1zXMyB04eznbndFzi4iKlepXodDrc3d1JS0sDwMnJSepkxVkzGo0UFRWRlpaGu7s7Op2clRXifJOUU8w1H2wmu6iM6QNDuXFQKA9/t5998TkApOaV8sIvh5h3fe8m7feUaX5Te5/zf/0dnVZDe592HEjM5VR6QY05VQaDkW0xmZaf31+nFu7VamB0Z99zOlZxcXJ1tKWwTF/rPKcc04kNTwmcRAuSwKkaf3911swcPAnRXNzd3S1/X0KIM7M9JotPN5/mmau6Nqlldn2Ky/Tc8flOUkyLzS7bfJplm08D4OFkyyPjOvP0jwdYuSeR8d39ubxb49/H1sCpZRs7NJf2Ps6WwKm6Y6n5ZBeV42Sn4/oBISzddBqAgRGecpZfnBMuDjYk59aRcSoyZZyc5G9RtBwJnKrRaDQEBATg6+tLeXnTyzKEqI2tra1kmoRoBvP+OsbW6Cw8ne14aXL3s96f0Wjk8ZX7OZiYh4eTLc9P6sYXW2PZcTobT2c7vrx9EF0CXInNKuTjf6J58ocD9A/3bPRZ7VNpquSt7QROapzmcVe25ZTKNvUP9+TpK7tyKr2QDcfTubp3UI1thWgJ5rWc8oprHp9lm0r1JOMkWpIETnXQ6XRyoCuEEOeRsgoDe+JyAPhlfxJPX9XFsqjrV9viKCqr4LbhEU0qsf7k32h+2puETqvhgxv7MaS9F5N6BXIoKQ9fV3t8XVRW68ExHVl7JI0TaQV8uP4kT13ZtVH7j85QmZvINlCqB9DeVJ5XW8ZJLdwLgyM90Wk1LJ7Zn/0JufSpo422EM2trrWcDAYj2eaMk7PMIxYt5/yeqSqEEEKYHEjMpbTCAKj5DOuOpqvrE3J58ocDvLzqCIdMa7lUp4KubMpM9wf453g6r/92FIBnr+rKkPZegKo86B7kZgmaQHW4e2RcJwB+3Z+MoY6ucym5JaTkqpK//JJyUvPUIrcNtR4/X1gyTukFVTqB6g1GtpkCpyGR6nWy1WnpF+aBVha9FeeIax1rOeWVlGN+S0qpnmhJEjgJIYRoE3aczqry88rdCQDM//u45bpVB5KrbFNaoefLbbFc+tZ6pnywmakfbiY2s5DTGYXc+9VuDEa4vn8IM4Y0vMDoJR19cLG3ITm3hD21rHWUUVDKuPkbGP+/DeQUlVnWb/Jxsbcs3nm+C/NyQqtRZ/QzCsos1x9JziOvpIJ29jb0CHJrxRGKi5k545RXLeNk7qjn4mBz3nevFG2b/HUJIYRoE3aaAqf/mNY1WncsjXXH0lhz1NrMZ9X+ZEumJD6riNFv/8NTPxwkMacYUFmrKxdsZMaS7eSVVNA31J0XJ3drVHmfg62OsV3VQrS/7k+ucfvH/5wit7icnKJyvtwW16Y66pk52OoI9lDrTVUu19tqyjYNCPfARg5MRSsxz3Gqvo6TuUxP5jeJliaffkIIIc57BoORHadVlufGwWH0CHKjXG9kzpe7AZjQwx8HWy1xWUUcTFTlem//eYyE7GJ8Xex5bmJX1j08igHhHhSUVhCXVYSfqz0f3dTPMk+qMa7sGQDA6gNVy/XS8kv4fGus5edlm09zJFmNo600hjAzB3qVAydzY4jBpjI9IVqDi6U5RPWMkwqkpExPtDQJnIQQQpz3TqQVkFtcjqOtjm6BrlzTV3VyKyzTo9NqeGx8Z0Z3NmeDkjiZls/P+5IAWDJrALcMiyDC25mvZw/m/tEd6BXsxicz+uPr2rSW5sM7eOPiYENqXik7Y63leh+tj6ak3ECvYDf8XR1Izy/lq21xQFsMnKp21qvQG9geo7J95nlgQrQGV0dzc4hqGSfz4rdObaMkVrRdEjgJIYQ47203len1DXPHVqdlYq9AbExNCab2DSLMy5mrTNmgX/cnM//vExiMcHlXP7pXmpNjo9Py4NiO/DRnOD2D3Zs8DnsbHeNM6zj9ul8FZql5JXy5TWWbHrq8EzOHhgMqqIO201HPrHpnvYNJeeSXVuDiYEO3QJnfJFqPJeNULXCyrOEkpXqihUngJIQQotWU6w0s+letj/TdrgTis4pq3W6HKeMxINwTAO929swaGk6kjzP3j+kIwKhOvjjZ6UjMKbbMQXrAdFtzspbrpfD7wRQe+W4/pRUG+od5MKKDNzcMCsXZzlr+12YzTqbA6RdT5m5EB2900kFPtKK62pFb1nCSUj3RwmQdJyGEEK0iMaeY+77ewy5TyZu5tA1AowGdRsMVPQJ4eXJ3S0e9gabACeDpq7ry9FXW9ZQc7XSM6eJnKdG7ors/XQNdm33cw9p74+ZoS0ZBKXd9scty/dzLO6LRaHBztOW6ASEs3XQaexstQe6OzT6GlmSe45SYU0xBaQU/7U0E4Jo+wa05LCGsC+BWzzgVSsZJnBsSOAkhhDgnYjIK+XTzacr0BoxGI6sPpJBbXI6LvQ3X9A1if2Iu+xNy0RuMGI1QYTTyy74kdsRkkZJXgo1WQ59Qj3of48qeAZbA6f4xHVrkedjZaJkxJIx3154kyrcdgyI8ubJHAEPbe1u2uX1EJL/uT2Zoe682t86Rp7Md7k625BSV8+nm02QUlOHlbMfITj6tPTRxkXOtK+MkXfXEOSKBkxBCiHPi5V8PV2kdDtAr2I13p/cl1Eu1wC4u01NQqg6KTmcW8tC3+4gzle91D3LD0a7+DniXdfZl+sBQIr2d6ezf/Nkms4cu78S9l3XAzqb2ivcgd0e2PjG6TZa2aTQa2vu0Y1dsNh//cwqASb0DZX0c0erMC+Dml1RgNBotywhYMk5SqidamAROQgghWlxhaQX/nswA4M5LInG2t8HXxZ5r+gZXCT4c7XSW4MjHxZ5f7xvOEysPsGp/Mpd382vwcWx1Wl67pkfLPIlq6gqazNpi0GTW3seZXbHZloVGp/aVMj3R+sxznPQGI0Vlepzt1c/ZRap0TzJOoqVJ4CSEEKJZVOgNALUukLrheDplFQbCvJx4/IrOjVpwFtSchvem9+HZq7ri62LfrOMVdavc0KKTnwvdWmCumBBN5Wirw0arocJgJK+k3BI4mTNOns7Sjly0LMm7CyGEaJL0/FK2RmdWuS6rsIwRb6xj8gebKCnX17jPn4dTAdUevLFBk5lGo8HP1aHJ9xNnrnLgdE3fIHntxXlBo9HU6KxXoTeQWywL4IpzQwInIYQQjXYsJZ/x8zcwbeFWvt0Zb7l+4YZoknNLOJiYx5t/HKtyn3K9gbWmuU1ju/qf0/GKM9PBTwVOWg1M7hPUyqMRwso8zynPFCyZgyaNBtwcJeMkWpYETkII0YaVVRi49sPN3Lx4G3qDsUUf60hyHtM/2UqmqSzmjd+Pkl9STkZBKZ9tOW3ZbsmmGLab1l0CtQZTbnE5ns529AurvyueOD+EeTnz9JVdePPaXvi5OrT2cISwqJ5xMnfUc3O0rbVMWIjmJH9hQgjRhq09msbO2Gz+PZHBX6ZyuLOhNxj5ZEM0u+Oyq1x/IjWfGz7ZSlZhGT2D3Yj0diajoIz31p5k4YZoisr09Ax24z/9gjEa4eEV+ygqUwc25jK9MV1823TDhIvN7SMimdpPmkKI80v1tZyyCk2NIaRMT5wDEjgJIUQbtnJ3guXyon+jm2V/r6w+wuPf769y/YfrT5FdVE6vYDc+v20Qz5gWnl2yKcaSbXpwTEeemdiVQDcH4rKKuOuL3RxLybcEdJdLmZ4Q4iyZM07mjo+y+K04lyRwEkKINiqrsIx1x9TcIZ1Ww87Y7BqZoqb6clscACfTCiguszZ5OJiUC8B9ozvg5mjLpZ19GdXJh3K9kZJyA71D3BnVyQdXB1veuLYXOq2GDcfTGTd/A4k5xTja6hjewbvWxxRCiMYyZ5zyTRknc6meNIYQ54IETkII0UYYjcYqwcyv+5Mo1xvpHuTK5N5qAv/ZZJ0OJuayNz4HAIMRjqXmA1BSrudUeiEAXQKsbamfvrIrNqbSu7ljO1o6rw3v4M2v9w5nQg9rhmlkRx8cbOtfvFYIIRriYi7VK66WcXKSxhCi5ck6TkII0UY8//Mhvt4ez2vX9GBqv2C+36XK9K7pE8zQKC++353A7wdTiM8qIsTTqcn7/2p7XJWfjyTn0TvEnZNpBegNRtwcbQlwszYKiPJtx8IZ/cgoKGNEtWxSlwBXPrixH8dS8vn7SCrXylwZIUQzcHU0N4cwZZwsazhJxkm0PAmchBCiDcgqLOPr7fGU6Q08/N0+ojMK2JeQi41Ww6TegXi3s2dEB2/+PZHB4o0xPD+pW5P2X1BawU97EgHoFeLOvvgcjiTnAXDY9L1LgEuN9Xwu6+xX7347+bvQyd+lSWMRQoi6WDJO5jlORTLHSZw7UqonhBBtwHe7VNBkb6PFaIT3150CYFQnH7zb2QNw67AIAP44lNLk/f+0N5HCMj2RPs7MHBIGYAmczN+7Brid9fMQQoiz4epQR8ZJ5jiJc0ACJyGEOM8ZDEa+MjVteH5SN2YNDbfcdk1fawlcv3C1RlJybgk5prOwjWE0Gvliq9r/DQND6Rqo5jEdSc7HYDByOMmacRJCiNZkneNkakdepL5LxkmcC1KqJ4QQ57kt0ZmczizCxd6GSb0CcRqgw9fVnrjMIsZ2tZbKuTrYEuLpSHxWMYeT8xjavnFd7E6lF3AkOQ87nZZr+wXjbG+DnU5LQWkFCdnFloxT5cYQQgjRGqxznEwL4FrmOElzCNHyJHASQojz3JfbYgGY3CcIZ3v1sX33qKhat+3i70p8VjFHkvMbHTj9eyIDgAERHribyl2ifNtxODmPNUdTySupwEaroYNfu7N9KkIIcVbM7cjT8ksprdBbAidpRy7OBQmchBDiPJOQXcRj3+/Hy9mePqHu/HlILSB7w6DQBu/bJcCVPw+nWrJEjbHRFDgNj/KxXNc10JXDyXms3K0aRrT3aYe9jbQTF0K0rijfdvi62JOWX8rH/0STX6oyT9JVT5wLEjgJIcR5Zv7fJ9h0MhOAn/clAdAvzKNRpXLmbRobOJXrDWyNVo9VuaW4eT8HEnNNP8v8JiFE63Ow1fH4FZ2Z++0+3l17AgCtxpqJEqIlSXMIIYQ4j6TmlfDTXpXlmTkkjEERnvi7OvDgmI6Nun9XU8BzIrWAcr2hwe33xOVQWKbH09nOcl+oGSjJ/CYhxPlicu8geoe4U643AqpMT6vVNHAvIc6eZJyEEOI88unm05TrjfQP8+CFq7s3+f7BHo60s7ehoLSCU+kFdPavP+DZeCIdgGFR3lUOPLpWC5QkcBJCnC+0Wg3PTezKlA82A9JRT5w7knESQojzRFFZBV+a2o7fPiLyjPah1Wos2aLGlOv9e1LNbxoRVbWRhLuTHQFuDpafJXASQpxP+oR6cE3fIAC8JHAS54hknIQQopWUlOu5+8vd5JeUM3tEJEk5xeQWlxPu5VSlzXhTdQlwZcfpbI4k5zOlT93b5RaXsy8+B4DhHWp24OsS4Epybgne7ezxcbE/4/EIIURLeGpCF3QaDRN7Bbb2UMRFQgInIYRoJe/8fZy1R9MA2HF6F+ZKuduGR6A7i3r9xjaI2HIqE4MRIn2cCXR3rHF71wBX1h5Nk8YQQojzklc7e978T6/WHoa4iEipnhBCtIJdsdl8siEagKt7B+Jsp8NgBHcnW6b2Cz6rfTc2cNp4Us1vql6mZzZtYAjDo7y5a2T7sxqPEEIIcSGQjJMQQjQjg8HI6oPJuDva0TfMHSe7mh+zxWV6Hl6xD4MRrukTxLzre5NdWMbP+5LoGexW632aopOfC1oNZBSUkZZfgq+Lda5SfFYRX2+PY1tMVqUyPZ9a9xPs4cQXtw86q7EIIYQQFwoJnIQQohmt2BXPY98fAMBGq6FXiDs3DAzl6t6B2Oi0ZBSU8uIvh4nJKMTP1Z7nJnYDVFeomUPDm2UMjnY6wr2diU4v5EhyfpXA6eEV+9gWk2X5uWuAK8PryDgJIYQQwkoCJyGEaEbf7kwAsLQE3xWbza7YbBasPcHQ9l78uCeJ4nI9AK9f0xM3p5ZZtLFrgCvR6YUcTspjZEeVUcorKWdnbDYAL0/uzsiOPgR7OKLRyPonQgghREMkcBJCiGZyOqOQXbHZaDWw9qGRlFYY+GV/Eov+jSE2s4jYzCIAega78dDlnSwBTUvoEuDKr/uT2Z+QY7lu66lM9AYjEd7O3DQ4rMUeWwghhLgQSeAkhBAm8VlF3LpsB9f2C+bOM2iIsHJPIgAjOvjg66rK4+4eFcXMIeF8uS2Woyn5TOwVyKiOPi2e5RkW5c2bfxxj/bF0isv0ONrp+PeEWrNJSvOEEEKIppPASQghTH7ck8iJtAJe//0ofcM8GBDu2ej7GgxGVu5WZXrmRRnNnO1tuOOSc9uZrlewG8EejiRkF7P2aBpX9gxgo2mx29rWbBJCCCFE/aQduRDiolRQWkGJaa6R2ZboTACMRnhkxT6KyiowGIx8/M8prvt4C/FZRXXub8fpLBKyi2lnb8PlXf1bdOyNodFouLJnAACrDiSRkF1ETEYhOq2GIe29Wnl0QgghRNsjGSchxEXjRGo+3+yIZ2t0JoeT8whwdeDvh0biZGdDaYWeXabGCa4ONpzOLOLZnw6RmldiKXH7fncCD4zpWOu+V+5WZXpX9gjA0U53bp5QAyb2DOTjf6JZezSN/mEqe9Yr2A1Xh5ZpSCGEEEJcyCTjJIS4aNz1xS4Wb4zhUFIeRiMk5Zaw5kgaAHvjciitMODdzp53b+gLwHe7EixBE6isUm32xuew6kAyULNMrzV1C3QlzMuJknIDC9aeANT8KyGEEEI0nQROQoiLQkxGIafSC7HVafjftN7cNDgUgFX7VcBjLtMbHOnJyI4+3DhI3d7Rrx3v3dAHgN2xOZTrDZZ9HkrKZeaS7Ux+fxMFpRW093Fu0ryolqbRaLjKVK6XU1QOwAiZ3ySEEEKcESnVE0JcFNYfU5mlAeGeXN07iCjfdnyxNY51x9IoKK1gyykVOJnn/7x0dXem9Amie5Abdjotbo4HyS0u51BSHr1D3MkvKWf6wq3klVSg02qY0ieIB8d2RKs9v9ZEurJHIO+vOwWotaV6hbi37oCEEEKINkoyTkKIi8K6Y+kAXNrJF1ALxEZ4O1NaYWD1/mT2xOUAMCRSBU5arYb+4Z442OrQajUMCPcAYEeMKtf7+0gqeSUVhHg6svahkbz1n14EuTue42fVsC4BLkT6OAMwONILW5187AshhBBnQv6DCiEueEVlFWw1leJd2lnN8alcxvb2X8co0xvwc7Unwtu51n2YS/C2m+Y5/bpPlfhN6RNMmFft9zkfaDQabh0WAcB/+ge38miEEEKItksCJyFEm1NaoaewtKLR228+mUlZhYFgD0fa+7SzXG9u152aVwqojExdC9MOiFCB087TWeQUlbHhhMpgmYOv89lNg8M4+tJ4xnVr/TbpQgghRFslgZMQok3590Q6w15fx7D/rmVPXHaj7rPONL/p0k6+VQKjTn4uRPlaAylzmV5tuge64WCrJbuonA/Xn6Jcb6SjXzs6+rmc4TM5txxsz48W6UIIIURbJYGTEKLVGAzGRm9boTfw5h9HmbFkOxkFpeQUlTNj8XbL2kt1MRqNrDfPb+pctRW3RqPhyh7WjFF9C8Pa2WjpE6LmOS3ZFAPAVT0DGz1+IYQQQrRtEjgJIc6puMwi3vnrONMWbqHzs79z06JtGI0NB1APr9jH++tOYTTC9IGhDI70JL+0ghmLt9VYX6mkXM/GExmcSM3neGoBiTnF2NloGRJZsxX31b0DsdNp6eTnQqinU71jMJfrlevVeCf0OP/L9IQQQgjRPKQduRDinMktLufq9zeSbVpTCGDjyQyOJOfTNdC1zvudTMvnx71JaDSwYFofJvYKpKisgtuW7WRLdCY3frKNp67swowhYURnFDLnqz0cSc4DVKYIVBmeo13NcrVIn3asvn8Ebo62dc5vMjN31gPo7F+1zE8IIYQQFzbJOAkhmo3RaORoSh5lFYZab1+8MYbsonJCPZ14ZUp3y2Ksv+5Pqne/izeq0rgxXfyY2EuVxznZ2bBk1gDGdfOjTG/guZ8PceOibUx8dyNHkvNwsbfB3kZrGcvl3fzq3H+Ubzt8XOwbfH59Qz3QmdZpMo9DCCGEEBcHyTgJIZqFwWDkiZUHWL4zntuHR/D0VV2r3J5TVMYSUwD0+BWdmdAjAFcHW/49kcGqA8k8Mq5TrRmfjIJSvt+dCMAdl0RWuc3RTsdHN/Xj082neXX1UTabF7GN9OJ/03rj5mTL/oRc0vJKGd/97DvKOdvbML6bP5tPZTC5T9BZ708IIYQQbYcETkKIs6Y3GHns+/18tysBgJ/2JfHkhC5otdZAaNG/MRSUVtDZ34XxprbYl3X2xcFWS2xmEQcT8+gR7FZj359viaWswkCvEHf6h3nUuF2j0TBrWAT9wjx5889jDI705M5L2lsyQ+b1l5rLezf0ocJglIVkhRBCiIuM/OcXQpwVo9HII9/t47tdCei0GuxttKTnl7I3IceyTVZhGUtNnegeGNPRElA529twWWdfAH49oMr1Ckor+HxrLBuOp5NZUMrnW2MBmD0iot45SD2C3fjs1oHcPSrKEjS1BI1GI0GTEEIIcRGSjJMQ4qxsic5k5e5EdFoNC6b14Y9DKfy8L4k/D6XSN1RliBZuiKawTE+3QFfGVZtrdFXPQFYfSGHV/mTuHhXFjCXb2RefU2WbIHdHS5ZKCCGEEKI1yGlTIcRZOZKcD8DlXf24smcAY7uqwOivwymAmqP02ZbTADw4pmONrNGlnXxxstORkF3MxHc3si8+B1cHG4LcHS3b3DUyEhvJ8gghhBCiFUnGSQhxVk6lFwDQ3ke15h7VyQdbnYZT6YWcTCvg253xFJXp6RnsxuguvjXu72inY3QXP37Zl0RcVhGeznZ8cdsguga6kpBdREpuCf1qmdskhBBCCHEuySlcIcRZOZVmCpx8nQFwcbBlaHvVZvzr7XH1ZpvMJvdWrb29nO34evZgy5pOwR5O9A/3bHB9JSGEEEKIliYZJyHEWTmVXghYM04AY7v68c/xdMv6S71D3BnVyafOfVzW2ZfFM/vTNdCVADfHOrcTQgghhGgtknESQpyx3OJyMgpKAYisFjhV9uDYurNNoDrVje7iJ0GTEEIIIc5brR44vf/++4SHh+Pg4MCgQYPYvn17vdvPnz+fTp064ejoSEhICA8++CAlJSXnaLRCiMqiTfOb/F0daGdvTWD7uTrQO8QdgL6h7lzSwbs1hieEEEII0WxaNXBavnw5c+fO5bnnnmP37t306tWLcePGkZaWVuv2X331FY8//jjPPfccR44cYfHixSxfvpwnn3zyHI9ciAtHhd7Q6G0X/RvN8z8fQm8wAtYyvUgf5xrb3ntZFN2DXHlhUneZoySEEEKINq9VA6d58+Yxe/ZsbrnlFrp27cpHH32Ek5MTS5YsqXX7zZs3M2zYMG644QbCw8O5/PLLmT59eoNZKiFE7Q4n5dH/lb959Lt9DW6bklvCK6uPsGzzaXaczgJqdtSrbHQXP369dwQ9gt2ad9BCCCGEEK2g1QKnsrIydu3axZgxY6yD0WoZM2YMW7ZsqfU+Q4cOZdeuXZZAKTo6mtWrVzNhwoQ6H6e0tJS8vLwqX0IIKKswMPfbveQUlfPLvuQGM08/7EnEqBJNbDyRAVTqqFdLxkkIIYQQ4kLSaoFTRkYGer0eP7+qk8j9/PxISUmp9T433HADL774IsOHD8fW1pb27dszatSoekv1XnvtNdzc3CxfISEhzfo8hGirFqw5wdEUtXhtcbmeE6YgCFRQdTAxF6MpUjIajazcnWC5/d8T6UCljJNvzYyTEEIIIcSFpNWbQzTF+vXrefXVV/nggw/YvXs3K1euZNWqVbz00kt13ueJJ54gNzfX8hUfH38ORyzE+WlffA4f/nMKAE9nO8t1Zu+uPcFV727kzT+OAXAwMY8TaQXY6dRHxv7EXDIKSonNLAJqL9UTQgghhLiQtNo6Tt7e3uh0OlJTU6tcn5qair+/f633eeaZZ7j55pu5/fbbAejRoweFhYXccccdPPXUU2i1NeNAe3t77O3tm/8JCNFGGQxGHvluH3qDkUm9AgnycOTD9afYG5/DtIGhAPx2UGV9P/rnFGO6+vHz3iQAxnX352iyCqKW74inwmDE0VaHv6tDqz0fIYQQQohzodUyTnZ2dvTr1481a9ZYrjMYDKxZs4YhQ4bUep+ioqIawZFOpwOwlBQJIeoXl1XE8dQC7Gy0vDCpm6Vt+F5Txik5t5iTprI9gxEe/nYfP+9TgdM1fYMYbmot/sXWWEB11NNqpWueEEIIIS5srZZxApg7dy4zZ86kf//+DBw4kPnz51NYWMgtt9wCwIwZMwgKCuK1114DYOLEicybN48+ffowaNAgTp48yTPPPMPEiRMtAZQQon6JOcUAhHg44uFsZwmcjqfmU1hawb+mxg+d/FzIKS4jOkO1HPdxsWdElDdGo5Glm06TnKvWT5MyPSGEEEJcDFo1cLr++utJT0/n2WefJSUlhd69e/P7779bGkbExcVVyTA9/fTTaDQann76aRITE/Hx8WHixIm88sorrfUUhGhzErLVvKQgDydALVYb4OZAcm4JBxJzLR3zLu/mR99QD25ZtgOAyb0DsdFpGRThha1OQ7leZXklcBJCCCHExaBVAyeAOXPmMGfOnFpvW79+fZWfbWxseO6553juuefOwciEuDAlZquMU7CHo+W6XsHuJOemsCcuh00nVeA0PMqbQZFe/N+o9vyyL4mbB4cD4GxvQ99QD7bFqLWc2vtKK3IhhBBCXPjaVFc9IcTZSzCV6gW5WwOn3qHuAKzYGU9mYRlOdjr6hHoA8Nj4zmx87DJCvZws248wzXMCyTgJIYQQ4uIggZMQF5mEOjJOgGU+0+BIL+xs6v54GN7BBwCNBiK8JeMkhBBCiAtfq5fqCSHOrdpK9XoGu6HVqC56oMr06tMr2I07R0bi084eB1tpzCKEEEKIC58ETkJcwOKzitgWk8XUvkFoNBoq9AZS8lQ3vCB3a+mds70NHf1cOJqSD1QtxauNRqPhiSu6tNzAhRBCCCHOMxI4CXEBe3D5XnbGZtPOXsf47gGk5JWgNxix1Wnwdam6MHSvYHeOpuTj52pPlK/MWxJCCCGEqEzmOAlxgUrNK2FnbDYAu+NyAGuZXqC7Y41Fay/r4gvAVT0D0WhkQVshhBBCiMok4yTEBeqvw6mWy4eScoHaG0OYjevmz99zLyHUU5o9CCGEEEJUJ4GTEBeoPysFTgcT8zAajSTW0oq8sihfl3MyNiGEEEKItkZK9YS4AOWVlLPllFrIVqOB3OJyEnOKK3XUc6rv7kIIIYQQohoJnIS4AP1zLJ1yvZH2Ps508XcFVNYpIacIqDvjJIQQQgghaieBkxAXIHOZ3tiu/nQLVIHT4aRcS8YpqJY5TkIIIYQQom4SOAlxgSmt0LPuaBoAl3fzswROBxJzScpRazjV1hxCCCGEEELUTZpDCHGB2RqdRUFpBT4u9vQOdsdgMAKwJTqTMr0BnVaDv6tDK49SCCGEEKJtkYyTEBeQ7TFZPPbdfgDGdPFDq9XQJcAVjQZKyg0A+Ls6YKOTt74QQgghRFPI0ZMQrcxoNLIvPoeScn2jto/JKCQus6jKdQaDkffWnmDawi2k5JUQ6e3MPZe2B8DZ3oYIb+vaTDK/SQghhBCi6SRwEqIVGQxGnvzhIFe/v4nrPt7SYPCUnFvMhP/9y7j5GyyL2gK8+ecx3vrzOAYjTOkTxC/3Dq/ScrxboJvlssxvEkIIIYRoOgmchGglKmg6wNfb4wDYn5DLEysPYDQa67zP++tOUlyup7hczx2f7SKzoJSf9yXx4fpTALw0uTvzruuFs33V6YvmBhEAwdKKXAghhBCiySRwEqIVGI1GHl+5n292xKPVwB2XRKLTavhhTyKLN8bUep+E7CKW74gHwLudPYk5xdyybAePfrcPgDtHRnLz4DA0Gk2N+3avlHGSUj0hhBBCiKaTwEmIVvD3kTS+3ZmATqth/rQ+PDmhC09f2QWAV1cfYfPJjBr3eX/dKcr1Roa29+Lr2YNwttOxPyGXknIDIzv68Oi4znU+XpWMU6USPiGEEEII0TgSOAnRwk6k5vPvifQq132yIRqA20dEMKlXIACzhoZzbb9gDEZ4aMU+8krKLdvHZxWxYqfKNj04tiMd/Fx45/re6LQaIn2cWTCtDzptzUyTmYezHV0DXLGz0dLRz6W5n6IQQgghxAVP1nESooUYDEYWb4zhv78fpcJgZP71vZncJ4h98TlsP52FjVbDLUMjLNtrNBpevLobO05nEZtZxEu/HObN//SiQm/gddM+RnTwZkC4JwCXd/Nn42OX4ulsh72NrsHxfH3HYMv6TkIIIYQQomkkcBKiBWQXljH3272sO2bNND3700GGtPfik39VtmlSr0D83aouROtkZ8Nb/+nFdR9vYcWuBPqGefDD7kS2n84CVLapsgC3xs9XcnO0xc3R9kyfkhBCCCHERU1K9YRoZkajkXu+2s26Y+nY2Wh56epu9AhyI6+kgnu+3M3qA8kA3D4istb7Dwj35LZhKhP1xMoDbD+dRTt7G96d3oe+oR7n7HkIIYQQQggrCZyEaGZ/HEph86lM7G20rPy/odw8JJy3r+uFnU7LzthsDEYYHuVN10oNG6p7eFwn2vuoRWu7B7ny673DmWiaCyWEEEIIIc49KdUTohmVlOt5edURAO68JJLuQaoNeEc/F+Ze3pHXfzsKqKYQ9XGw1fHNHUPYFpPJ2K5+jZrDJIQQQgghWo4ETkI0o8UbY0jILsbf1YG7RrWvctvsEZGczihEo9EwsqNPg/vycbHnqp6SZRJCCCGEOB9I4CREM4nLLOL9dScBeGJCZ5zsqr69dFoNr0/t2RpDE0IIIYQQZ0kCJyHOgN5gpKRcD0BWYRmL/o3m6x3xlFUY6BfmYVmbSQghhBBCXBgkcBKiHun5paTmlVjmKgFkFpRy5YKNpOSV1Ni+f5gHb1/XC42m7sVohRBCCCFE2yOBkxD1uHXZDg4m5fLdXUPpF6Zagf+wJ7FG0DQowpP7R3dgSHsvCZqEEEIIIS5AEjgJUYfo9AIOJOYC8NmW05bAaeXuRACen9iVaQND0WiQrndCCCGEEBc4WcdJiDr8dTjVcvm3AylkFZZxJDmPw8l52Om0TO4ThIOtToImIYQQQoiLgGSchKjDn6bASafVUKY38N2ueNLzSwEY3cUXdye71hyeEEIIIYQ4hyTjJEQt0vJL2B2XDcC9l0UB8OW2OH7cmwTANX2DW21sQgghhBDi3JPASQjgRGo+d3y2k12xWQCsOZKG0Qi9gt2YPSISF3sbYjOLSM8vxdPZrlEL2AohhBBCiAuHBE7ionAsJZ+TaQW13mYwGHl4xT7+PJzKbZ/uJC6zyDK/aWxXP5ztbZjcJ8iy/aRegdjZyFtHCCGEEOJiInOcxAVtV2w2/1tzgg3H03G20/HvY5fh6Vx1btLKPYnsS1Dd83KKypn92U5iMgsBuLybPwA3DArl862xAFzTNwghhBBCCHFxkcBJXJDK9QYe+24/K/ckWq4rLNOzNTqTCT0CLNcVlFbw39+PAnDb8Ah+2pvEsdR8AMK9nOjg2w6ALgGuPH1lF0orDPSotBiuEEIIIYS4OEi9kbjglOsN3Pf1HlbuScRGq2HagBCu7KmCpS2nMqts+/66k6TnlxLu5cSj4zvx8c19sdWpBWzHdvWrspjt7SMiuefSKFngVgghhBDiIiSBk7iglFUYuOfL3fx2MAU7nZZPZvTn9ak9mdgzEIAt0dbAKT6riMX/xgDw9JVdsbfR0S/Mk/9N68PwKG9mDg1vjacghBBCCCHOQ1KqJy4YpRV67vlyD38fScXORsvCm/sxqpMvAIMjPdFo4GRaAWn5Jfi6OPD19jjK9AaGRHoxuouvZT8TegRUKecTQgghhBBCMk7iglBSruf/vtjN30dSsbfRsmhGf0vQBODuZEcXf1cAtkVnYTAY+cE0/+mmwWFSfieEEEIIIeolGSfR5pWU67nri12sP5aOg62WRTMGMLyDd43tBkd6cTg5jy3RmXg625GcW4Krg02VbJMQQgghhBC1kYyTaPMWb4yxBE1LZtYeNAEMae8FwNZTmXy/OwGAq3oF4mCrO2djFUIIIYQQbZNknESbZjQaWbEzHoAXJnVjaFTtQRPAwAg1zyk6o5DEnGIApsqaTEIIIYQQohEk4yTatN1x2ZzOLMLJTsdVps55dXFztKVboJrnVFphINzLib6hHudimEIIIYQQoo2TwEm0ad/vVg0exnf3x9m+4QTqkEgvy+Vr+gZLUwghhBBCCNEoEjiJNqukXM+v+5IAuLZvcKPuY57nBDClj5TpCSGEEEKIxpE5TqLNWnMkjbySCgLdHBhcKZNUn6HtvRnd2Zco33aEeDq18AiFEEIIIcSFQgIncd6LySikqKyCboFuVa5faeqMN7lPEFpt40ruHGx1LJ41oNnHKIQQQgghLmxSqifOa2UVBv7z0WamvL+Z+Kwiy/UZBaWsP54OwDXSGU8IIYQQQrQwCZzEeW3n6SwyCsoo0xtYaWoEAfD9rgT0BiO9gt2I8nVpxREKIYQQQoiLgQRO4ry27lia5fLKPQkYjUYMBiNfb48DYPrA0NYamhBCCCGEuIjIHCdxXlt3LN1yOTaziN1x2ZSUGzidWUQ7exsm9qp/7SYhhBBCCCGagwRO4rwVn1XEybQCdFoNl3X25a/DqXy/O5GcojJAtRNvzNpNQgghhBBCnC0p1RPnrfWmMr1+YR7cMjQcgF/2JvHnoVQAbhgkZXpCCCGEEOLckMBJnLfMZXqXdvJlcKQXgW4O5JdWUGEw0jfUnS4Brq08QiGEEEIIcbGQwEm0qsyCUp5YeYAjyXlVri8p17P5VAYAl3b2QavVMKVS2/EbB4Wd03EKIYQQQoiLmwROolV9uiWWr7fH8cA3ezEYjJbrt0ZnUlJuIMDNgU5+qt341L7B2Gg1eLez48qeAa01ZCGEEEIIcRGSmfWiVR1MzAXgWGo+vx1MsQRE646q+U2jOvmi0WgAiPRpxw93D8PFwQYHW13rDFgIIYQQQlyUJOMkWtWhpFzL5fl/H0dvMHIwMZflO+MBGN3Zt8r2PYLdCPd2PqdjFEIIIYQQQjJOotWk55eSmleKRgMu9jacSCvg8y2n+eTfGErKDYzs6MOl1QInIYQQQgghWoNknESLMhiMlFUYar3NnG2K8HZm9ohIAJ7/5TCJOcWEezmxYFofdFrNORurEEIIIYQQdZHASbSoGxZtZcQbayksrahx26Ek1UmvW6Abs4aF4+5kC0A7exs+mdEfN9PPQgghhBBCtDYJnESLKSqrYGt0Fql5pTXajYM149Q90BUXB1uevKIL/q4OvDu9Dx1MnfSEEEIIIYQ4H8gcJ9FiYjOLLJej0wvpH+5Z5fbKGSeA6waEcN2AkHM3QCGEEEIIIRpJMk6ixVQJnDIKq9yWV1Juub1boOs5HZcQQgghhBBNJYGTaDGxmdZgKSajoMpth03ZpiB3Rzyc7c7puIQQQgghhGgqCZxEizldrVSvMnOZXlfJNgkhhBBCiDZAAifRYuKyrMFSbGYReoPR8vOhRHNjCLdzPi4hhBBCCCGaSgIn0WJOZ1gzTmV6A0k5xZafrY0hJOMkhBBCCCHOfxI4iRZRWqEnKVcFSt7t1BymU+lqnlNJuZ6TpsvdgiRwEkIIIYQQ5z8JnESLiM8qxmgEZzsd/cI8AIgxddY7kpyH3mDEy9kOf1eH1hymEEIIIYQQjSKBk2gR5vlNoV7ORPq0A6yB0+ZTmQD0DnFHo9G0zgCFEEIIIYRogiYHTuHh4bz44ovExcW1xHjEBcI8vyncy4lIb2fA2llv/bE0AEZ19m2dwQkhhBBCCNFETQ6cHnjgAVauXElkZCRjx47lm2++obS0tCXGJtow8xpOYV7ORPqowCkmo5DconJ2xWYDMKqjT6uNTwghhBBCiKY4o8Bp7969bN++nS5dunDvvfcSEBDAnDlz2L17d0uMUbRBsVnWjFOEtyrVS8wp5o/DKRiM0MG3HSGeTq05RCGEEEIIIRrtjOc49e3blwULFpCUlMRzzz3HokWLGDBgAL1792bJkiUYjcaGdyIuWLGmxW9DvZzwdLbD3ckWgGWbTgNwqZTpCSGEEEKINuSMA6fy8nK+/fZbJk2axEMPPUT//v1ZtGgRU6dO5cknn+TGG29sznGKNqRCbyDeknFSZXoRpnlOh5PV+k2jOkmZnhBCCCGEaDtsmnqH3bt3s3TpUr7++mu0Wi0zZszgnXfeoXPnzpZtpkyZwoABA5p1oKLtSMopocJgxM5Ga2k3Hundjj1xOQC0s7ehf5hnK45QCCGEEEKIpmly4DRgwADGjh3Lhx9+yOTJk7G1ta2xTUREBNOmTWuWAYq2J9bUijzM0wmtVrUbNzeIABjRwRs7G+mEL4QQQggh2o4mB07R0dGEhYXVu42zszNLly4940GJtu20aX5TmJc1WDKX6gFc2knmNwkhhBBCiLalyaf909LS2LZtW43rt23bxs6dO5tlUKJti80wtyK3ds2rnHEaKfObhBBCCCFEG9PkwOmee+4hPj6+xvWJiYncc889zTIo0bZVbkVu1tHXhekDQ7hvdAf8TPOehBBCCCGEaCuaXKp3+PBh+vbtW+P6Pn36cPjw4WYZlGi7DAYje+NzAIjydbFcr9VqeO2anq00KiGEEEIIIc5OkzNO9vb2pKam1rg+OTkZG5smx2HiAnM4OY/0/FKc7XT0DXNv7eEIIYQQQgjRLJocOF1++eU88cQT5ObmWq7LycnhySefZOzYsc06ONH2rDuaBsCwKG/sbXStPBohhBBCCCGaR5NTRG+99RaXXHIJYWFh9OnTB4C9e/fi5+fH559/3uwDFG3LumMqcLq0s3TOE0IIIYQQF44mB05BQUHs37+fL7/8kn379uHo6Mgtt9zC9OnTa13TSVw8sgrL2GOa3zRKOucJIYQQQogLyBmtQurs7Mwdd9zB+++/z1tvvcWMGTPOOGh6//33CQ8Px8HBgUGDBrF9+/Z6t8/JyeGee+4hICAAe3t7OnbsyOrVq8/osUXz+vdEOkYjdPZ3IcDNsbWHI4QQQgghRLM5424Ohw8fJi4ujrKysirXT5o0qdH7WL58OXPnzuWjjz5i0KBBzJ8/n3HjxnHs2DF8fWuWepWVlTF27Fh8fX357rvvCAoKIjY2Fnd39zN9GuIs5RaV4+pog0ajscxvkjI9IYQQQghxoWly4BQdHc2UKVM4cOAAGo0Go9EIgEajAUCv1zd6X/PmzWP27NnccsstAHz00UesWrWKJUuW8Pjjj9fYfsmSJWRlZbF582ZLhis8PLypT0E0k/XH0pi1dAfDorx4+z+9+ed4OgCXdpLASQghhDivlRWBnVPD2wkhLJpcqnf//fcTERFBWloaTk5OHDp0iA0bNtC/f3/Wr1/f6P2UlZWxa9cuxowZYx2MVsuYMWPYsmVLrff5+eefGTJkCPfccw9+fn50796dV199td5grbS0lLy8vCpfonlsPJEBwKaTmYyZ9w/ZReW4ONjQN9S9dQcmhBBCiNrFb4fn3eDVADCd/Ba1OL0JfrwHSnIb3lZcNJqccdqyZQtr167F29sbrVaLVqtl+PDhvPbaa9x3333s2bOnUfvJyMhAr9fj5+dX5Xo/Pz+OHj1a632io6NZu3YtN954I6tXr+bkyZPcfffdlJeX89xzz9V6n9dee40XXnihaU9SNMrJ9AIAnOx0FJRWAHBJRx9sdGc0dU4IIYQQLW3/t9bLZQVg71L3thezZRPUd0MFXPNx645FnDeafISr1+txcVFvMm9vb5KSkgAICwvj2LFjzTu6agwGA76+vixcuJB+/fpx/fXX89RTT/HRRx/VeR/zmlPmr/j4+BYd48XkRKoKnD6+uR83DQ7Fxd6GaQNCWnlUQgghhKhTWYH1cmF6642jrYjZ0NojaFhOHJQXt/YoLgpNzjh1796dffv2ERERwaBBg3jjjTews7Nj4cKFREZGNno/3t7e6HQ6UlNTq1yfmpqKv79/rfcJCAjA1tYWnc66sGqXLl1ISUmhrKwMOzu7Gvext7fH3t6+0eMSjVNUVkFijnqTdg90Y0QHH166urtlrpsQQgghzkMFlY67CjPAs/HHbheNykHIiLmtN47GSDsKHwyC8BEw69fWHs0Fr8kZp6effhqDwQDAiy++SExMDCNGjGD16tUsWLCg0fuxs7OjX79+rFmzxnKdwWBgzZo1DBkypNb7DBs2jJMnT1oeH+D48eMEBATUGjSJlnMqrRAAL2c7PJzVay9BkxBCCHGeK0izXpaMU+2yYtR3BzcYcHvrjqUhe79Q30//K3PWzoEmZ5zGjRtnuRwVFcXRo0fJysrCw8OjyQfOc+fOZebMmfTv35+BAwcyf/58CgsLLV32ZsyYQVBQEK+99hoA//d//8d7773H/fffz7333suJEyd49dVXue+++5r6NMRZOpmeD0CUb7tWHokQQojzyvZPID8ZLnsG5ITa+adKxkkCp1plRavvnpFt4G+40vjyk8E1sPWGchFoUuBUXl6Oo6Mje/fupXv37pbrPT09z+jBr7/+etLT03n22WdJSUmhd+/e/P7775aGEXFxcWi11qRYSEgIf/zxBw8++CA9e/YkKCiI+++/n8cee+yMHl+cOfP8JgmchBBCWOgrYPXD6nLXqyGgV+uOR1Slr1DleWYSONWunS/0mg6uQZC0B8oKIXx4a4+qdu0qLQGTfkwCpxbWpMDJ1taW0NDQJq3V1JA5c+YwZ86cWm+rrb35kCFD2Lp1a7M9vjgzJ9NU4NRBAichhBBm+UnWy3by/+G8U5QBmMq5OowDj4hWHU6zyEsGZx/QNbmIqm4hA9XXwZWwcJQ6AXBnA00i8lPByat5x9EYQ++F2C1wbBVkHIf2l57bx7/INHmO01NPPcWTTz5JVlZWS4xHtBHmwCnKV9qYCiGEMMmJU98924NX+9Ydi6hJZwejnoSh98GN30KPa1t7RGcncRfM6wzf3dIy+w8ZpL6nHFRZp7pE/wNvd4K/nm2ZcTSkz01wxZsQOap1Hv8i0uSw+L333uPkyZMEBgYSFhaGs7Nzldt3797dbIMT56eyCgOxWUWAlOoJIYSoxBw4uYe27jhE7Zw8YdQFNL1Br9aQ5MjPqjFCc81HyopRZXpuQep7XiIk7oaIEbVv/8eTgBG2vg+Xvwzac7SepcGgnnPnCefm8UTTA6fJkye3wDBEW3I6sxC9wYiLvQ1+rtLqXQjRAkrzYd1r0Gk8RFzS2qMRjWUOnNr5QW6iOvAU59aRXyF6PVzyCLj41b2d0ajabts5nbOhYTDApndUiWD3a85+f4G9VRZNX6YaOjRHlrOiFN7tqy4/dFyV7B36AeK31R44GY2qKYNZ8l4I6ltzmz1fQG4CXPIw6GzV9eUlsO4VldnqclXTx5q4Cz6fDKFD4Kbvmn7/c+3kGojdpLKe57qksZk0edTPPfdcS4xDtCHmxhDtfdtJC3IhRMv4aQ4c/hH2fQWPnW7t0YjGMgdO+7+BhO1w357WHc/FxGiETf+Dv03HaSf+hJtWgneUdZucOCgrUmVny64EO2d49NS5G+OhlbDmRXW5OQInG3sI7KOCmoQdZxY4HVwJx36DrpOgy0T1GhkNYOsMzt4QbA6cttd+/8J0NceqKFP9fHJNzcAp4wT8bJrP7+QFg+5Qlze8CZtNS/k8lQK2jk0be1a0WtC4okRlxDKOQ6cJ4ODatP2cK1+YfudOXjDkntYdyxk6R7lEcSGRxhBCiBaVeUoFTQDF2eostTj3ygrVQXZThAxUZ79BHYDqy5t/XKImgx5+e9QaNDm4Q04sLB5rXZMIYMv7arHUnYuholgd7JvL3WqTlwzFOVCUpb7O1v7l1stN/duqjTkTBNbv1enLoTCz7n1Er4cD36rueVCzFbl5nlPC9trXSWrnC/dsg9Gm+U0x/9Tcxqej9X2x/jX1mkLVAOfoqqr3KcxoeF0my1gjYPnN8MOdkHYYKsrg8E/qcSov5ns29OVQktfwdnlJaq2wbQvh37et11d+LtHrm2dMraDJgZNWq0Wn09X5JS58J9JkDSchRAsyT7COHAXP5567+QLCqiQPFvRVB96GJnTS7TcLZq0GG0cwVEBufIsNUVSy9QPYvhDQwLjXYM5OCOwLkSPBPcy6nXkNJ98ualuMUFxPQLT+NfhvGLwRATsWnd0YDYbmb4UeXSlIqSsj9OV/4J2ukHGy9ttTDqjv/j3U98rBiPl6Gwf1PiiqJwDrMwNu+h5uXGG9rnKwMPNX8O6kXu9/31LXDbsf+s5Ul/d+Zd32nzfgzfZw8Pu6H6/KWCNVcAaqJXn8Nvh2hul3F6kCqbP10z3wVgdIP173NvoK+HyK+uz47RHY8Jb1xJdGAzN+VpeT97XZxXqb/N/ohx9+YOXKlZav5cuX8/jjjxMQEMDChQtbYoziPGPJOPlJ4CSEaGanN8LRX0GjhfGvt/ZoLl7x26AgBVIPQvS6pt1Xq7UedJoP7ETL8mwP/W6BK96AIXdDOx+Y9StM+bjqiYeCNPXdNVA1ioC6AxijUZWdmaUfO7sxarUwe63158pB1JkqzbdeTjtce0bEI1yVsu35rOZt+gp1P1DPdcNb1r9Zc9mfjR0MuB1uWK5K9yqrKFNzokC95lFjrOV2pzfBxyMgxtTGXGcD415Rl7d9bH2c4Q+o79HrVLYm+7Qq4QPV9KI+2aZsomekCspAleud/Nu6TXmRNTg8U2VFKltYUQI7l9S93e5PIf2o+vw2P3ZegvX20MGqBLIgVX22tEFNDpyuvvrqKl/XXnstr7zyCm+88QY//9zAL1i0eXqDkegM1ZIzykdakYuLRMoBlQWp/E9aND+DwdSdCpW58O2iLrfRM5NnbPfnsG95w9udjexY+OOpusuvKp+9P/Rj4/ZZXqwaQhj01vWBKpeJtRVHfoUVt8CKWepr+yetPSIrg0EdVEdXKwfrPAEmzrfOnQE1f8mmWgMnc8apnZ+alwN1B07px6oe9GacZeAEKusQ0Lv+x22Kyp/JRqM1CKosaoz6vm95zbLErFMqGADY87nK3GWaMlOekdbtxr0CYUOtP2ecUL+Lk3/Df8Ph1wer7tf8WZZyoOr7J2oMtL9MNbP4dqb1cUKHqnlV+76Bv19Qt4N6H9b3+Vdrxulo1YAXVJnh2bBzUsEj1J1FLsyEda+qy5c9DT6mz29zhqogTX02mJv9VA7u2pBmq38YPHgwa9asaXhD0abFZxVRVmHA3kZLkEcTJzEK0VZ9NU1Nuv7lgdYeyYWtKBNcAsGns+q6FLsFPhyuSj8uFnnJahL5D3dY50G0hMWXw5b34Pcnar/dPF+kw+Vw1TuN22fCTlUS9cHgs8s45SaquTgF6SoY2/6JGue5mOumr4Bf7ldNDA79oL5WP6x+L+eD47/B2pfhs0mN2z4vSWUIdn2qfi4wBStVAqc6Mj/mA1tzqV/GiaaVbVZWlAWlqlqFCW/CbX9B2JAz21dlZaZ9XvIoPB6rMhrlJfDpJDhsalHe4XLVjKAgpWb21JyJCewL9q7qM+iUKStWOXCqLPUQfHKZWjvq2CqVVdHorM/zz2fgRQ/VXc/eFUZVeo9pNKpduUanAlNzBrD3Der71g/U3x4atU1RpnWb6opzrKWDHhHWjFPMBkg9oPYx2NSAwfx+LsxQ76czma/W3bTmV23BXPZpWDJOLbDs1QH631I1kAP1Pno10Bp4VQ/u2ohmCZyKi4tZsGABQUHSdvRCF2PKNkV4O6PTSke9i46+ov5FAC9ERqP1rOvB75p+8Fac3fxjam4JO2HpBPjLNLG8OTI8ZYX1H2TpK9QBTmXtfOCGb9RE63Y+YN9OHQAk7r54sk6Vz+q35N+O+exxXmLN2wx61eYYYPRz1tbJ1ZnbWZuZO+q5BloPOs8kcNr3tTpb//2toLWB3x9XB5S1jbWxygob16hCZwP37lQZz/GvqzIvqHnGvjBDNTHJPNW035O+vP5mDA0JG2a9bA6si7LUnJHami2kH1XZkM0L1O+qNFdd387XWnZWV+bHHDgNuE21/K4osf6Om2rzAnirI2z9SDUQCRkIDm5ntq/KSk2leaGDrPvb+oFq0PD742rMNnbQ4zp1294vq94/Zb/6HmSaDwZqPlPP61UAUJvMU+q1PPyjajEO1qyWraO1Sx7AiLnqs6wyv25w6x9w25/q9wDQbTLMXgfXf6kyNX1ugjv/gScS6m4pX14EHa9Q2Sr7duBjCpzM2arAPtDpCnXZnEHe/60KYL6eXvs+6xPYW70fC9NU4xGzpL2waCxkngC3EJj2pfrMsJQOmj7T0o8DRvXe6jsTBv9f08dwHmhy4OTh4YGnp6fly8PDAxcXF5YsWcKbb77ZEmMU55GEHPVPMsTzHK77IM4fn14Fb3eG1FrKIS5U+dXONJ/+t/H33fqRKuPY+lGzDqnZZRxXa2vs+wY+v0Z1YzobJbnw8Uj4+b66t/ntUfXa1FfK5d0JtLbqYO9MD9jaGnNZS6cJ1qxNSzDv21jLiYC8RFXmZediLZes7YTB9oXwSgCc+Ev9bD6T7B6qDrJ6TYeO45o2LqPROkm+13R1AOZpmmtypqViWdHwTjf4bHLjAnBHD5j4P3Vg1360uq5y6WLsFngzSq31825f9b5pjPxUeKM9rLy9yU/BOjZ36+LC5jkiJ9fAx5dYWz1X5mdqeJB5yvpes3FQmZDgAdDpSnALrnm/skL1mQDQcTx4mVqaZ9TTGKAu5cWw92soLwTXgKbfvz7mUj0709SBgjT4d566PPo563yj3qZA4eiqqoFucY7K7Pj3sAY/Ab3hmoV1ByxdJ8HNK9VrCCqoDB+uLts6Wl8rgEF1BAchA9R7xMzeRQVvoYPgro0w/jVTU4p61sp0DVQnmm79Tf3s7A2Ontbbo8aofWp06j2dm2B9b/W4Vn1ON6bjXuYp+PI6dUIjoJe6zvx+KCuEL69VwZRfd5VJNAdw5u/px9XJAnMJZIexMGkBdL6y4cc+DzU5cHrnnXeqfC1YsIBff/2V2NhYJk1qZOpYtFlJpsApyF3K9C46FWUQt0Wd4XPyau3RnL1jv8HKO6wTd+tSeVLt6OdUGVljFKTB74+py78/dn5n6sxBSUEKnFqj5nOZJzxX15gDz9J8VRN/+Ke6/zGXFah2yJUnP5fmV92/jZ31wP1sJze3FebgwHzQUZ+iLPU3fGqtet30FY3PiJoPvmsLSN1D4aFjcN9uNcl73Wswv0fNblq/PQoY1YFT5X25h0JQP5jyEfS/tXHjMYvfruad2DpDF9MxReUDsDPx17PqYDl2o8rM1KW21y5koGlclVpdH1gBGEFnrw6e68rIVZd+VJ0EOPTD2bXi9u+pvpvfE+a/Ge+ONbdt5wMuAWq82TFw6VMwZI4qGRtyD0z/Sq1dVN3pTSpz4Rai9mve95k0iNj6gfpscQ1SQVj6cXUy6dAPTd9XdebAyd4F1r+uur6V5atsS4//WLfz76kO7PVlVTvVTVoATyaqbc1BcsL2hrOIEZfArb+r/Q66S2V8zK54QwVPN/8Atg5Nf046G/V8zsQVb1gvR41RJ0D8u6ufdy5RGXydnZoL9lYntYZVQ07+DSf+UNuGDAI0ao4kqP3fs12V896yumpgbP6byTimSvkM5arbplvomT2380STF8CdNWtWCwxDtBWJ2RI4tSmJu+H4HzDiIXUQejbyk6yXzeUFLaE4R80n6jcLPMIa2rp2WTGwa6nqMlXXWfvjv6suQY4e1smq385QZ4UDe8OwB9Q/AVtH9Q/IK0qVXZgZjWotFK0t9JtZc//rXrFevmuT+gdTH6MRNs2veubzXDH/ExzxEOz5UpVhbPsYht1nHdv2T+DoL+rs44yfqy6qWZ1rkJooXJavDsA61PJ8XE2l3ZVLuRZfrs6M3vCtmqsA6sAkZb86SOxyFSTvV5kOQ4U6aJ3wRs19nw8MBtj4tsqadW3CSUXzgal3JzUnpPIBWXUHvlN/w2lH4M5L4Zf7VCnY1e/X/37/+gYwmsoo8xLVfaof/Gs01vd58j5VrrrvKxjzvHUbra06GDIfrFkCpzN834K1lKrbZOtz9+kERzizjNPpTXDkl0r7/6rqmf7KNr4Nx36HSx62ljhFjFQHhSGmv0ejEU6aMmzXfQadxlfdx7aPofvUmt3XQH3OtPNXQUTSHggfVnOb+pTmw5IrTPNXsAZO6Q0E2/49VOY8PxlGPtq4xwrsrZ630aj+FjqOV3OizBkHfTlsfEe9PqGDrPdLOwp7v1CZFregmhkgG3tI2q1OJkVeCt3Ocv7iXZvU6+IRBrsrdc0b92rVboIajQpwMo6pMVdmzkrZOYNdO3VS5+QalZWpj183uKuWCoSo0XDvrjN7PpVVlKqS1YSdcMtv6mTUsd9V5mbgHeoz0NZRPTeznv9Rwf6pterkBajA2Kezde5Wpwnq87eiWL0f+txY/zjMJZtRY6D3jWrOVuX1p5w8az9B4tMJbv0TvDuok66gLmu1pnLg3RC3GYbeV/U5nOeanHFaunQpK1asqHH9ihUr+PTTT5tlUOL8Zc44BUrg1DZseQ/+eR22NUOpWJ4pcPKIUB9y+anqgKQ5FjGsLHGXmku08o6Gt63r/ovGqOBr0/zat0k/bn0+5n8K2bEqQxK/Vb1e5jKViEvU2hxX/Nd6/4oy+OEuWPWQmkhunnBtlnrI+k/8lt+tZ/zqE70e/n4evphqHdu5Yj7g9ekClz2lLu9aar09N0GtyRGzQR1o7/uq5j7M8lPVP8Woy9TP1TsnGY0qqDCvmZJiKjcyl3KU5KqJ62aW7Q6og7XvblHdr/Z9bV0k93xUmqfmcP00B9b/t/FztMylUD/epdbOqW/9FXOQ0ftGFVzuX64W8vzy2roXqixIUxPaj/+ufjYaas4dqj7Wnqb5IeaSPDNzYBM+Qn03z3swZ7P05WrtnPoWH62srMiahTBPlgfrXImmZpyMRvjzaXXZ/Hd04Nvas6nmEsHEnVUnzrsGqINCv67q58xT6v1SuTzLbNtClYVbPLb2uV0ajTWDdSZdzlIPWYMmsM7PMf/NeNcTOEHtWdvq89TM2vmq5z3gNvVz7+lw5VvWeUDbPlYnh5ZcXnUu4+qHVRc58zybda+qQCSwrzUDZJlb1QztyF0DVBMCG3vrekhhw6p2wDPre7NqzOBdx9wlsJaWJuw4+7GdLZ0dHF2tmkwk7VGfrctvgj+fUu/xJePg9bCan7EeYao5g86UG7nkEZj0nvVzvveN0GsaoFFZ2PrKpctLIMYUHEaNURlMc9DUUKMQG3sVVDt51gzuK0rU/3nfrm1u/mqTA6fXXnsNb++aZ1J8fX159dVXm2VQ4vyVaC7Vk456bYO5zKmhcrTaVD+4yDUdXJnr4ReOUh/i5tXWm4tHuPqAT9heNYAwGBqe3H38D1h2lersA3UveBi9Hk78qS5nnlT/OE5V6/BT22KK5aY1LF72gf3meQ1G6wEMqH8CfzylDki7Xl21c1TyfhWE5CbUDDgrlwKtfbna4zbTyu+gXsfq//Aql1iZy6Oyoq0BYfUDrn3f1P1P86e7YZ55cU1q/lOP3w4Lelu7W6UeUvvKiVUHWzYO1gNvqHrQt3Op+n05ecHYF9UBwblQUdr0f+6O7uqAoTQX1r+qAuyGmgIYDCpL2vVqNS9BX1b3nJLUQ+qASmurDkgDeql1Zmyd1cT4pRNq7wRnPusc0Ms6F6NyuV5BOrzdSb23zb9jv+7W7cyvQ1mRtZzJLUg9N/NnhPn3t/wmeK8fHKk2Z66iFI7/qTIWlR1dpQJO9zA14d2seneuxtJoVNak43i48TtVonbDCnVAWl38NvU3b+usXv+6mP+eQ4fUzAa2v1Q996xoNVk+sVrWoSgLgvubHu8MAifz+9DXFMSlHVW/B/PckfoyTqDarKcdsQbVibvVHLUPBlfdvjGd8/ZXapdv/v+SHavmgObGqyYCqYfVuj5QNQNk6eZXR7e4MzX0XpiyUGWsG2I0wub34JPRqv2/2dUfwNTFMPrZ5h3bmdBo1FwoUH+fLn6qIyGo93jKfvX50pjS+ZN/qQ587fxUO3S3YLXAOKjKidwEddKqurjNKjPVzl9l2Cr74yn1d36qEeu8VQ/u7ZzVycgOY9vcAudNHm1cXBwRETVLX8LCwoiLu0gm716kyvUGUvNUF6xA9zOo2xXnnrnkK25r01YO3/wevOKvDm7MzJ3lzCVWlT/Qm5NXe3VQYjRY/zkbjSrT8N/wupsExG1VnYLKi1RZgl27uuvLK69NAipoMrdG9TX9c4jfpl6zytmk4izreh0andrWs33VwCZ2kwoKdHZVy5p+f1IthvhON/U1rzPkp1hvr3wgZdCbAsUK+HWuauHamFr0xvj9cbU/89l7fYU14+Aeog74zetvmM+Kmw/Yul0DDu5q+5hK68gYjepMfF6SOjAvTFOllhqd6rSUfdq67V5TKWBFqTpIrShW97WUqHUArc66vX931d3Kp6M1oLz0KRh2PwycbX0Opzc1z+tTXfI+eDUIfnus6fcdcg9cOU/NE9r9qcra1UerhUufUCVgoaaAu665XeZJ3h3HgbPpwClqDNyySh2Yph6AzyfXnLdTuezmqnfUZO7AvtbbE7artX4yTlp/D+4h6ntpHpTkqMuVs1SHflB/V0PnqDK1dv7qestaTpWyL7mJsOxK+Oo/KsNa+eRI2mH1vul9Q9WDKa8OgEa9/xqbvTIL7K0CShd/tRZPyIDay4LM2buuV9cMiPJTYMciNS/HIxw6jIPOV9Xch3cHuO1vVV5alAGfXl11vJ9OUvOtoOH1eWpjPkHT6QpVHnnzD6a5IxXqvVRbkwewzokqylBB0tYP1M8Obur9Vznzk3kK/tdbBRPVx1eSp4LB0gJVdmdm/ls0N8mIHKX+ZvRlqsFH9RNIzqYS0MKMxs/Jq+21KkhXberNi8XaOUGv6+svbwV1AuvTiep+iTvV35WZrYMq0WuotPpcCTGVQZozYP1vgTvWW19DsL7P6lOSpwLuntdZM1G9TSV6m99V/5M2v1fzfuYsc9QY6/tm/wpYeCls+1B9XtR3QjNhp/odZZ+G3jdZS7DbsCYHTr6+vuzfv7/G9fv27cPL6wKYMC7qlJJbgsEIdjZavJ3r6fQiWl95MZzeqP5hOnmruSaNLQ3JTVClAEZD1RXCzWeTXQPVd/MH+pmcOa1LaQHEbbOe8d37lfqHeeIvVZZVVqCySrXZ+qGat9FlEtz5r2rjetP3tW9rPlhzcFffj/1mXVDyUtOaGykH1NnTt6JUdg3Ucx94pzqQu/1v1f3ovt1q7o1ZYF+YtQr+s6zqOiDO3mpirM4O0Kize8dWq9sMBvUPBtRB8zUfqwOa5Teqs4FGQ80yqTNRlAXbP1ZlEntMpYTms5A2DtYD3uoT4s0HbMH9rXX/lecTbF6gDsh+uV+NNXSI6uZk3o85KK1citXnZusZzJT9lSa4Vztr7uCm2kP7dFZnV306W0tyQB0QfDRMHQil1ZOR+PVBNX+rqaWlh39S83i2f6zO0DeGwaBKbArSVanTf0xn3XcubXyTi/rKq/Tlqq0wWA9+zAL7qGDI1lllaCpnQw166+8iaowqQw0ZWPVA0/x+Np8YATWPwnygZj5xUfk99Mv9KrAYeh9cu8Qa9FhaklcqBTq1pmoZVOXPjzHPwWOnYfDdVZ+TnZN6vz0aYw0Sm1NZERw0/13WMt8jK0aV5W6cpwLVG7+tutBsZS5+apK8R3jNz93KJ32KMpreqt1c1urfEwbdCREjVCMNUEFbXfNEPCLUvERzMG6eu2bO/JQVWN8Xfz8HuXHq87b6/j6+RK1flLRbzVu83ZS9PPKLmptauXQUwNZJZUbHvlR1P+YMiVFvDcTrE7tZfQZXX88oP1kFgU1doDhmg/psNz+2+b12Pgo2fYYeW20NHgP7wO1/qTlMXa9WJ7saYn6uAyv93Xa5Su1DZ6e+Kp+wAnVCytxIwzznD9TfbpLps9CcwapL2hH1O7Kxh8nvq7/ZNq7JgdP06dO57777WLduHXq9Hr1ez9q1a7n//vuZNm1aS4xRnCcs85vcHNDKGk7nt6Or1Fndz65WE1Wh8at0r6n0T05fKUvl1V7NZTAf7Jo/0BPqOHOaE6e6cdU116I2ibtUzfyGt1SQkXFcHViZ5ylA3eU613wC4/+rzvDb2NU/2dQcBJqbOpz8Wx3kOHmr9rwugeqfujk4qHx2b8Ib6kA+qG/tJQZ2TmruQ/VWqyPmwtMp8Ey6ypiA9SA245gKCmyd1eMDrH3FOg/FvE1tDKYA95cH1NevD9adfancTcp8EOLiBw8dUYGm+flEjlQH1ubMk/ng3b+Hde7JoR9UoGIwqANhfZm1/NG8jeVvz/Q8j/xsKsUKVfMQLMHBfmsGrLZyI4NBZSMALn/FesYUVL29V5T6fX1/m/V1OLrauk3qYdNrdH/NssdTa9VrZr6f+ey5WeUD+z+ealyWIPMEfDMd/tdTHXx0naSydRjVZO+69pFxQpU7VZkDVvNEJSfXqKyek7cqdanOM8I6F6Xy+z55rzq7bm5FXRtL4DSo6vXVu/BFjlR/M3dtNI3VWLNkp7a1nGor3azMzrnqxHOz4P6q9NGsKEu9R3ITam4L8PO9KtipPn8j5YD6O6h8Uujor+r9X71E0My8fk1BauPa4tu7QJCpJM+cSS3Osa6h1GWiOnHQkFPrVEBqzj6b3wOVD/R9u6qy1f631L0frVb9vsyf5+Y5hPYu6oQJqLWczI00NFo1F6g6S3dD03MK6qtOdFQUq4xsTqxqC27Oxvl0VGsRVW/yY2NnPWlV1xpSZsd+U23kk/eq+VJQqVy0wPo8mmLg7KpZGr/zOHAK6Gm9/PMc62WPcJi9Vp1oa4zB/wd3b6laBm3rqPbxTLr6GvV41fsUZaoyXWdftYiwmfmEGFTNYNXmbDtinoeaHDi99NJLDBo0iNGjR+Po+P/t3Xl4U2X2B/BvkrbpvtGdfd8psiMiIpVFBgVRUVFxGRUFN8BxdFRc5jc46LiMOjCDC86owKCCOw4giCg7IouAFEGWUtpSutC9zf39cXpzkzRrmzZp8/08T5+kyc3lDb1N77nnvOcNQ1hYGMaOHYvLL7+cc5xaOM5vakbUK3/tR2jleu4ETqd3a3N3rngWuOo17blh9wK3fa5lHFL7STve0nP2r5wuv0kaU6z5Y93nHFFP0NsP1zqR/bTMei6Loyv2QSHAsJl1Fxu0Ry3V6zbBOijqMkZOMtSr7WrzAVdXJNWGB+5SA4pfv5VywIRucgI6dYn2R+iyP0pGYNKr8n3uL3VPuKsrgVV3y4n/rnck0AsKkwyJPZbrzdj+P1p2VeszVbJ1/W+UEz510n9yH8moqXMsdrwp/1/XvastqBocAfSaXLufa4Hr/wNMWSQn+1/Mlcf7T5fXDbsXuGeTBJLOWirr9cDNH0tnKXsd+q54Vub6nN0v/w+73gFWztBKBNVmFq26yIT2r/+kvTY0VgJA9XWr79VOjmuqtXkqOr08bruulz1qMJA2QPt5Zjwtvy/HNslJoD1rHpNga/dS64yT7c9dqZH/p37THLfC7jVZ5j6lXaQ9dvBzue00Sl5XdEau1qtX7GuqtCvJtoFTUo/an7vFBQljlJRkqZ8xu9+1nh+jTsLPPSxBYU01cHSjPDa4tsxSzch4mgn85jlg00Lgwzvr/v+U5su6QTverLsMwKkdwK6lwKa/aUG0OVNyk/2LIcFhWjc5y4sPzqgnjOrcDvWYCk8Apr0HXP26XIxyRFGk1PKLuXJcnsuUTHFIpJz0l+YDP62QwH/Eg1Ia64p6sUQNnHQ6Let0IUeCekD2pc6PtaT+bn45Tz6PdDppINFnqjbXtc8UuXjkinmek5PASVHk/ddUSDCW9wvw5xRtPqp5DScXpXm2gozA2NoLhLHt3fub4StBRq35SpSX18CypyRPFvVVFLmodsvHwIN7rLt0plgEc/1cJEzUY6Y4yzvNQPyAx4FTSEgIVqxYgcOHD+P999/Hxx9/jKNHj+Ltt99GSEgD2x2TX9MyTgyc/Frhae3Kb/oNtWl0nZyAWc6psaU2NQDkw3DEgzLp25Ego3ZSZnvVWFG0Cdh73nfd1EFlzmz0s8hsfCxXaO9Ty8b2Wwcpp3fZ3/8PrwFvDJPuT5ZMJm3SfEwbKbUbOU8WDlRPAG1PGp0FTituAZ5vJycOOYfkyqtltsOe1P6S1Wp9kZQ96GsXYLTMUoVGS3lN+k0yV6iy2PrnV14onZX2rZSr4cNnS7DVY6I26dfWjcuAYbPkfmm+62YFgJTaALKeS3i8nCxd/29peT1+gTynNwBXvihB0i2rtIxBfEcJgI+sBT64Xq4QdxwlYwXkxDo1XY6lzpfLOipqIwJbOp39TlmAnIDe/JEEYKP/JMdlTaVkLmuq5QQTkIB151vArne1E+rWA+R9XPa41ixBzZCdPy6BgDFGfhb379RKVZ1RSxwty93i2ku28vfrrYMZS5bBY2J3+bmWF9TNqvSYKGunOJvAnj4NmPqmFqQDMs8ntp0EtIDs98t50oESkOxWdbm06LdcxBOQn/d9W6zLUlXq783x77TW0+p77jZBAr21T8l8kopC2f/QmbJN1h5purLoYmDxSMdXpvOOyOfT+udk+321AczJrXUXbN73oVw8SOlXt6Nl+o1AdBu5eLLlDXls0B0ybyndyUmgmmFf/4z13E9Hel0tvw/qRR/LBizusFxHaMNfJGBP6CbvSa+Xn92quyWAdCsLelRboNhyOQm1w93WNySgD4mS3wV7LLPB2/8lt8NmApMXa59NtqWjjlz1mswHUwNSe3IOyly6oFA5lvUGyW6V1v7fWK7h5Kmek4AbPgBueN/z1za1q16TigpHPxdvqSoH/n4R8Mks66ZPtvO9DMFSpnnLKtcdYy3LCBdf4nCz5sTjdZxUXbt2RdeuTlo6UovDjFMzoS7O2H6EtobRyLnyR9fZlTlTjdTv5x8Fxjxp85ypdvE6m7ltbQfLicvJbdrK7ICc5N7xtXRXK8mVE+ceV7oeu2VJWIdLpbyp61jZX0JXOQlL6ll75TVcTv6XTpKWtDM+t158r7wQyD0of3wtleTKe9Hp5QqeIUje7+jHZX4OIFdQ2w2TdYVM1c4Dp8oSKT/L3isn69sWSwbO2fvV64GH9jkvcQDkfQeFAHetlyujlqVKK2+TBg0hkRLIWJ4gOxKZJBPkL75fTqJ1OimDPL1bghnbMRdny7955zrruQgJXeu29NXpHK9XFNdRAune1zheY+jyJ+o+5olOo7TytO5XStvpkXPl6rRa1jZmvpRlnT8uJUnqiXJaf/nS6YENf5bs7KDbZa2qx05Jxs3y/aqBu6NuUI7K3ZxlBSpLgYLaE9uE7vK71vsaOc4VU93tdTrPF9ccek9tpqf2RFs9iVfXcjpZO/eozRDX66p8839Sujb491pQAdTNgI19Tjp6HVmrnYB1vlyC3YhE+X088LEszqoPdhyYlp6T5RWiW0trcLXsDZCgrPsE7fPJdq6NpeAwyf59/Hvp6nfRLRLkOOukB2jtyAHrUiVHErtbBxq2gVNNlXzeJfawn6EJjwcePwMsaCMXV07vBGbv0DJ6iT1qA+tCKZHt4qI7mRo0AdZZdjXzo849vHSu4wyMZTbYci5YUAgwa5v8btke845YNotwRK2S6HCJ/NzCaj//1GYO5sDJTmmnO2zLqf1VfEfH6xF6U3ConAPsWykXAK9b6vjiaZuBnu/f3tpmzZDHGaepU6fir3/9a53HFy5ciOuuu84rgyL/dLpA7ajHwMmvna5tMtDd4iR4zJOuuw0ZgoBLHgIe2i+ZmENfytXdM3vlpObPScCrNlcH+14n7V8tF4Y17y9YSokA7UTGmapy7Yp7St/aErB3JCALMsrVxpuWywRy9UTj6DdAVYmcQESlWO/P3vwKQJoNzPhMWs5aBi56g3bSF5UiE5tN1VppjCPqFbfsfVqmoY0bJ1bqv12aL2tC7Xzb8ZXjtIusg6aqci0TdPPH1kFTRbH8v6hZE1s6nQSY6onx6R+lE6BtSdPWxdKW+tuFEiDbm0vjrjYDgbs2AFP+WTdo2v8R8OkD0hTEW1L6SPleaIx27PWbJv92em0mc9U9EjSWFWivsyyhVLOYQSHWQZNSO0/pozvtrwdUdl47jh3NIwLq/n+fOwJAkZND9QRj6hIp1bScI3J4jftlbYoix4llma5er00Cj0ySq/nqWk7h8XLia7s+kT2HPpfSvJJc+T8a9UfJUtkGKwld5T3M2qa1zVY7dKm/JxtrM5ft7bT4Nu+n9qS96LTMAzNGS/Y0KlUymercR9s27fb0mSqT4isvWC9U7UzPq2QuzODfuzcZ35Zt4LT4EmDJaLnw5EhIOHBNbWbnu5dlHR/1ZxcUol0I++B6+8G1pXYXS+lo94nWAbdloBPTThaudSQ1XbbvNVmy5paiU2XukDcXMlVL8tSMpvoZWGobONUj40T2qZUep7YDL/eSNbka6qrXJED/3asN35cf8DjjtGnTJjz99NN1Hp8wYQL+9re/eWNM5KdOn5c/1m0YODWOsz/LH4r8X6Uc7dZP3KsVt6WWuiT1qN841BPbH9+ThTKjUrQrp3qbj4zU9LqlFrmHpRa96zj5EN7yujQ5KMmre8XppxXSJatLhpz4mKqljCfawVUuW+oJYbdxdf9g2+voBchJQ8dLXe9bzX4l93F+JVet987ep81/ceeKtOrwlzKP6/Qu+6uv2xMcCsw9LFeRbUt/Dn0hQUGbwVog8Mv/pPPdkLvqXll3VEKkXmH3VtdER8fjoS9lIcTQaFks0ZtK87WySfWEIP0GWVcJkHLOQXdoJ8Kp/aXjV3WFnOTbm+eR90vthP0q+f9XmwDEdZAOemp3xPjO9q+wKoo0Ltj/kXSKU5utWDbHsD2WFUUeO/szsGyajPHhA3IV3plfNwD/mSJzWib+TX4nLQNXnU5KMM8dkeOg3/XaYre2irKA96+TwPDhA3XXdRv9mNaR0tZFN0vJZHhtZ0m1C9fox6Xc8H9/kn9fPUG2JzxeMiUlOZJZHHav/Jz6TpX/67BY+Tf+Wfu7bdmm3ZZeL+sKvT1Ogr8eE7WFTx0JiwXu3ex8G1vHNsnvdddx8jnZ+xptHaeUvvKZd3K7865kfaZKV7LTuyQbajnv1LICwFX2OihEGgHYHluXzpOvk9slmHeWxQwyAne6UabojrMH5P8npq398s/KEummB2jHhZpxKq1t8W5uDuHhHCdyrOMo6+/bj2j4PgfcKpldbwbVPuRxxunChQt25zIFBwejqMiD7lnUrCiKgixmnBrXrnfkCvjOt+Vqz2/1WJempsqiPa1Nd7Ky8zJHwHY+gCr3F1lzRM16qKUB+b9qrYfdCWi2/VMWvvxyrpwUpvaXgGjfh9bbnd4lNfrvTZX6e8syPWcfsBdyZV6EyWTdWtmWGjgVnrSfGXAlyCjv17KrkT1qGd+p7fJv6fRyNdsdH98j9eSA8yzVuaPSOOB/FiWUOp39+RJq0HbmJ8lMAcCe92T+iZrVyd4HfHADsHy6xRpONvtS1/YpOiXdEd2dp+Yp9f/vh9cku+VNZee1eSFqZjCuvRY4D77LumW8Xi8NKP5wTE7S/jFcGm9YZgITuwPTV8pckFM7ZC2TbYuANY8CH0zT5hc6KlnS6aTssarUuoOfo+YYigJ89oAEa2r2rN1w10GTul1QqJTUrbhZmg3Ysu2W50hYnDTfKDot82vUUjl35nwBcmJ/84fAH3/TssMpfSTgVLtAOgucAOsOXcFhEsy0HqgFvkqNfNYAEqw5026Y1inM0WdiQ21dLGtVHf9OMufXvaNduFBbg3//d/tLDXz6APDfW6UEWO1wl/uL9fxONbvnaF6gLWefq22HyAK+TeXEFmkc9NMy+88bQoAblwOjHtXm26kZJ7VUb9i9Mtfvkocbf7yBQm/Q5sF2GOm9xhktJGgC6pFx6tu3L1asWIGnnrKelLp8+XL06tXLwauouTtfWoWyKqmtTuXit95XXVE7NwlyIlNwQrIpHpdH6aR0K++Xuosh7nxbsj8H28kVUNsri+9dIyf+d66VP6KWpW7quhv2FljMOyIZpcgUyXDsrw2Qel8jt8NnSzBnuQ4EoK0ZBMgchSuelXbizj6oT+0E3hwj5Tk3rZCrz8ERQFs7i+pFJEopS+UFKe1JrD0hzVwnJ37thttvfa3qkgFckuO43EfVqotcRa+u7dCV3Nv9K6CW/5/OslTlhXLVOSJR6wblSFxHubJfmifBU0JXaekLaPPQdAbgl6+01xhCtE5bKmOkbKfUSHdE21a13mI5f8zdifPuim0vWTa1K5Xq6jdkXoi9ltDqMXFqe237Z13dP/qdRwN3b9CaENRUAjvekqv2Q2dKQBDbvs6uzfpPlzlWe/9b220vWGvxbHtMHv5Ka4uvNlxxdwJ+cJhcMVZLnrqNr7uN+n9+epeUo9lrBa7uS834nNgijxljPC+Tsp0neeIH+d2JStW6NTqS0E2CEEet+XUGmdcW08b+e7U19U0JXtWSYm9L7CZZe3tLKPS/SY6BXzdIwD3pVWCAxfH4y9fAhWxZG6v9xcBN/5XyYcvs9+g/yYWAri6yZf7I3FXPotOayaS9P0Ow/D2xLENW/w6ppXphcfJF3jXmqdrGPi7m/QUojwOnJ598Etdccw2OHj2Kyy+X9PL69evxwQcf4MMPP3Txamqu1I56iVFGGIMMLrYmj/2yRq6OR6XJYoErZ7i/7pIlQ5D1JHlLQ2cC29+UoGz7P6Vrnqqmqm7mwTJwUq8q28s4/brRep0lQLpWqVf1+zkIPGJaS6e8RRfLfIlh90qHJmcSuwPQSUmceZX6UfabDeh08uGfvU/egxo4/fieTIQe9xfngVNIhJx0u6I3SFmb2rbanflNqi4ZwHcvyn1nk6rVLERJrpxovD1Oysgm/d167hMg77vtUDlhO7Vda1qR0lcLUhK6SmvsmtpMXExb++WIce21OWKNdcXQMnByNpesPgxB9te3iW2ntU93xNwZz8HPM6GrdWlarykSpNv73bPVJaO2MUKOZE27j5cT6Vad65bGdJ8gJ8gb/k9+jo7WbnL2bx1dL0GFvTI89fd959uyQO/oPwGjHqm7nbptSY5WQuWs66a7tr8ptxGJro8xNbO0+WXg8qfqHrOGIOedBm2FxsjnTmNRs/5nD0jWPjJFG3NwmARDn94vS0B8OluC1l5Xy4WSC7Vd6tT5dfZKCQ1B7rUh90fmwKm2RfqRtZJhG3SH/A2093kU01Y+X+2V0JL3BIe697cvQHlcqjdp0iSsXr0amZmZuO+++zB37lycPn0a33zzDbp06eJ6B9QsnTpf24qcZXqNQy3ZSb9Brmbrg2SOhe38nIYIidC65W160fpKX9FpmVxsMGodl9TA6fxxrduXvbKc7hO0K4GAlKqNeLDuKuSAXFG0LHtK6qH94f/6cddrIRmjtHFt/YfcOusml9y3tozF4t9U52a4O4/KHZZ14e52lQJkHlK7iyXItLd+kcoYKcEoIGtLncuUkrDQGPvbqyf7J7fZ7zBmCLY++XCU6Zn6pvxsr37DrbdTL5FJskZL60HS2c4f/PC6lA4C7s9XazPQvaAJsGmc8p7cdp8g2Sfb/wOdDhj1B5nbYowGRjzgeO0me3pPkUn/g++s20AFkHXZ7viflMxBqbtYqSX1OFEzTt74Heo2To6x373ietsBt0rwMepR5/MO/YV6sebkNukw+nJv6+eDQoApi4EBM+R79WKQOt8tKtXx73hzp/6dUf8O7XxHyle3vA58cJ1cjDv2nfVrOowAfr9WWwZh59vSqt22cypRI6pXO/KJEydi4kRp41hUVIRly5Zh3rx52LVrF2pqaly8mpojNeMUEI0hirJkgv3A2zw7Qamv4mytxr3/TfKHsu1QmeN0dD0Q7+LKuKX9H0nZX6fL7Ac5/W6QdtlnfpJOVhNrG7qYGwRYZB5i2khpUE2l1iDAXqleTBtg3hFtVXqdwX4G6MRWmadz2R8lC5TcR66GX/aYrK1z5idg3XzXpWgpfaX0r8fvpCWv5YrmtqYsqvuYOl/L3nupr4z58lV4yrPWuIYg4I6vXG8HyElY0Slg93/k+zaD7AengHayf/AzudUH1S05TOmrLcQa18H+floPBP5gZ3Fjb/O3tVTUq/2AZ4GwJ9JvrC2d/Uy6pUUlO9++vhOso1OBh/c5fj62nZzEqhcUnHUCVAMntfTMGxmngTPkyx1xHYB5Dsr0/JHtxRB7gatOJ+WFXcdqWXq1FNFZRry5UxunVBTJXEzLEtHMdfJ1+keg40j7rwdkkeNT22UOI7NQ1ETqfclm06ZNmDFjBtLS0vC3v/0Nl19+ObZuddJWk5o1dQ2ntECY3/T3AbIo5K6ljf9vVVdIpyqlRkoQ1LIMNYviqKW0I9+/Cqy+V9blsUevB8bWtt/d9a7WPMBeZzW9QTuhjkqReSKOSqn0Bik9CQ6zHzQB0j0uazfw5SNSdrRsmqyPE5kodfyAtNF2RS3tCg6TDJon82JMNVrnO29mnFQxbRzPEWkotexHDXaclQSmXWTdAbHb+Lod3tRugN3GA7972WvDbBEsmxRYNo/wppQ+WkfKHW+695rGKpc8s0fmakUkOQ6iAe13rfuVsr7VmPmNM56WwhilZYoBx59Vce2ls5z62aHOd7Nt8NOShMZIy3hA5mNOWQw8kQvcslq7+OSqJNXcjpxd9ajpeJRxys7OxtKlS/HWW2+hqKgI119/PSoqKrB69Wo2hmjh1IxT65aecTp/XJvkf3oXgAbU+aothJ0JMsqioUVZWvYHkBO3H17T6sDdYTJJowbA+ZXKDpdIaUzpOVkgNu0ixy2pp74pf+Ci27hud+vKyLkyv6jgN/m+7TCZ0wHICVhcB+l05Ypl+293qT+L4mwJUvVBUiLWnCTaXL12lgkJDpOfXc4h4Phm+80E1AA0e1+L6njkFZ0uA655U47Jxvy/mfIvaVJhbx5WU1p9n9zGtXf+flt1BhJ7ygUCrp3jHjVTDLh/kSdPbU3vpHy3udPp5O9bcZbM3YxpIxfdOo8Gfr9e5mjazrNRFODVftJZ9YHdFu3IeSxS03H7TGjSpEnYtGkTJk6ciFdeeQXjx4+HwWDA4sWLG3N85Ce0jFMLD5zUGnNASs7qa8s/ZNL/rZ9qbZAdGTkPGHCbdTe5lH7AI0frlmLVVMuE/pCIuvspOiU14vpg55PsdTop+VFM2pU9R4GT7RpNDREaI+u2fDFXvlfX1QEkKBt8p3v7UU/4cw/JWh/2/i9UZQXA0okyR+sPR7UyvahUx2Vu/irRZh0kVyu3954C9HbyfHJvaakd3Voyj87WbwlEjpqaeFNSj/qvt+ZN6hIGtp0VbXW6DJjFyhKPZDwtywkU/OY8cCrJk6UcztfOazUYW3bGCZAFnoNC5XPIUmI3+0GjTieLP1eXSWe9itolcDwpjyZqILcDp6+++goPPPAA7r33XnTt2tX1C6hFMWec4lpw4GQyWa+ronb7qY/9H0lGZ/u/gKv+Xvf5A6slq2SMlD8Gti24dTr7gdup7cC/J0tZx9S3gO1LgJ8+AKa9r00obtXFdXboimesv+82HgiNtd/Wu6pcxmPbRrg+BtwmLZwvnJUT+/qISpETuAu50ojCGWO0nLRUl0lwqF75bYwyvcbWeqC0LP7sQQmiGtqGNzQa+OOJ5jHJnhrXpY9IabK6XpAziiJrQoW3ks8RtoN2LjVdK8Fz1qJepwc2vQBAAeYclCDWspFOS9ThEvkcf7GL/N2audn1+mTh8VLaV5ZvUarHjBM1Hbf/Ym7evBnFxcUYOHAghg4ditdffx15eXmuX0jNXnlVDfIuyMT/Fl2qp9NJnXXf64GHf5ZWsfXlrNPb6d3Sbvy1gdJ21hlFkRN/VeY6yTjp9DLen1cDWT9KO1t1wnZ9yjt6TwYmPC9diywVZ8s4/5wErLzN8/3aMgTJAqMP/Fj/uUA6HXDrJ8B9P7j+I6vXWyzke0y63834zLOWxf4iyCjt6tsMkRMOb2DQRABw+RPAI5na74oz5YWyfMDudyUrQq45yuhbCo/XFs7OXC8Z8YaWRzcH6hpjIRHuLeocVrv8QmFtJ1hA1usjaiJu/9UcNmwYlixZgjNnzuCee+7B8uXLkZaWBpPJhLVr16K4uLgxx0k+tOu38wCAhMgQxIQ1QZc5X9HpZKHBqUukW1RD5jZYroFkSVGAr/8k9ztd5rzVbFU58Epf4LUBQFFtQwN1bafOtYGZWu625wOtE5O75R2l+cCv3zpvAV5VqmVpnJXEeaKp59OoDTfWPy2d/zpeWjdAbC66jZV2vJbz4Yia0ru/0+6HhPtuHM1FTbVc8AgKk66lzqhNSeqzhl9zlLUHWHWP3O/s5GKjJXXdOnWuLHTe+9tE5AaPLzdGRETgjjvuwObNm7Fv3z7MnTsXzz//PJKSknDVVVc1xhjJx/53QFrzZvRMho6TyF07f1yb3Gu7DtPBz4ATP0hdt7qmkiPBoVoDg6PrgQs50rIbADrL4tPodbWsJn8uUxovAO61sK2plnVF/n0VcHa/ZMFKztXdLsbiD31D5nz50qhHZdHQ7H3Am1doJY1E5Lnzv7nehjSGIODSecDkf7g+wVcDp59XAzveavSh+ZyabQKsO1k6o2acoJMF1H+/ns1tqEk1qE6je/fuWLhwIU6dOoVly5Z5a0zkRxRFwdqfzwIArujlYuKwr5zaCbzcR1uzpj4OrAa+mKd1avv6T8Dy6VozAU8c/gr4rjYjUHQKqKrt0mcyyTpFAHDx/e6tI2R5BVJt1Z3ST1vzxRglwRMgV+xu/khbC8QZQ5C27sXufwNLRgNv21kPqSnWsWpsyb0lSxPfCSg8AXz+kAShROQ5d8qpyFrfa4E+17jervUA7b56kawlqyzV7ru70HR47Zy6iiJprOKqSQ6Rl3mlwN1gMGDy5Mn49NNPvbE78iMHsoqQVViO8BADRnRJcP0CX/j0fqDwpExYrq8dbwI7lgC/rJHvD34mdfxqbXrJOZmU/8NrrveVa7NAo3qF9vwxKd0zGIERD7o3LjVwOrpBG5vtlTm1XO/kNqD9CPfbbKvd6Q59IbeO6u+H3itZLXWtpeYovhNw51qg3XAge7+s50REnpvyT+ncOWGhr0fS8ugNwCUPS1nf8Fm+Hk3jG3CLzE+6+H73L9K16ipLMTTHBj/UIgTAzENqCLVMb1S3RIQG+2mpVmIPIOdnuV92vm6Xp5xDkk1J6g3c8VXd15//DTj+HQAd0O8GeSw6TWqo1cVSzx2RrlMx7eRD3pk8m1Kw/F/lypiazUru5X4XoLQBMg+qvAA4sEoesw2c2l8i4yo8IUFQ32vd27e6HlJxbVbNUeA04XnpnuWNrnq+FJEgjSlqKpv/eyHylc6jgcdP83eosYyZL1+BUH4W10EWUvbEwBnydfZnYOPz0o3P3b95RF7Alkrk1P/8vUwPAK57R2uI8Ou3dZ8vOiWdoE78AGz4S93n1bWbOo3SJu9GpchtsQSO5iYP4XFaowZH1IzThBeAuzbIftV96YO0TI87DEFAp9Fy3xgD9Phd3ZIGvR7ofyOQ1AswVbu/b9txOOv41FJOkrzVVp0okPF3qPHodIERNKnq+36z9wIbF2hze4maCAMncujEuVIcyi6GQa/D5T3cLP/yFWfdiApPa/ePb7Z+zmQC9rwv9/tP1x6PSpVbNeOkBk5nfgLWPe14HKX5ssYEAFw0XWrW1QnBw2YCj50GMp5x/Hp71PeW0AW44X37JQ0jHpJ1kdIG1H3OkWSb1VGdrTFCRETkL7iGE/kIS/XIof/9LNmWoR3jERse4uPROFBTLVmZLmOArW/I+heKYn0Fq8gicMreZ/38iS1SkhcSJdkclaOME6C1/bZHzTbFtLPfQSk4VL480SUDGHaf865DIeHAqD94tl9jlMz9Ud+bs4wTERGRr+UfA965UisxN9ZzPUCiemLGiRxqFmV6G/8CvNBV0vax7aSjXGWJ9TaWGaeKIov1HyDrHwGyAKzlmiSOMk4AkHfE8YrualCV2E3mW21dbL880BPRqcD4Bc4X1a2vYfdp9xk4ERGRPwuJ0IImADBy8VtqWsw4kV1ZBWXYcTwfgJ8HTtn7gJIcyZ48uNd+rXTRqbqviesg9+PaS5BkWaYHaIFTyTkJks5ZBE6VFySLZa+deOcxwDVvAmGxQHUFsOZRQKeXLkDfPAd0uQK4/E/1fbfed9HN0iyh4CQQ4eflmEREFNhsmz+xVI+aGAMnsmv1ntNQFCnTaxPnx6vDq53qUvo5nmCqrsWkdp7L3gf0nCSPjfoDMHKuBDeW2g4B/nBMPqTLzgMVhfJ4bDtpUZ572H7gFNtWazChKNLGu6oU+PkTIOtH/8vqBAdI21siImr+DMFSnldRJN8zcKImxlI9qkNRFHy8W8rbpg5wY5FWX7mQW1tKp5OOcoAEK2f2Wi+sl9gDSOwJ9LhSvleDLZXeUDfoCjIC4fHyeHi8tEy9dwuQmi7P27Yct0enkzlEgAROgGcd9YiIiMhaeLx2n4ETNTEGToQT50rxly8P4nRBGQBg76lCZOZcgDFIjwl9U3w8Ogs1VcD718lCtIoCnK0NgFp11uqc3xoL/HMkcMyiLfm0/wCztgI9rwJCY6VGuigLOLJWmku4wxgl6y+pbc9zD8lt/q/AG8OAdc8AFReArYu0BhUAEN9RbssL5FZdO4mIiIg8F1YbOF3yMND9St+OhQIOS/UI//ruKN7begIbDuVg1awR+Hi3zAka1zsFUaFurubdFLL3Akf+J/e7jgXOZcp9yyxOUg/g1Hbg1A6g+wTr17cbDjx6XDJBG/8qjSV6TQauf9f+v/ftC8CZPcCl84C0i+SxjiMlCOp0mXx/cjuQe1C+jn8n/254AvCHo/K8mnFSMeNERERUf2rGqVUXrQMuURNh4EQ4kS+ZpiM5F/DQ8h+x67fzAICpA5ugTK+6Ejj4qSxQC8haRJZpeEv5x7T7/3sSSOkj9y2DETWjo5bjWbYe19cmWC3XbnJ2ter4JuDYJuD8b0DbwUD/myVgUoMmAEi/Qbr4fTFHgiZASgNVloFTeCut6QQRERF5Lrm3rOMUGuPrkVAAYuBEOFNbogcA6w7mAACSoowY0blV4//ju94BvrJYf6jdMMeBk2ICIhKBklwg/6g0XWh/CdB6oLaNbeC06x1g7dNAv+uBiS/KY5ZrN/X8HRxSg5yz++Sr02UABtbdbvCdEiCtuAWoLJasl8oycErpG1grwhMREXnbFc8CP7wujZpK8x2fMxA1As5xCnCKoiCrNnCaNbqz+fHJF7VGkKEJDo9jm+Q2NV063Tmb6NnveuCRTOB3r8j3VWXADe9bZ4CSewHQSdOIC7myhlNFoQRdALD/I2BpbZap92T7i9SqbEsA1CCoohg4vQs4tVN7rvNo4M6vgcG/t14bKW0AcNEt0gWI85uIiIgabuMC4OvHtWoVoibCjFOAKyqrRkllDQBg9uiuCDEY8MW+LNw6vH39d7rzHWDfh8A1/wJiWstjVeXAR3cCMW2BCc/LY4oic4QAYMJCyTapKkutF6S1NOBWaeyQPq1uqt4YJQFO/lHJEplbkdeOQ28xZ8t27SZbtmV16tpPK28HMtfK/ZS+wO1rpDlFcm9g4t9sxhMJXP26fJlMzv89IiIics5UI+spAuyqR02OGacAl1Uo2ab4iBCEhRjwYEZX/O/hUQ1bu2nL68Bvm4G1T2qPbf0HcOhzYNsiLZg5f1wWr9UHA6n9tW23LwFe7q0FVbb0BuDGD4BeV9svfVPnPGXv0xa/ja6dr9V+hHTWaz3QOlCzxzLjFJGkfUAndtceDwp1f+VyPX/diIiIGkRd3gNg4ERNjmdyAU4t00uLDfXODqsrtSYO+z+S4OdCDvDdS9o2mevlVm2mkJoOBFv8+2f2AGX5wJrHtLbe5UXAwk7AmxlAdYXzMfSeAox6FOhwiZTqAUB0mtxGtAIe2gfM+Nz1fCPLjJPlXKWEbtr9/jc53wcRERF5T5U2LxtBRt+NgwISS/UCnBo4pcaEeWeH+UcBpUb7fs1j0v2ushiADoACZK4DBtwCxLQB+t1g3UwBAC5/Eti/Cji9U+ZAdRoFnD8GlJ6Tfbj6oOw9Wb4UBSiqDZzUUj0ACI12771YZpzU9ZgAaYFq/reucW9fRERE1HDR7E5LvsPAKcBlFZYDAFrHeilwCk8ArnxRApZt/5JSvM5jgJxDQI8rgQ1/kVI7AGh/sXzZikqRbnd7V0gHvE6jZKFZoO66SM6UnQeq5f0hurXzbe2JaQv0vQ7YtxKI1xpnoP3FwKV/kJK9sFjP90tERET102k0MOJBIKm3r0dCAYiBU4DzeqleZCIw5C65322CVobXc5J0thtyNxDsRpDWZrAETie3yfeeBk5FZ4BfvgKS+0gDifqk8/UGYOqb0vBBLRkEpMTv8j95vj8iIiJqGJ1OWpIT+QADpwDn9VI9S+2Gavd1OkBnAPS1/07haaC8QBaLVTNQltrWvvbUTulG52ngtPpe4NcNwKRXgYG31fcdCC6yR0RERBTw2BwiwGUVSClbmrdK9Q59KWscuWrg8MNrwKKLgdX32X8+qRcQHAFUFAG5h4D84/K4u4GTZWc9IiIiIqIGYsYpgNWYFGQXqYGTF0r1TDXAytuAmgrg/t1Aq851t6kqA5aMAXIOyPdpF9nflyFI1msyBMt6Tp5mnNTFZhk4EREREZEXMHAKYDnF5agxKTDodUiK8kLgVPCbBE0Go7ZYrC3b+U1tBzven7pQrqlGOu8Zgq272zmjZpxObgN2vQsMnOHe64iIiIiI7GDgFMDUMr2U6FAY9C7WNHJH7i9y26qL/XlLqviOWsZJzQw5ozcAt6zybCyWLcMvnPXstURERERENjjHKYB5vaNe3mG5TezufLtLHwH0QUDPqySL5Ex5EXD0G7n1hCEIaD1Q7ve8yrPXEhERERHZYMYpgGmBk5caQ6gZJ1eBU1p/4IEfgfBWrvf51hXSHOKm/wLdxnk2nhmfSbbJk7WfiIiIiIjsYMYpgJ0p9HJHPTXjlNDN9bax7YCQCNfbtR4ktx9cD+xa6tl4QiIYNBERERGRVzBwCmCn1YxTjBdK9RTF/YyTJ9oO0e4b6rGILRERERGRF7BUL4B5tVRPUYBr35asU7ydNuT1ZRk4xbb13n6JiIiIiDzAwCmAqaV6qTFeCJz0eqBrhnx5U0J3IDQGqCoHkvt4d99ERERERG5i4BSgyiprkF9SCQBo7a05To1Brwdm7wJqKoGwWF+PhoiIiIgCFAOnAHWmUMr0IkIMiA7zwmHwy9dARTHQ/mIgOq3h+7MUmejd/REREREReYjNIQKUuvhtamwYdDovLH77w2vAR3cCRzc0fF9ERERERH6GgVOAUhtDpHqjox4A5Kkd9Xp4Z39ERERERH6EgVOAOl8q85sSI73Q4rusQBaaBYCErg3fHxERERGRn2HgFKCKyqsAAFGhXpjfpGabotKA0OiG74+IiIiIyM8wcApQxeXVAIDosOCG7yz3sNwmdmv4voiIiIiI/BADpwBVVObNjJMaOHF+ExERERG1TAycApQ54xTqxYxTAjNORERERNQycR2nAKUGTlHeCJyufBHI+RlI7t3wfRERERER+SEGTgFKbQ7hlcVv49rLFxERERFRC8VSvQDl1YwTEREREVELx8ApQKnNIaIb2hzi5Hbg2xeA45u9MCoiIiIiIv/EwCkAmUwKLlR6KeN0ZC2w4c/A3hVeGBkRERERkX9i4BSAiiuqoShyv8HtyNVW5AndG7YfIiIiIiI/xsApABXXNoYICdIjNNjQsJ3l/iK3iQyciIiIiKjlYuAUgIrK1DWcGphtqqkGzmXKfa7hREREREQtGAOnAKRmnBq8+O35Y4CpCggOB2LaemFkRERERET+iYFTACoytyJvYMYpt3Z+U6sugJ6HEhERERG1XDzbDUDmjFNYAzNOuYfkNqlXA0dEREREROTfGphyoOao2FsZp5Fzge5XemFERERERET+jYFTANIWv21gxkmnA5KZbSIiIiKilo+legGouMJLGSciIiIiogDhF4HTG2+8gQ4dOiA0NBRDhw7F9u3b3Xrd8uXLodPpMHny5MYdYAvjlYzTV48CH94JZP3opVEREREREfkvnwdOK1aswJw5czB//nzs3r0b6enpGDduHHJycpy+7vjx45g3bx5GjhzZRCNtORo8x8lkAvZ9COz/EKgs8eLIiIiIiIj8k88Dp5deegl33XUXbr/9dvTq1QuLFy9GeHg43n77bYevqampwfTp0/HMM8+gU6dOTTjalqGooV31sn8CSvOAkCigzRAvjoyIiIiIyD/5NHCqrKzErl27kJGRYX5Mr9cjIyMDW7Zscfi6Z599FklJSbjzzjtd/hsVFRUoKiqy+gp02jpO9QycMtfJbadRQFCIl0ZFREREROS/fBo45eXloaamBsnJyVaPJycnIzs72+5rNm/ejLfeegtLlixx699YsGABYmJizF9t27Zt8Libu2LzHKd6luplrpfbLmO8NCIiIiIiIv/m81I9TxQXF+OWW27BkiVLkJCQ4NZrHnvsMRQWFpq/Tp482cij9H8Nyjjt+QA4Wdu8ozMDJyIiIiIKDD7tR52QkACDwYCzZ89aPX727FmkpKTU2f7o0aM4fvw4Jk2aZH7MZDIBAIKCgnD48GF07tzZ6jVGoxFGo7ERRt98aXOc6vHj/+0HQKkBEnsCce29PDIiIiIiIv/k08ApJCQEAwcOxPr1680txU0mE9avX4/Zs2fX2b5Hjx7Yt2+f1WNPPPEEiouL8eqrr7IMzw3lVTWorJZgs14Zp56TgPhOQI+JXh4ZEREREZH/8vkKqHPmzMGMGTMwaNAgDBkyBK+88gpKSkpw++23AwBuvfVWtG7dGgsWLEBoaCj69Olj9frY2FgAqPM42ae2ItfpgCijmz/+H16XhhADZwC9pwDdxjXiCImIiIiI/I/PA6dp06YhNzcXTz31FLKzs9G/f3+sWbPG3DDixIkT0Oub1VQsv1ZcW6YXGRIEvV7n3ot++x74dQPQbXwjjoyIiIiIyH/5PHACgNmzZ9stzQOAjRs3On3t0qVLvT+gFqxei99m75fblL6NMCIiIiIiIv/HVE6A8Xjx27LzQOEJuZ/CckgiIiIiCkwMnAKMxxknNdsU2x4IjWmkURERERER+TcGTgGmyLz4rZsZp+zaLoYs0yMiIiKiAMbAKcB4nnFSA6d+jTQiIiIiIiL/x8ApwHg8xykoBAiNZcaJiIiIiAKaX3TVo6bjccZp0qvA714BFFPjDYqIiIiIyM8xcAowHs9xAmS1XJ2hkUZEREREROT/WKoXYIrMGSc3AicTs0xERERERAADp4CjzXFyI9n49ePAK/2A3f9p5FEREREREfk3Bk4BptiTjFP2XqDgN0DPMj0iIiIiCmwMnAKMNsfJRcapsgTI2iP32YqciIiIiAIcA6cAU1xbqucy43Twc6CqBIjrACT1avyBERERERH5MQZOAcRkUnChQkr1XM5x2vO+3KbfBOh5mBARERFRYOMZcQApqayGSZH7TtuRF5wAjm2S++k3NP7AiIiIiIj8HAOnAKI2hggx6GEMcvKj/2kFAAXoMBKIa980gyMiIiIi8mNcADeAFJnnNwVBp9M53rDHlUBpHtD+4iYaGRERERGRf2PgFECO55UCAGLCXDSGSO4NTPhrE4yIiIiIiKh5YKlegFAUBYu+PQoAGN0jycejISIiIiJqXhg4BYiNh3Px08kChAbrMXNUZ/sbVZYAn94PHPsOUJSmHSARERERkR9j4BQAFEXBy+t+AQDMGN4BiVFG+xse/BzY/W/g09kMnIiIiIiILDBwCgDrD+Zg76lChIcYcPelnRxvyLWbiIiIiIjs4tlxC2eVbbq4A1pFOsg2ce0mIiIiIiKHGDi1cKfOl+FAVhGCDTrcNdJJtolrNxEREREROcTAqYXLzLkAAOiUEIn4iBD7GykK8NMHcr//9CYaGRERERFR88HAqYVTA6cuSZGONzq5HSg8DYREAr2uaqKRERERERE1H1wAt4VzK3BK6Qu0HQLEtgNCIppoZEREREREzQcDpxbuSE4xADuB07Z/Ace+lUYQPScBXccCvaf4YIRERERERP6PgVMLpiiKOePUNdkmcDqxBTj0OdD+Yvl+xANNPDoiIiIiouaDc5xasNziChSVV0OvAzom2JTgFZyQ29h2TT8wIiIiIqJmhoFTC6Zmm9q3ioAxyGD9JAMnIiIiIiK3MXBqwY7UBk6dE23K9KrKgJIcuR/TtolHRURERETU/DBwasEczm8qOCm3IVFAWFwTj4qIiIiIqPlh4NSCmVuR22acLMv0dLomHhURERERUfPDwKkFO+Io41R2HggK5fwmIiIiIiI3sR15C1VQWom8CxUA7Mxx6ncd0PdaoKrUByMjIiIiImp+mHFqodQyvdaxYYgw2omPdTogJKLu40REREREVAcDpxZKDZw6J0W62JKIiIiIiFxh4NRCHXHUGAIA/j0ZWHEzUJTVtIMiIiIiImqmGDi1UA5bkVeVAb9uAA5+Jg0iiIiIiIjIJQZOLdQvZ4sBAF1sS/W4hhMRERERkccYOLVAJ/NLcaawHEF6HXqnRVs/yTWciIiIiIg8xsCpBdpy9BwAIL1tLMJDbDrqFfwmt1zDiYiIiIjIbQycWqCtv0rgNLxTq7pPWmaciIiIiIjILQycWhhFUbBFDZw6M3AiIiIiIvIGBk4tzG/nZH5TiEGPAe3sNX9QAIORgRMRERERkQeCXG9CzYmaberfNhZhIYa6G1y3FDCZAMXUtAMjIiIiImrGGDi1MGpjiGH2yvRUej2YbCQiIiIich/PnlsQq/lN9hpDEBERERFRvTBwakF+zStBbnEFQoL0uKhdbN0NfvsB+OcoYM3jTT42IiIiIqLmjKV6LYhapjegXSxCg+3MbyrKAs7sAYxRTTswIiIiIqJmjhmnFmTj4RwAwPBOCfY3KMmT23CW8REREREReYKBUwux43g+1h3MgU4HjOuTbH+jUslIMXAiIiIiIvIMA6cWwGRS8MxnBwAANwxuix4p0fY3VAOnCAcZKSIiIiIisouBUwvw4a5T2H+6CFHGIMwd293xhqVqqR4DJyIiIiIiTzBwauaKy6uw8OtDAIAHM7oiIdLoeOPSfLkNj2+CkRERERERtRwMnJq5pd8fR96FSnRKiMCtwzs439gQDIREslSPiIiIiMhDbEfezK07JJ307hnVCSFBLuLgW1bJraI08qiIiIiIiFoWZpyascLSKuw7VQAAuLRbovsv1OkaZ0BERERERC0UA6dm7IejeTApQJekSKTGhPl6OERERERELRYDp2bsu0zpkndJFzfmLOUfA/41Glh5W+MOioiIiIioBeIcp2Zs8xEJnEZ2dSNwunAWyNoNlOU38qiIiIiIiFoeZpyaqRPnSnEivxRBeh2Gdmrl+gUlXMOJiIiIiKi+GDg1U99l5gIABrSLQ6TRjcRh6Tm5DXcjyCIiIiIiIisMnJoptUzvEnfK9ACgtDbjxDWciIiIiIg8xsDJH9VUA+WFjp82Kfg+08PAqUTNOMU3dHRERERERAGHgZM/+s9kYGEn4EKO3af3nipAUXk1okKD0K91jHv7NJfqMeNEREREROQpBk7+6Ph3gKkaOPyl3af3nCwAAAztGI8gg5s/Qr0BCIlkqR4RERERUT2wHbm/qSjW7huMdjc5llcCAOiSFOX+fif/Q74UpSGjIyIiIiIKSMw4+RtTtXa/ptLuJmrg1DEh3PP963T1GRURERERUUBj4ORvwuKA9Bvlftl5u5scPyeBU4dWEU01KiIiIiKigMbAyR/FdQSSegOh0XWeqqw24fT5MgBAxwQ3A6eqMuBfo4H3rgWqyr05UiIiIiKigMA5Tv6m5Bww5C5g1B/sltWdyC+FSQEiQgxIjLI/B6qO0nNA1m5AHwwEufkaIiIiIiIyY8bJ32x6AVjYEVj/jN2nj9fOb2rfKgI6d+crlVgsfss5TkREREREHmPg5G+Kz8htZIrdp9X5TW6X6QEWazi1asjIiIiIiIgCFgMnf1OcLbdrHgXenVTnabWjXgdPOuoxcCIiIiIiahAGTv5GzTgBwLlf6zxdr456DJyIiIiIiBqEgZM/URQt4wTYbUd+PK8UgIelepZznIiIiIiIyGMMnPxJ2XmgpkL7vqoEqNa+L6+qQVahtCLv4EngBAUwRgPhDJyIiIiIiOqD7cj9iVqmFxYHlBUAUOQ2KhmAtCJXFCDKGIRWESHu73fMU/KlKN4eMRERERFRQGDGyZ+ERABD7gbSbwTCYuUxi3I9rTGEB63ILbEVORERERFRvTDj5E/iOgBXviD3f1kjQZNF4HTcInAiIiIiIqKmw8DJXyV0A4LCrLJE5jWcWnnQihwA/n01oA8CJv0diGntzVESEREREQUEBk7+pDgbMITIHKebVtR5+pgnGafj3wOHv5T7v34LQJHgiYiIiIiIPMYzaX/y+Rzg8BfAxJeAwXfWeVptRe5W4PThHcAFi9bmQWFAeLy3RkpEREREFFAYOPkTtateVGqdp8oqa5BdVA4A6Ohq8duSPC1oGvEgAB3QcSRgCPbiYImIiIiIAgcDJ3+iLn4blQLsehfY8jrQ/UrgimdwIKsQABATFow4V63Izx2V29h2wBXPNuKAiYiIiIgCAwMnf2GqAS6clftRqcDJbUDeL0ByHyiKghe+PgwAuKx7out9tRsKPHocuJDTeOMlIiIiIgogDJz8RUkeoNQAOj0QkSgNIgCg7Dy+2p+NbcfyYQzS45Fx3d3bX1ictg8iIiIiImoQLoDrL4qz5DYiCTAEmYMeU+l5/N8XBwEAM0d1Rps4D1uRExERERFRgzFw8heW85sAc+BUXJCL0wVlSI0JxcxRnd3b10e/B756lKV6RERERERe4heB0xtvvIEOHTogNDQUQ4cOxfbt2x1uu2TJEowcORJxcXGIi4tDRkaG0+2bjeg0YMg9QK+r5fvawElXdh4A8GRGa4S9eQnwxVzn+6koBvatBLYt5rpNRERERERe4vPAacWKFZgzZw7mz5+P3bt3Iz09HePGjUNOjv1sycaNG3HjjTdiw4YN2LJlC9q2bYuxY8fi9OnTTTxyL0tNB65cCIycAwDIN0lJXrSuFJd1jceEkD1Azs/AjjeBgpOO95P3i9xGJHLdJiIiIiIiL/F54PTSSy/hrrvuwu23345evXph8eLFCA8Px9tvv213+/fffx/33Xcf+vfvjx49euDNN9+EyWTC+vXrm3jkjaeqxoTZq44hS4lHpr4DXr2mG3TnMrUN9i53/OLc2sApwc0mEkRERERE5JJPA6fKykrs2rULGRkZ5sf0ej0yMjKwZcsWt/ZRWlqKqqoqxMfbz65UVFSgqKjI6ssvHfoCKJexvfj1YfxwrBBXKItgumczYuJaAdn7tG33fAAoiv395EnbciR2a+QBExEREREFDp8GTnl5eaipqUFycrLV48nJycjOznZrH48++ijS0tKsgi9LCxYsQExMjPmrbdu2DR631507Ciy/CXipJ5TyQizfIaV4f722H7olR8k2k/4OXLdU7uf/CpzZY39fzDgREREREXlds+4e8Pzzz2P58uXYuHEjQkND7W7z2GOPYc6cOebvi4qK/C94+mmZ3LYbhtwqIwrLqqDXARk9LQLKqGSg9xS5n9gTSOphf1/mjBMDJyIiIiIib/Fp4JSQkACDwYCzZ89aPX727FmkpKQ4fe2LL76I559/HuvWrUO/fv0cbmc0GmE0Gr0y3kZhMgF7agOn/jch8+wFAEC7+HCErvsTcHQ9cPkTWrc9NXiyu68aoLxQ7jNwIiIiIiLyGp+W6oWEhGDgwIFWjR3URg/Dhw93+LqFCxfiueeew5o1azBo0KCmGGrjOb4JKDoFGGOA7hORmSuBU5ekKOBCtnTJ274E+ObPwMkd1q811Vh/rzcA844A8zKBqNQmegNERERERC2fz0v15syZgxkzZmDQoEEYMmQIXnnlFZSUlOD2228HANx6661o3bo1FixYAAD461//iqeeegoffPABOnToYJ4LFRkZicjISJ+9j3pTs019pwLBoThyVg2cIoEaWcsJx7+TryAj0HYwkJcJbPg/4MRWYNp7QJuB2v50OiAysYnfBBERERFRy+bzwGnatGnIzc3FU089hezsbPTv3x9r1qwxN4w4ceIE9HotMbZo0SJUVlbi2muvtdrP/Pnz8fTTTzfl0BuuvAj4+RO53386ACAzRwKnrkmRQEGc9fYptSWJEQnSIKI4C3j3d8C17wDdxzfVqImIiIiIAo7PAycAmD17NmbPnm33uY0bN1p9f/z48cYfUFM5uQ2oLgcSugGtJWt0JMci41RhGzj1lduwWOC2L4CVM4DMdcCyGwBjFFBRBHQYCYx6FOg4sgnfCBERERFRy+bzBXADWtcrgIcPAFe/Aeh0KCitRN6FCgBA56RIIMwicApvZT1vyRgJ3LgcuOhmAIoETQDw2w/yHBEREREReY1fZJwCWkxr+YJWppcWE4pIY5B14JTSV+YvWTIES9A1+gmgqlQeC4sDwu0vBkxERERERPXDwMmPqIFT56TajFGERZMHtUzPnmh20CMiIiIiakws1fMjWmOIKHmg7RCg4yi5n+J4rSoiIiIiImpczDj5EavGEKpbVgH5x6STHhERERER+QQDJz9izjglWwROegOQ0MVHIyIiIiIiIoClen6jpKIapwvKAABdEtkVj4iIiIjInzBw8hO/5pYAABIiQxAXEeLj0RARERERkSUGTj5UWFaFwrIqAMCRnGIAQGdmm4iIiIiI/A7nOPnQyp0n8X9fHkSv1GjzEk1W85uIiIiIiMgvMHDyoV/zSqAowIGsIvNj5lbkRERERETkNxg4+dBfpvTFQ2O6YuuxfGz79RwKy6owuX9rXw+LiIiIiIhsMHDysaToUFyVnoar0tN8PRQiIiIiInKAzSGIiIiIiIhcYOBERERERETkAgMnIiIiIiIiFxg4ERERERERucDAiYiIiIiIyAUGTkRERERERC4wcCIiIiIiInKBgRMREREREZELDJyIiIiIiIhcYOBERERERETkAgMnIiIiIiIiFxg4ERERERERucDAiYiIiIiIyAUGTkRERERERC4wcCIiIiIiInKBgRMREREREZELDJyIiIiIiIhcYOBERERERETkQpCvB9DUFEUBABQVFfl4JERERERE5EtqTKDGCM4EXOBUXFwMAGjbtq2PR0JERERERP6guLgYMTExTrfRKe6EVy2IyWRCVlYWoqKioNPpfD0cFBUVoW3btjh58iSio6N9PRxqBnjMkKd4zFB98LghT/GYofrw9XGjKAqKi4uRlpYGvd75LKaAyzjp9Xq0adPG18OoIzo6mh8y5BEeM+QpHjNUHzxuyFM8Zqg+fHncuMo0qdgcgoiIiIiIyAUGTkRERERERC4wcPIxo9GI+fPnw2g0+noo1EzwmCFP8Zih+uBxQ57iMUP10ZyOm4BrDkFEREREROQpZpyIiIiIiIhcYOBERERERETkAgMnIiIiIiIiFxg4ERERERERucDAyYfeeOMNdOjQAaGhoRg6dCi2b9/u6yGRn3j66aeh0+msvnr06GF+vry8HLNmzUKrVq0QGRmJqVOn4uzZsz4cMfnCpk2bMGnSJKSlpUGn02H16tVWzyuKgqeeegqpqakICwtDRkYGjhw5YrVNfn4+pk+fjujoaMTGxuLOO+/EhQsXmvBdUFNydczcdtttdT57xo8fb7UNj5nAsmDBAgwePBhRUVFISkrC5MmTcfjwYatt3PmbdOLECUycOBHh4eFISkrCI488gurq6qZ8K9SE3DluLrvssjqfNzNnzrTaxt+OGwZOPrJixQrMmTMH8+fPx+7du5Geno5x48YhJyfH10MjP9G7d2+cOXPG/LV582bzcw8//DA+++wzrFy5Et9++y2ysrJwzTXX+HC05AslJSVIT0/HG2+8Yff5hQsX4u9//zsWL16Mbdu2ISIiAuPGjUN5ebl5m+nTp+PAgQNYu3YtPv/8c2zatAl33313U70FamKujhkAGD9+vNVnz7Jly6ye5zETWL799lvMmjULW7duxdq1a1FVVYWxY8eipKTEvI2rv0k1NTWYOHEiKisr8cMPP+Ddd9/F0qVL8dRTT/niLVETcOe4AYC77rrL6vNm4cKF5uf88rhRyCeGDBmizJo1y/x9TU2NkpaWpixYsMCHoyJ/MX/+fCU9Pd3ucwUFBUpwcLCycuVK82MHDx5UAChbtmxpohGSvwGgrFq1yvy9yWRSUlJSlBdeeMH8WEFBgWI0GpVly5YpiqIoP//8swJA2bFjh3mbr776StHpdMrp06ebbOzkG7bHjKIoyowZM5Srr77a4Wt4zFBOTo4CQPn2228VRXHvb9KXX36p6PV6JTs727zNokWLlOjoaKWioqJp3wD5hO1xoyiKMmrUKOXBBx90+Bp/PG6YcfKByspK7Nq1CxkZGebH9Ho9MjIysGXLFh+OjPzJkSNHkJaWhk6dOmH69Ok4ceIEAGDXrl2oqqqyOn569OiBdu3a8fghs2PHjiE7O9vqOImJicHQoUPNx8mWLVsQGxuLQYMGmbfJyMiAXq/Htm3bmnzM5B82btyIpKQkdO/eHffeey/OnTtnfo7HDBUWFgIA4uPjAbj3N2nLli3o27cvkpOTzduMGzcORUVFOHDgQBOOnnzF9rhRvf/++0hISECfPn3w2GOPobS01PycPx43QT75VwNcXl4eampqrA4EAEhOTsahQ4d8NCryJ0OHDsXSpUvRvXt3nDlzBs888wxGjhyJ/fv3Izs7GyEhIYiNjbV6TXJyMrKzs30zYPI76rFg73NGfS47OxtJSUlWzwcFBSE+Pp7HUoAaP348rrnmGnTs2BFHjx7F448/jgkTJmDLli0wGAw8ZgKcyWTCQw89hBEjRqBPnz4A4NbfpOzsbLufRepz1LLZO24A4KabbkL79u2RlpaGvXv34tFHH8Xhw4fx8ccfA/DP44aBE5EfmjBhgvl+v379MHToULRv3x7//e9/ERYW5sOREVFLdsMNN5jv9+3bF/369UPnzp2xceNGjBkzxocjI38wa9Ys7N+/32rOLZErjo4by7mRffv2RWpqKsaMGYOjR4+ic+fOTT1Mt7BUzwcSEhJgMBjqdJw5e/YsUlJSfDQq8mexsbHo1q0bMjMzkZKSgsrKShQUFFhtw+OHLKnHgrPPmZSUlDoNaaqrq5Gfn89jiQAAnTp1QkJCAjIzMwHwmAlks2fPxueff44NGzagTZs25sfd+ZuUkpJi97NIfY5aLkfHjT1Dhw4FAKvPG387bhg4+UBISAgGDhyI9evXmx8zmUxYv349hg8f7sORkb+6cOECjh49itTUVAwcOBDBwcFWx8/hw4dx4sQJHj9k1rFjR6SkpFgdJ0VFRdi2bZv5OBk+fDgKCgqwa9cu8zbffPMNTCaT+Q8YBbZTp07h3LlzSE1NBcBjJhApioLZs2dj1apV+Oabb9CxY0er5935mzR8+HDs27fPKuheu3YtoqOj0atXr6Z5I9SkXB039uzZswcArD5v/O648UlLClKWL1+uGI1GZenSpcrPP/+s3H333UpsbKxV5xAKXHPnzlU2btyoHDt2TPn++++VjIwMJSEhQcnJyVEURVFmzpyptGvXTvnmm2+UnTt3KsOHD1eGDx/u41FTUysuLlZ+/PFH5ccff1QAKC+99JLy448/Kr/99puiKIry/PPPK7Gxsconn3yi7N27V7n66quVjh07KmVlZeZ9jB8/XrnooouUbdu2KZs3b1a6du2q3Hjjjb56S9TInB0zxcXFyrx585QtW7Yox44dU9atW6cMGDBA6dq1q1JeXm7eB4+ZwHLvvfcqMTExysaNG5UzZ86Yv0pLS83buPqbVF1drfTp00cZO3assmfPHmXNmjVKYmKi8thjj/niLVETcHXcZGZmKs8++6yyc+dO5dixY8onn3yidOrUSbn00kvN+/DH44aBkw+99tprSrt27ZSQkBBlyJAhytatW309JPIT06ZNU1JTU5WQkBCldevWyrRp05TMzEzz82VlZcp9992nxMXFKeHh4cqUKVOUM2fO+HDE5AsbNmxQANT5mjFjhqIo0pL8ySefVJKTkxWj0aiMGTNGOXz4sNU+zp07p9x4441KZGSkEh0drdx+++1KcXGxD94NNQVnx0xpaakyduxYJTExUQkODlbat2+v3HXXXXUu6PGYCSz2jhcAyjvvvGPexp2/ScePH1cmTJighIWFKQkJCcrcuXOVqqqqJn431FRcHTcnTpxQLr30UiU+Pl4xGo1Kly5dlEceeUQpLCy02o+/HTc6RVGUpstvERERERERNT+c40REREREROQCAyciIiIiIiIXGDgRERERERG5wMCJiIiIiIjIBQZORERERERELjBwIiIiIiIicoGBExERERERkQsMnIiIiIiIiFxg4EREROQBnU6H1atX+3oYRETUxBg4ERFRs3HbbbdBp9PV+Ro/fryvh0ZERC1ckK8HQERE5Inx48fjnXfesXrMaDT6aDRERBQomHEiIqJmxWg0IiUlxeorLi4OgJTRLVq0CBMmTEBYWBg6deqEDz/80Or1+/btw+WXX46wsDC0atUKd999Ny5cuGC1zdtvv43evXvDaDQiNTUVs2fPtno+Ly8PU6ZMQXh4OLp27YpPP/20cd80ERH5HAMnIiJqUZ588klMnToVP/30E6ZPn44bbrgBBw8eBACUlJRg3LhxiIuLw44dO7By5UqsW7fOKjBatGgRZs2ahbvvvhv79u3Dp59+ii5dulj9G8888wyuv/567N27F1deeSWmT5+O/Pz8Jn2fRETUtHSKoii+HgQREZE7brvtNrz33nsIDQ21evzxxx/H448/Dp1Oh5kzZ2LRokXm54YNG4YBAwbgH//4B5YsWYJHH30UJ0+eREREBADgyy+/xKRJk5CVlYXk5GS0bt0at99+O/785z/bHYNOp8MTTzyB5557DoAEY5GRkfjqq68414qIqAXjHCciImpWRo8ebRUYAUB8fLz5/vDhw62eGz58OPbs2QMAOHjwINLT081BEwCMGDECJpMJhw8fhk6nQ1ZWFsaMGeN0DP369TPfj4iIQHR0NHJycur7loiIqBlg4ERERM1KREREndI5bwkLC3Nru+DgYKvvdTodTCZTYwyJiIj8BOc4ERFRi7J169Y63/fs2RMA0LNnT/z0008oKSkxP//9999Dr9eje/fuiIqKQocOHbB+/fomHTMREfk/ZpyIiKhZqaioQHZ2ttVjQUFBSEhIAACsXLkSgwYNwiWXXIL3338f27dvx1tvvQUAmD59OubPn48ZM2bg6aefRm5uLu6//37ccsstSE5OBgA8/fTTmDlzJpKSkjBhwgQUFxfj+++/x/3339+0b5SIiPwKAyciImpW1qxZg9TUVKvHunfvjkOHDgGQjnfLly/Hfffdh9TUVCxbtgy9evUCAISHh+Prr7/Ggw8+iMGDByM8PBxTp07FSy+9ZN7XjBkzUF5ejpdffhnz5s1DQkICrr322qZ7g0RE5JfYVY+IiFoMnU6HVatWYfLkyb4eChERtTCc40REREREROQCAyciIiIiIiIXOMeJiIhaDFafExFRY2HGiYiIiIiIyAUGTkRERERERC4wcCIiIiIiInKBgRMREREREZELDJyIiIiIiIhcYOBERERERETkAgMnIiIiIiIiFxg4ERERERERufD/6WbMbDr5Q24AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming x_train_sc has shape (number_of_samples, number_of_features)\n",
    "# Make sure to replace 'number_of_features' with the actual number of features in your data.\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=128, input_dim=x_train_sc.shape[1], activation='tanh'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(units=len(y_train.unique()), activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Print the model summary\n",
    "# model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# Custom callback for logging test accuracy at each epoch\n",
    "class TestAccuracyLogger(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        super().__init__()\n",
    "        self.test_data = test_data\n",
    "        self.test_accuracies = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        _, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        self.test_accuracies.append(test_accuracy)\n",
    "        print(f'Test Accuracy after Epoch {epoch + 1}: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Assuming x_test_sc and y_test are your test data and labels\n",
    "# Also, replace 'num_classes' with the actual number of classes in your classification task.\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "test_accuracy_logger = TestAccuracyLogger(test_data=(x_test_sc, y_test_encoded))\n",
    "\n",
    "# Fit the model with the custom callback\n",
    "history = model.fit(x_train_sc, y_encoded, epochs=250, batch_size=32, validation_split=0.1, callbacks=[test_accuracy_logger])\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(test_accuracy_logger.test_accuracies, label='Test Accuracy', linestyle='dashed')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # Fit the model\n",
    "# # print(x_train_sc)\n",
    "# model.fit(x_train_sc, y_encoded, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# # # Evaluate the model on the test set\n",
    "# test_loss, test_accuracy = model.evaluate(x_test_sc, y_test_encoded)\n",
    "# print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae478df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "print(x_train_sc.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 568973,
     "sourceId": 1032238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 319.866664,
   "end_time": "2024-01-11T05:50:17.106287",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-11T05:44:57.239623",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
