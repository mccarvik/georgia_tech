{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcb0642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:01.238455Z",
     "iopub.status.busy": "2024-01-11T05:45:01.237988Z",
     "iopub.status.idle": "2024-01-11T05:45:22.452939Z",
     "shell.execute_reply": "2024-01-11T05:45:22.451641Z"
    },
    "papermill": {
     "duration": 21.228331,
     "end_time": "2024-01-11T05:45:22.456076",
     "exception": false,
     "start_time": "2024-01-11T05:45:01.227745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 1 - music genre classification\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import pdb\n",
    "sys.path.append(\"C:\\\\users\\\\mccar\\\\miniconda3\\\\lib\\\\site-packages\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import validation_curve, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from utils import learn_curve, val_curve\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1deffdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:22.476225Z",
     "iopub.status.busy": "2024-01-11T05:45:22.475656Z",
     "iopub.status.idle": "2024-01-11T05:45:23.739387Z",
     "shell.execute_reply": "2024-01-11T05:45:23.736447Z"
    },
    "papermill": {
     "duration": 1.277192,
     "end_time": "2024-01-11T05:45:23.742359",
     "exception": false,
     "start_time": "2024-01-11T05:45:22.465167",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features_30_sec.csv']\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "file_path = \"data/gtzan_music_genre/\"\n",
    "print(os.listdir(f'{file_path}/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3bcf8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:23.769832Z",
     "iopub.status.busy": "2024-01-11T05:45:23.769185Z",
     "iopub.status.idle": "2024-01-11T05:45:38.438753Z",
     "shell.execute_reply": "2024-01-11T05:45:38.437541Z"
    },
    "papermill": {
     "duration": 14.686168,
     "end_time": "2024-01-11T05:45:38.441264",
     "exception": false,
     "start_time": "2024-01-11T05:45:23.755096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sound, sample_rate = librosa.load(f'{file_path}/genres_original/classical/classical.00005.wav')\n",
    "# print(sound[:5])\n",
    "# print(sample_rate)\n",
    "\n",
    "# plt.figure(figsize=(16, 6))\n",
    "# librosa.display.waveshow(y=sound, sr=sample_rate, color=\"darkred\")\n",
    "# plt.title(\"Waveform of classical.00005.wav\", fontsize=12)  \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aed6c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:38.472531Z",
     "iopub.status.busy": "2024-01-11T05:45:38.471893Z",
     "iopub.status.idle": "2024-01-11T05:45:39.554517Z",
     "shell.execute_reply": "2024-01-11T05:45:39.553259Z"
    },
    "papermill": {
     "duration": 1.10268,
     "end_time": "2024-01-11T05:45:39.557909",
     "exception": false,
     "start_time": "2024-01-11T05:45:38.455229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sound_rock, sample_rate_rock = librosa.load(f'{file_path}/genres_original/rock/rock.00017.wav')\n",
    "# print(sound_rock[:5])\n",
    "# print(sample_rate_rock)\n",
    "\n",
    "# plt.figure(figsize = (16,6))\n",
    "# librosa.display.waveshow(y = sound_rock, sr = sample_rate_rock, color = 'darkred')\n",
    "# plt.title('Wavefrom of rock.00017.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b1b9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.592249Z",
     "iopub.status.busy": "2024-01-11T05:45:39.591810Z",
     "iopub.status.idle": "2024-01-11T05:45:39.657703Z",
     "shell.execute_reply": "2024-01-11T05:45:39.655729Z"
    },
    "papermill": {
     "duration": 0.086344,
     "end_time": "2024-01-11T05:45:39.660995",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.574651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_fft = 2048 # FFT window size\n",
    "# hop_length = 512 # number audio of frames between STFT columns (looks like a good default)\n",
    "\n",
    "# # Short-time Fourier transform (STFT)\n",
    "# D = np.abs(librosa.stft(sound_rock, n_fft = n_fft, hop_length = hop_length))\n",
    "\n",
    "# print('Shape of D object:', np.shape(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e617f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.695494Z",
     "iopub.status.busy": "2024-01-11T05:45:39.695066Z",
     "iopub.status.idle": "2024-01-11T05:45:39.796498Z",
     "shell.execute_reply": "2024-01-11T05:45:39.795102Z"
    },
    "papermill": {
     "duration": 0.121206,
     "end_time": "2024-01-11T05:45:39.799409",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.678203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 60)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 60 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   filename                 1000 non-null   object \n",
      " 1   length                   1000 non-null   int64  \n",
      " 2   chroma_stft_mean         1000 non-null   float64\n",
      " 3   chroma_stft_var          1000 non-null   float64\n",
      " 4   rms_mean                 1000 non-null   float64\n",
      " 5   rms_var                  1000 non-null   float64\n",
      " 6   spectral_centroid_mean   1000 non-null   float64\n",
      " 7   spectral_centroid_var    1000 non-null   float64\n",
      " 8   spectral_bandwidth_mean  1000 non-null   float64\n",
      " 9   spectral_bandwidth_var   1000 non-null   float64\n",
      " 10  rolloff_mean             1000 non-null   float64\n",
      " 11  rolloff_var              1000 non-null   float64\n",
      " 12  zero_crossing_rate_mean  1000 non-null   float64\n",
      " 13  zero_crossing_rate_var   1000 non-null   float64\n",
      " 14  harmony_mean             1000 non-null   float64\n",
      " 15  harmony_var              1000 non-null   float64\n",
      " 16  perceptr_mean            1000 non-null   float64\n",
      " 17  perceptr_var             1000 non-null   float64\n",
      " 18  tempo                    1000 non-null   float64\n",
      " 19  mfcc1_mean               1000 non-null   float64\n",
      " 20  mfcc1_var                1000 non-null   float64\n",
      " 21  mfcc2_mean               1000 non-null   float64\n",
      " 22  mfcc2_var                1000 non-null   float64\n",
      " 23  mfcc3_mean               1000 non-null   float64\n",
      " 24  mfcc3_var                1000 non-null   float64\n",
      " 25  mfcc4_mean               1000 non-null   float64\n",
      " 26  mfcc4_var                1000 non-null   float64\n",
      " 27  mfcc5_mean               1000 non-null   float64\n",
      " 28  mfcc5_var                1000 non-null   float64\n",
      " 29  mfcc6_mean               1000 non-null   float64\n",
      " 30  mfcc6_var                1000 non-null   float64\n",
      " 31  mfcc7_mean               1000 non-null   float64\n",
      " 32  mfcc7_var                1000 non-null   float64\n",
      " 33  mfcc8_mean               1000 non-null   float64\n",
      " 34  mfcc8_var                1000 non-null   float64\n",
      " 35  mfcc9_mean               1000 non-null   float64\n",
      " 36  mfcc9_var                1000 non-null   float64\n",
      " 37  mfcc10_mean              1000 non-null   float64\n",
      " 38  mfcc10_var               1000 non-null   float64\n",
      " 39  mfcc11_mean              1000 non-null   float64\n",
      " 40  mfcc11_var               1000 non-null   float64\n",
      " 41  mfcc12_mean              1000 non-null   float64\n",
      " 42  mfcc12_var               1000 non-null   float64\n",
      " 43  mfcc13_mean              1000 non-null   float64\n",
      " 44  mfcc13_var               1000 non-null   float64\n",
      " 45  mfcc14_mean              1000 non-null   float64\n",
      " 46  mfcc14_var               1000 non-null   float64\n",
      " 47  mfcc15_mean              1000 non-null   float64\n",
      " 48  mfcc15_var               1000 non-null   float64\n",
      " 49  mfcc16_mean              1000 non-null   float64\n",
      " 50  mfcc16_var               1000 non-null   float64\n",
      " 51  mfcc17_mean              1000 non-null   float64\n",
      " 52  mfcc17_var               1000 non-null   float64\n",
      " 53  mfcc18_mean              1000 non-null   float64\n",
      " 54  mfcc18_var               1000 non-null   float64\n",
      " 55  mfcc19_mean              1000 non-null   float64\n",
      " 56  mfcc19_var               1000 non-null   float64\n",
      " 57  mfcc20_mean              1000 non-null   float64\n",
      " 58  mfcc20_var               1000 non-null   float64\n",
      " 59  label                    1000 non-null   object \n",
      "dtypes: float64(57), int64(1), object(2)\n",
      "memory usage: 468.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('display.max_columns', 60)\n",
    "train_df = pd.read_csv(f'{file_path}/features_30_sec.csv')\n",
    "train_df.head()\n",
    "print(train_df.shape)\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ebfd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.833663Z",
     "iopub.status.busy": "2024-01-11T05:45:39.832566Z",
     "iopub.status.idle": "2024-01-11T05:45:40.641774Z",
     "shell.execute_reply": "2024-01-11T05:45:40.640665Z"
    },
    "papermill": {
     "duration": 0.829401,
     "end_time": "2024-01-11T05:45:40.644815",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.815414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# label_tempo_df= train_df[['label', 'tempo']]\n",
    "\n",
    "# f, ax = plt.subplots(figsize = (16,9))\n",
    "# sns.boxplot(x = 'label', y = 'tempo', data = label_tempo_df, palette = 'rocket' )\n",
    "\n",
    "# plt.title('BPM Boxplot for Genres', fontsize = 15)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.xlabel('Genre', fontsize = 20)\n",
    "# plt.ylabel('BPM', fontsize = 20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7497a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "train_df = train_df.drop(['filename', 'length'], axis = 1)\n",
    "y = train_df['label']\n",
    "X = train_df.drop('label', axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82a823f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:40.680821Z",
     "iopub.status.busy": "2024-01-11T05:45:40.680116Z",
     "iopub.status.idle": "2024-01-11T05:45:41.294675Z",
     "shell.execute_reply": "2024-01-11T05:45:41.292817Z"
    },
    "papermill": {
     "duration": 0.640956,
     "end_time": "2024-01-11T05:45:41.302621",
     "exception": false,
     "start_time": "2024-01-11T05:45:40.661665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cols = X.columns\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# np_scaled = min_max_scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(np_scaled, columns = cols)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components = 2)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "# finalDf = pd.concat([principalDf, y], axis = 1)\n",
    "# print('variance ratio : ', pca.explained_variance_ratio_)\n",
    "# print('sum : ', sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341d4d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:41.411559Z",
     "iopub.status.busy": "2024-01-11T05:45:41.411130Z",
     "iopub.status.idle": "2024-01-11T05:45:41.744452Z",
     "shell.execute_reply": "2024-01-11T05:45:41.743084Z"
    },
    "papermill": {
     "duration": 0.382564,
     "end_time": "2024-01-11T05:45:41.747565",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.365001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pca = PCA(whiten = True).fit(X)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d078f89",
   "metadata": {
    "papermill": {
     "duration": 0.016425,
     "end_time": "2024-01-11T05:45:41.780771",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.764346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1efdb122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:41.816931Z",
     "iopub.status.busy": "2024-01-11T05:45:41.815973Z",
     "iopub.status.idle": "2024-01-11T05:45:42.199666Z",
     "shell.execute_reply": "2024-01-11T05:45:42.198158Z"
    },
    "papermill": {
     "duration": 0.405254,
     "end_time": "2024-01-11T05:45:42.202781",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.797527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e63aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:42.240883Z",
     "iopub.status.busy": "2024-01-11T05:45:42.240160Z",
     "iopub.status.idle": "2024-01-11T05:45:42.716199Z",
     "shell.execute_reply": "2024-01-11T05:45:42.715014Z"
    },
    "papermill": {
     "duration": 0.498045,
     "end_time": "2024-01-11T05:45:42.718870",
     "exception": false,
     "start_time": "2024-01-11T05:45:42.220825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba895e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:42.756639Z",
     "iopub.status.busy": "2024-01-11T05:45:42.756172Z",
     "iopub.status.idle": "2024-01-11T05:45:42.776635Z",
     "shell.execute_reply": "2024-01-11T05:45:42.775324Z"
    },
    "papermill": {
     "duration": 0.042967,
     "end_time": "2024-01-11T05:45:42.779761",
     "exception": false,
     "start_time": "2024-01-11T05:45:42.736794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# More preprocessing\n",
    "scale = MinMaxScaler()\n",
    "scaled_data = scale.fit_transform(x_train)\n",
    "x_train_sc = pd.DataFrame(scaled_data, columns = x_train.columns).values\n",
    "scaled_data = scale.fit_transform(x_test)\n",
    "x_test_sc = pd.DataFrame(scaled_data, columns = x_test.columns).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e16493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K val: 1   acc: 0.395\n",
      "K val: 2   acc: 0.495\n",
      "K val: 3   acc: 0.485\n",
      "K val: 4   acc: 0.53\n",
      "K val: 5   acc: 0.56\n",
      "K val: 6   acc: 0.555\n",
      "K val: 7   acc: 0.55\n",
      "K val: 8   acc: 0.585\n",
      "K val: 9   acc: 0.605\n",
      "K val: 10   acc: 0.66\n",
      "Train accs:  {1.0: 0.42, 2.0: 0.505, 3.0: 0.56, 4.0: 0.61375, 5.0: 0.65625, 6.0: 0.68375, 7.0: 0.70125, 8.0: 0.74125, 9.0: 0.7575, 10.0: 0.77875}\n",
      "Test accs:  {1.0: 0.395, 2.0: 0.495, 3.0: 0.485, 4.0: 0.53, 5.0: 0.56, 6.0: 0.555, 7.0: 0.55, 8.0: 0.585, 9.0: 0.605, 10.0: 0.66}\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "# Curve based on value of K - Validation curve\n",
    "val_knn = False\n",
    "if val_knn:\n",
    "    k_accs = {}\n",
    "    for k_val in range(1,24):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "        knn.fit(x_train_sc, y_train)\n",
    "        y_pred = knn.predict(x_test_sc)\n",
    "        k_accs[k_val] = accuracy_score(y_test, y_pred)\n",
    "        print(\"K val: {}   acc: {}\".format(k_val, k_accs[k_val]))\n",
    "    val_curve(list(k_accs.keys()), list(k_accs.values()), \"knn_music\", \"value for K\")\n",
    "\n",
    "learn_knn = True\n",
    "if learn_knn:\n",
    "    # Shuffle the data without replacement - Learning curve\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        # shuffled_data = shuffle(x_train, random_state=RANDOM_SEED)\n",
    "        x_percent_index = int(x_perc * len(x_train_sc))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "        knn = KNeighborsClassifier(n_neighbors=7)\n",
    "        knn.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = knn.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = knn.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"K val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    # learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"knn_music\")\n",
    "    print(\"Train accs: \", train_accs)\n",
    "    print(\"Test accs: \", x_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9404c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - hyperparameter tuning - Validation curve\n",
    "dt_max_depth = False\n",
    "\n",
    "if dt_max_depth:\n",
    "    # Max Depth\n",
    "    # Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "    param_range = np.arange(1, 31)\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train, y_train, param_name=\"max_depth\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Max Depth\")\n",
    "    plt.xlabel(\"Max Depth\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_max_depth_music.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "058beef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min samples to split\n",
    "# Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "dt_min_split = False\n",
    "\n",
    "if dt_min_split:\n",
    "    param_range = np.arange(0, 15)\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train_sc, y_train, param_name=\"min_samples_split\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    print(test_scores_mean)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Min Samples Split\")\n",
    "    plt.xlabel(\"Min Samples Split\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_min_samples_split_music.png\", dpi=300)\n",
    "    # plt.savefig(\"pngs/validation_curve_dt_min_samples_leaf.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c30b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion\n",
    "crit = False\n",
    "\n",
    "if crit:\n",
    "    # Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "    param_range = ['gini', 'entropy']\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=13)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train, y_train, param_name=\"criterion\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    print(test_scores_mean)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Criterion\")\n",
    "    plt.xlabel(\"Criterion\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.xticks(['gini', 'entropy'])\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_criterion_music.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493883e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Perc val: 1   acc: 0.32\n",
      "0.2\n",
      "Perc val: 2   acc: 0.3\n",
      "0.3\n",
      "Perc val: 3   acc: 0.4\n",
      "0.4\n",
      "Perc val: 4   acc: 0.405\n",
      "0.5\n",
      "Perc val: 5   acc: 0.43\n",
      "0.6\n",
      "Perc val: 6   acc: 0.48\n",
      "0.7\n",
      "Perc val: 7   acc: 0.475\n",
      "0.8\n",
      "Perc val: 8   acc: 0.485\n",
      "0.9\n",
      "Perc val: 9   acc: 0.445\n",
      "1.0\n",
      "Perc val: 10   acc: 0.5\n",
      "Train accs:  {1.0: 0.45625, 2.0: 0.485, 3.0: 0.6375, 4.0: 0.69875, 5.0: 0.7425, 6.0: 0.78, 7.0: 0.86125, 8.0: 0.9025, 9.0: 0.9525, 10.0: 0.99875}\n",
      "Test accs:  {1.0: 0.32, 2.0: 0.3, 3.0: 0.4, 4.0: 0.405, 5.0: 0.43, 6.0: 0.48, 7.0: 0.475, 8.0: 0.485, 9.0: 0.445, 10.0: 0.5}\n"
     ]
    }
   ],
   "source": [
    "# DT - Amount of data - Learning curve\n",
    "l_curve = True\n",
    "\n",
    "if l_curve:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        print(x_perc)\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "        dec_tree = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "        dec_tree.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = dec_tree.predict(x_test)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = dec_tree.predict(x_train)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    # learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"dec_tree_music\")\n",
    "    print(\"Train accs: \", train_accs)\n",
    "    print(\"Test accs: \", x_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1bdcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - epochs - Learning curve\n",
    "dt_epoch = False\n",
    "\n",
    "if dt_epoch:\n",
    "    # Number of epochs\n",
    "    epochs = 5\n",
    "\n",
    "    # Initialize the decision tree classifier\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    # Loop through epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "\n",
    "        # Train the decision tree on the training set\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        x_accs[epoch+1] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = dec_tree.predict(x_train)\n",
    "        train_accs[epoch+1] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(epoch+1, x_accs[epoch+1]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"dec_tree_epochs_music\", x_axis=\"Epochs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f82d2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Tree - Hyperparameter tuning - Validation curve\n",
    "boost_gscv = False\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "if boost_gscv:\n",
    "    # Create XGBoost classifier\n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    # Define hyperparameters to tune\n",
    "    param_grid = {\n",
    "        'n_estimators': [15, 50, 150, 200, 250],\n",
    "        'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "        'min_child_weight': [1, 5, 10, 15],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200],\n",
    "        'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "        'min_child_weight': [1, 5, 10, 15],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_classifier,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search.fit(x_train_sc, y_encoded)\n",
    "\n",
    "    # Display the best hyperparameters and corresponding accuracy\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    print(grid_search.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02457455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting tree - Validation curve - max depth\n",
    "bt_md = False\n",
    "\n",
    "if bt_md:\n",
    "    xgb_classifier = XGBClassifier(learning_rate=0.3, min_child_weight=1, max_depth = 7, subsample=0.9, colsample_bytree=1.0)\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": [10, 50, 100, 150, 200, 250]\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_classifier,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search.fit(x_train_sc, y_encoded)\n",
    "\n",
    "    # Display the best hyperparameters and corresponding accuracy\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    param_range = [10, 50, 100, 150, 200, 250]\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    # train_scores_mean = grid_search.cv_results_['mean_train_score']\n",
    "    # train_scores_std = grid_search.cv_results_['std_train_score']\n",
    "    test_scores_mean = grid_search.cv_results_['mean_test_score']\n",
    "    test_scores_std = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Boosting Tree - N Estimators\")\n",
    "    plt.xlabel(\"N Estimators\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    # plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # # Fill the area around the mean training scores\n",
    "    # plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "    #                 train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_bt_n_estimators_music.png\", dpi=300)\n",
    "    # plt.savefig(\"pngs/validation_curve_dt_min_samples_leaf.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b710809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perc val: 1   acc: 0.43\n",
      "Perc val: 2   acc: 0.41\n",
      "Perc val: 3   acc: 0.475\n",
      "Perc val: 4   acc: 0.485\n",
      "Perc val: 5   acc: 0.54\n",
      "Perc val: 6   acc: 0.555\n",
      "Perc val: 7   acc: 0.515\n",
      "Perc val: 8   acc: 0.545\n",
      "Perc val: 9   acc: 0.54\n",
      "Perc val: 10   acc: 0.51\n",
      "Train accs:  {1.0: 0.49625, 2.0: 0.6225, 3.0: 0.725, 4.0: 0.7775, 5.0: 0.8325, 6.0: 0.8775, 7.0: 0.91875, 8.0: 0.94625, 9.0: 0.96875, 10.0: 0.99875}\n",
      "Test accs:  {1.0: 0.43, 2.0: 0.41, 3.0: 0.475, 4.0: 0.485, 5.0: 0.54, 6.0: 0.555, 7.0: 0.515, 8.0: 0.545, 9.0: 0.54, 10.0: 0.51}\n"
     ]
    }
   ],
   "source": [
    "# BT - Learning Curve - amount of data\n",
    "bt_lc = True\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "if bt_lc:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_encoded[:x_percent_index]\n",
    "        xgb_classifier = XGBClassifier(n_estimators=200, learning_rate=0.3, max_depth=7,\n",
    "                                       min_child_weight=1, subsample=0.9, colsample_bytree=1.0)\n",
    "        xgb_classifier.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = xgb_classifier.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test_encoded, y_pred)\n",
    "        y_pred_train = xgb_classifier.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_encoded, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    # learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"boost_tree\")\n",
    "    print(\"Train accs: \", train_accs)\n",
    "    print(\"Test accs: \", x_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf6b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Validation curve - C / kernel func\n",
    "hyper = False\n",
    "\n",
    "\n",
    "if hyper:\n",
    "    # Run through the kernel functions and get validation curves for each hyperparameter\n",
    "    for kern_func in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "\n",
    "        x_perc = 1.0\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "\n",
    "        # Define the hyperparameter values to be tested\n",
    "        param_range = np.logspace(-2, 6, 9)\n",
    "        svm_model = SVC(kernel=kern_func)\n",
    "\n",
    "        # Create a validation curve\n",
    "        train_scores, test_scores = validation_curve(\n",
    "            svm_model, first_x_percent, y_train_iter, param_name=\"C\", param_range=param_range,\n",
    "            cv=3, scoring=\"accuracy\", n_jobs=-1\n",
    "        )\n",
    "        # Plot the validation curves\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Validation Curve for SVM - {}\".format(kern_func))\n",
    "        plt.xlabel(\"C Parameter\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=2)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\", lw=2)\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.savefig(\"pngs/validation_curve_svm_{}_music.png\".format(kern_func), dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0542d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perc val: 1   acc: 0.49\n",
      "Perc val: 2   acc: 0.53\n",
      "Perc val: 3   acc: 0.545\n",
      "Perc val: 4   acc: 0.555\n",
      "Perc val: 5   acc: 0.575\n",
      "Perc val: 6   acc: 0.61\n",
      "Perc val: 7   acc: 0.555\n",
      "Perc val: 8   acc: 0.59\n",
      "Perc val: 9   acc: 0.595\n",
      "Perc val: 10   acc: 0.59\n",
      "Train accs:  {1.0: 0.56125, 2.0: 0.67375, 3.0: 0.74375, 4.0: 0.7875, 5.0: 0.82875, 6.0: 0.86875, 7.0: 0.91125, 8.0: 0.9425, 9.0: 0.9725, 10.0: 0.99875}\n",
      "Test accs:  {1.0: 0.49, 2.0: 0.53, 3.0: 0.545, 4.0: 0.555, 5.0: 0.575, 6.0: 0.61, 7.0: 0.555, 8.0: 0.59, 9.0: 0.595, 10.0: 0.59}\n"
     ]
    }
   ],
   "source": [
    "# SVM - Learning Curve - amount of data\n",
    "svm_lc = True\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "if svm_lc:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_encoded[:x_percent_index]\n",
    "        svm_model = SVC(kernel=\"rbf\", C=100)\n",
    "        svm_model.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = svm_model.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test_encoded, y_pred)\n",
    "        y_pred_train = svm_model.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_encoded, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    # learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"svm\")\n",
    "    print(\"Train accs: \", train_accs)\n",
    "    print(\"Test accs: \", x_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f82e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN - hyperparameter tuning - GridSearchCV\n",
    "nn_hyper = False\n",
    "\n",
    "if nn_hyper:\n",
    "    # Define a function to create the Keras model\n",
    "    def create_model(optimizer='adam', activation='relu', neurons=16):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=x_train_sc.shape[1], activation=activation))\n",
    "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # Wrap Keras model into a function for compatibility with GridSearchCV\n",
    "    keras_model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "        'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "        'neurons': [8, 16, 32]\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=3, \n",
    "                        scoring='accuracy', verbose=9, n_jobs=-1)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    grid_result = grid.fit(x_train_sc, y_train, callbacks=[EarlyStopping(monitor='val_loss', patience=2)])\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "    # Evaluate the model on the test set with the best hyperparameters\n",
    "    best_model = grid_result.best_estimator_\n",
    "    test_accuracy = best_model.score(x_test_sc, y_test)\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4442e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.0625 - loss: 2.3099Test Accuracy after Epoch 1: 12.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1182 - loss: 2.2944 - val_accuracy: 0.2000 - val_loss: 2.2634\n",
      "Epoch 2/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1562 - loss: 2.2793Test Accuracy after Epoch 2: 16.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1773 - loss: 2.2590 - val_accuracy: 0.2000 - val_loss: 2.2154\n",
      "Epoch 3/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2188 - loss: 2.1928Test Accuracy after Epoch 3: 18.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1914 - loss: 2.2171 - val_accuracy: 0.2625 - val_loss: 2.1568\n",
      "Epoch 4/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2812 - loss: 2.1395Test Accuracy after Epoch 4: 21.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2328 - loss: 2.1150 - val_accuracy: 0.2500 - val_loss: 2.0433\n",
      "Epoch 5/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1562 - loss: 2.0555Test Accuracy after Epoch 5: 25.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2299 - loss: 2.0148 - val_accuracy: 0.2500 - val_loss: 2.0001\n",
      "Epoch 6/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2500 - loss: 1.9903Test Accuracy after Epoch 6: 27.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2865 - loss: 1.9018 - val_accuracy: 0.3250 - val_loss: 1.8524\n",
      "Epoch 7/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2188 - loss: 1.9411Test Accuracy after Epoch 7: 28.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2891 - loss: 1.8430 - val_accuracy: 0.4000 - val_loss: 1.7088\n",
      "Epoch 8/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4062 - loss: 1.4806Test Accuracy after Epoch 8: 34.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3347 - loss: 1.6650 - val_accuracy: 0.3125 - val_loss: 1.7455\n",
      "Epoch 9/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3125 - loss: 1.6949Test Accuracy after Epoch 9: 41.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4135 - loss: 1.6229 - val_accuracy: 0.4250 - val_loss: 1.5441\n",
      "Epoch 10/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4375 - loss: 1.4327Test Accuracy after Epoch 10: 42.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4628 - loss: 1.4783 - val_accuracy: 0.4625 - val_loss: 1.4520\n",
      "Epoch 11/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 1.5255Test Accuracy after Epoch 11: 42.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4959 - loss: 1.4004 - val_accuracy: 0.4500 - val_loss: 1.3660\n",
      "Epoch 12/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3125 - loss: 1.5750Test Accuracy after Epoch 12: 47.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4661 - loss: 1.4113 - val_accuracy: 0.5250 - val_loss: 1.3529\n",
      "Epoch 13/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5312 - loss: 1.1767Test Accuracy after Epoch 13: 44.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4977 - loss: 1.3048 - val_accuracy: 0.4750 - val_loss: 1.4003\n",
      "Epoch 14/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4688 - loss: 1.1520Test Accuracy after Epoch 14: 46.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5207 - loss: 1.2272 - val_accuracy: 0.5125 - val_loss: 1.2295\n",
      "Epoch 15/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5625 - loss: 1.1579Test Accuracy after Epoch 15: 45.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5602 - loss: 1.1841 - val_accuracy: 0.5625 - val_loss: 1.2218\n",
      "Epoch 16/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5312 - loss: 1.0900Test Accuracy after Epoch 16: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5760 - loss: 1.1118 - val_accuracy: 0.5125 - val_loss: 1.2209\n",
      "Epoch 17/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.1010Test Accuracy after Epoch 17: 47.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5392 - loss: 1.1547 - val_accuracy: 0.5250 - val_loss: 1.2694\n",
      "Epoch 18/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5625 - loss: 1.1479Test Accuracy after Epoch 18: 41.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5454 - loss: 1.1702 - val_accuracy: 0.6000 - val_loss: 1.1567\n",
      "Epoch 19/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6562 - loss: 1.0598Test Accuracy after Epoch 19: 46.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5756 - loss: 1.1350 - val_accuracy: 0.5625 - val_loss: 1.2166\n",
      "Epoch 20/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 1.3291Test Accuracy after Epoch 20: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5629 - loss: 1.1586 - val_accuracy: 0.5750 - val_loss: 1.1388\n",
      "Epoch 21/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6562 - loss: 1.2040Test Accuracy after Epoch 21: 44.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6097 - loss: 1.0933 - val_accuracy: 0.5375 - val_loss: 1.1981\n",
      "Epoch 22/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 1.2928Test Accuracy after Epoch 22: 47.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5878 - loss: 1.0597 - val_accuracy: 0.5500 - val_loss: 1.1365\n",
      "Epoch 23/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5938 - loss: 0.9423Test Accuracy after Epoch 23: 46.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5978 - loss: 1.0239 - val_accuracy: 0.5625 - val_loss: 1.1445\n",
      "Epoch 24/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5625 - loss: 1.1774Test Accuracy after Epoch 24: 48.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6243 - loss: 0.9764 - val_accuracy: 0.5750 - val_loss: 1.1269\n",
      "Epoch 25/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6875 - loss: 0.7592Test Accuracy after Epoch 25: 48.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6504 - loss: 0.9189 - val_accuracy: 0.6250 - val_loss: 1.1043\n",
      "Epoch 26/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 1.0704Test Accuracy after Epoch 26: 44.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6419 - loss: 0.9837 - val_accuracy: 0.5750 - val_loss: 1.1291\n",
      "Epoch 27/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6250 - loss: 1.0331Test Accuracy after Epoch 27: 47.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6261 - loss: 0.9874 - val_accuracy: 0.5750 - val_loss: 1.1102\n",
      "Epoch 28/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7188 - loss: 0.8028Test Accuracy after Epoch 28: 47.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6300 - loss: 0.9808 - val_accuracy: 0.5250 - val_loss: 1.1076\n",
      "Epoch 29/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4688 - loss: 1.0699Test Accuracy after Epoch 29: 47.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6498 - loss: 0.8990 - val_accuracy: 0.6125 - val_loss: 1.1084\n",
      "Epoch 30/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7188 - loss: 0.8845Test Accuracy after Epoch 30: 46.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6548 - loss: 0.8958 - val_accuracy: 0.6000 - val_loss: 1.0508\n",
      "Epoch 31/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 1.0286Test Accuracy after Epoch 31: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.9019 - val_accuracy: 0.5750 - val_loss: 1.1171\n",
      "Epoch 32/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6250 - loss: 0.9706Test Accuracy after Epoch 32: 45.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6719 - loss: 0.8762 - val_accuracy: 0.6125 - val_loss: 1.0540\n",
      "Epoch 33/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7812 - loss: 0.7092Test Accuracy after Epoch 33: 50.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6594 - loss: 0.8925 - val_accuracy: 0.5875 - val_loss: 1.1980\n",
      "Epoch 34/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6250 - loss: 1.0479Test Accuracy after Epoch 34: 46.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.9300 - val_accuracy: 0.5500 - val_loss: 1.0765\n",
      "Epoch 35/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7188 - loss: 0.7567Test Accuracy after Epoch 35: 47.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6850 - loss: 0.8476 - val_accuracy: 0.6125 - val_loss: 1.0461\n",
      "Epoch 36/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7188 - loss: 0.7470Test Accuracy after Epoch 36: 50.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6914 - loss: 0.8338 - val_accuracy: 0.6000 - val_loss: 1.0823\n",
      "Epoch 37/250\n",
      "\u001b[1m 9/23\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6904 - loss: 0.8472 Test Accuracy after Epoch 37: 50.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6880 - loss: 0.8490 - val_accuracy: 0.6250 - val_loss: 1.0609\n",
      "Epoch 38/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7188 - loss: 0.8487Test Accuracy after Epoch 38: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6799 - loss: 0.8634 - val_accuracy: 0.6250 - val_loss: 1.0762\n",
      "Epoch 39/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6250 - loss: 0.6922Test Accuracy after Epoch 39: 49.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6916 - loss: 0.7934 - val_accuracy: 0.6500 - val_loss: 1.0652\n",
      "Epoch 40/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.5583Test Accuracy after Epoch 40: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6737 - loss: 0.8166 - val_accuracy: 0.6000 - val_loss: 1.0619\n",
      "Epoch 41/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7812 - loss: 0.7806Test Accuracy after Epoch 41: 49.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.7878 - val_accuracy: 0.6375 - val_loss: 1.0278\n",
      "Epoch 42/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5938 - loss: 0.9069Test Accuracy after Epoch 42: 45.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6838 - loss: 0.7955 - val_accuracy: 0.5625 - val_loss: 1.0820\n",
      "Epoch 43/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.8338Test Accuracy after Epoch 43: 49.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7211 - loss: 0.7650 - val_accuracy: 0.5875 - val_loss: 1.0431\n",
      "Epoch 44/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.8499Test Accuracy after Epoch 44: 46.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7071 - loss: 0.8078 - val_accuracy: 0.5875 - val_loss: 1.0269\n",
      "Epoch 45/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5312 - loss: 1.0334Test Accuracy after Epoch 45: 49.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6715 - loss: 0.8257 - val_accuracy: 0.6000 - val_loss: 1.0513\n",
      "Epoch 46/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.5591Test Accuracy after Epoch 46: 50.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7178 - loss: 0.7812 - val_accuracy: 0.6250 - val_loss: 1.0398\n",
      "Epoch 47/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6875 - loss: 0.6889Test Accuracy after Epoch 47: 45.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7101 - loss: 0.7252 - val_accuracy: 0.6125 - val_loss: 1.1264\n",
      "Epoch 48/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6250 - loss: 1.0606Test Accuracy after Epoch 48: 50.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6919 - loss: 0.7962 - val_accuracy: 0.6250 - val_loss: 1.0375\n",
      "Epoch 49/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.7261Test Accuracy after Epoch 49: 49.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7450 - loss: 0.7379 - val_accuracy: 0.6500 - val_loss: 0.9901\n",
      "Epoch 50/250\n",
      "\u001b[1m16/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7254 - loss: 0.7074 Test Accuracy after Epoch 50: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7234 - loss: 0.7114 - val_accuracy: 0.5875 - val_loss: 1.0954\n",
      "Epoch 51/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.6079Test Accuracy after Epoch 51: 48.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.7207 - val_accuracy: 0.6500 - val_loss: 0.9842\n",
      "Epoch 52/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7188 - loss: 0.6083Test Accuracy after Epoch 52: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7378 - loss: 0.6843 - val_accuracy: 0.6125 - val_loss: 1.0492\n",
      "Epoch 53/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5938 - loss: 0.8996Test Accuracy after Epoch 53: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7146 - loss: 0.7301 - val_accuracy: 0.5875 - val_loss: 1.0351\n",
      "Epoch 54/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.4096Test Accuracy after Epoch 54: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.6809 - val_accuracy: 0.6750 - val_loss: 1.0061\n",
      "Epoch 55/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7188 - loss: 0.6890Test Accuracy after Epoch 55: 50.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.6812 - val_accuracy: 0.6000 - val_loss: 1.0178\n",
      "Epoch 56/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.9072Test Accuracy after Epoch 56: 50.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.7316 - val_accuracy: 0.6750 - val_loss: 0.9744\n",
      "Epoch 57/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 0.4585Test Accuracy after Epoch 57: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.6282 - val_accuracy: 0.6375 - val_loss: 1.0207\n",
      "Epoch 58/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8438 - loss: 0.4851Test Accuracy after Epoch 58: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.6632 - val_accuracy: 0.6750 - val_loss: 1.0015\n",
      "Epoch 59/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8125 - loss: 0.4753Test Accuracy after Epoch 59: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 0.6095 - val_accuracy: 0.6500 - val_loss: 0.9677\n",
      "Epoch 60/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7812 - loss: 0.6903Test Accuracy after Epoch 60: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.6639 - val_accuracy: 0.6750 - val_loss: 1.0157\n",
      "Epoch 61/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8125 - loss: 0.4833Test Accuracy after Epoch 61: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7648 - loss: 0.6308 - val_accuracy: 0.6375 - val_loss: 1.0305\n",
      "Epoch 62/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.6263Test Accuracy after Epoch 62: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.6415 - val_accuracy: 0.6500 - val_loss: 1.0071\n",
      "Epoch 63/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6875 - loss: 0.7211Test Accuracy after Epoch 63: 51.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.6433 - val_accuracy: 0.6750 - val_loss: 0.9574\n",
      "Epoch 64/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.5153Test Accuracy after Epoch 64: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7480 - loss: 0.6287 - val_accuracy: 0.5625 - val_loss: 1.1030\n",
      "Epoch 65/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 0.6140Test Accuracy after Epoch 65: 50.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7687 - loss: 0.6252 - val_accuracy: 0.6375 - val_loss: 1.0803\n",
      "Epoch 66/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6250 - loss: 0.8623Test Accuracy after Epoch 66: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.6543 - val_accuracy: 0.6750 - val_loss: 1.0108\n",
      "Epoch 67/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7812 - loss: 0.4795Test Accuracy after Epoch 67: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.5566 - val_accuracy: 0.6875 - val_loss: 1.0208\n",
      "Epoch 68/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8125 - loss: 0.4780Test Accuracy after Epoch 68: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.5717 - val_accuracy: 0.6875 - val_loss: 0.9460\n",
      "Epoch 69/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 0.7797Test Accuracy after Epoch 69: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 0.6206 - val_accuracy: 0.6500 - val_loss: 1.0281\n",
      "Epoch 70/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 0.5210Test Accuracy after Epoch 70: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 0.5706 - val_accuracy: 0.6750 - val_loss: 0.9509\n",
      "Epoch 71/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8438 - loss: 0.5398Test Accuracy after Epoch 71: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7648 - loss: 0.6105 - val_accuracy: 0.6375 - val_loss: 1.0001\n",
      "Epoch 72/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8125 - loss: 0.3872Test Accuracy after Epoch 72: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.5702 - val_accuracy: 0.6750 - val_loss: 1.0049\n",
      "Epoch 73/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7188 - loss: 0.6454Test Accuracy after Epoch 73: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.5872 - val_accuracy: 0.6250 - val_loss: 1.0600\n",
      "Epoch 74/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8125 - loss: 0.5758Test Accuracy after Epoch 74: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8052 - loss: 0.5654 - val_accuracy: 0.6750 - val_loss: 1.0246\n",
      "Epoch 75/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.4835Test Accuracy after Epoch 75: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8288 - loss: 0.4946 - val_accuracy: 0.6500 - val_loss: 1.0285\n",
      "Epoch 76/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7500 - loss: 0.5534Test Accuracy after Epoch 76: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7742 - loss: 0.5516 - val_accuracy: 0.6500 - val_loss: 0.9966\n",
      "Epoch 77/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7812 - loss: 0.6978Test Accuracy after Epoch 77: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.5282 - val_accuracy: 0.6875 - val_loss: 0.9730\n",
      "Epoch 78/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7812 - loss: 0.4787Test Accuracy after Epoch 78: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7888 - loss: 0.5319 - val_accuracy: 0.6875 - val_loss: 0.9458\n",
      "Epoch 79/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8125 - loss: 0.5145Test Accuracy after Epoch 79: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.5208 - val_accuracy: 0.6125 - val_loss: 0.9863\n",
      "Epoch 80/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 229ms/step - accuracy: 0.7188 - loss: 0.6141Test Accuracy after Epoch 80: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.5172 - val_accuracy: 0.7125 - val_loss: 0.9647\n",
      "Epoch 81/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8438 - loss: 0.4154Test Accuracy after Epoch 81: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.5066 - val_accuracy: 0.7000 - val_loss: 0.9742\n",
      "Epoch 82/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7812 - loss: 0.4540Test Accuracy after Epoch 82: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7944 - loss: 0.5079 - val_accuracy: 0.6875 - val_loss: 0.9769\n",
      "Epoch 83/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5938 - loss: 0.7454Test Accuracy after Epoch 83: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7978 - loss: 0.5086 - val_accuracy: 0.6625 - val_loss: 0.9904\n",
      "Epoch 84/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.2993Test Accuracy after Epoch 84: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.4590 - val_accuracy: 0.6000 - val_loss: 1.0555\n",
      "Epoch 85/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.5991Test Accuracy after Epoch 85: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.5195 - val_accuracy: 0.7125 - val_loss: 0.9200\n",
      "Epoch 86/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.4939Test Accuracy after Epoch 86: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8143 - loss: 0.5331 - val_accuracy: 0.7125 - val_loss: 0.9965\n",
      "Epoch 87/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9062 - loss: 0.2717Test Accuracy after Epoch 87: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.4497 - val_accuracy: 0.6875 - val_loss: 1.0196\n",
      "Epoch 88/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 0.7109Test Accuracy after Epoch 88: 51.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.5073 - val_accuracy: 0.6250 - val_loss: 1.0354\n",
      "Epoch 89/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8438 - loss: 0.4344Test Accuracy after Epoch 89: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8297 - loss: 0.4658 - val_accuracy: 0.7125 - val_loss: 1.0256\n",
      "Epoch 90/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8750 - loss: 0.4888Test Accuracy after Epoch 90: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.4710 - val_accuracy: 0.6875 - val_loss: 0.9704\n",
      "Epoch 91/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7500 - loss: 0.6448Test Accuracy after Epoch 91: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7997 - loss: 0.5057 - val_accuracy: 0.6625 - val_loss: 1.0457\n",
      "Epoch 92/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.3883Test Accuracy after Epoch 92: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8264 - loss: 0.4578 - val_accuracy: 0.6250 - val_loss: 1.0532\n",
      "Epoch 93/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9688 - loss: 0.2443Test Accuracy after Epoch 93: 51.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8447 - loss: 0.4405 - val_accuracy: 0.6625 - val_loss: 1.0241\n",
      "Epoch 94/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 0.4226Test Accuracy after Epoch 94: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 0.4570 - val_accuracy: 0.7125 - val_loss: 0.9747\n",
      "Epoch 95/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8125 - loss: 0.4689Test Accuracy after Epoch 95: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.4295 - val_accuracy: 0.6875 - val_loss: 1.0518\n",
      "Epoch 96/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8438 - loss: 0.3773Test Accuracy after Epoch 96: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.4127 - val_accuracy: 0.6500 - val_loss: 1.0430\n",
      "Epoch 97/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.3926 Test Accuracy after Epoch 97: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8688 - loss: 0.4031 - val_accuracy: 0.6625 - val_loss: 0.9366\n",
      "Epoch 98/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9062 - loss: 0.3084Test Accuracy after Epoch 98: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8590 - loss: 0.4031 - val_accuracy: 0.6875 - val_loss: 0.9823\n",
      "Epoch 99/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.5215Test Accuracy after Epoch 99: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.4616 - val_accuracy: 0.6625 - val_loss: 1.0354\n",
      "Epoch 100/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8750 - loss: 0.3164Test Accuracy after Epoch 100: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.3715 - val_accuracy: 0.6875 - val_loss: 1.0307\n",
      "Epoch 101/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8125 - loss: 0.4697Test Accuracy after Epoch 101: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8524 - loss: 0.4070 - val_accuracy: 0.6625 - val_loss: 1.0303\n",
      "Epoch 102/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9062 - loss: 0.3848Test Accuracy after Epoch 102: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.4136 - val_accuracy: 0.7000 - val_loss: 0.9876\n",
      "Epoch 103/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.2093Test Accuracy after Epoch 103: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.3871 - val_accuracy: 0.6750 - val_loss: 1.0102\n",
      "Epoch 104/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.3948Test Accuracy after Epoch 104: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8625 - loss: 0.3987 - val_accuracy: 0.6750 - val_loss: 1.0217\n",
      "Epoch 105/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8438 - loss: 0.4452Test Accuracy after Epoch 105: 52.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.4268 - val_accuracy: 0.6750 - val_loss: 1.0017\n",
      "Epoch 106/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8125 - loss: 0.3845Test Accuracy after Epoch 106: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8553 - loss: 0.3482 - val_accuracy: 0.7000 - val_loss: 1.0148\n",
      "Epoch 107/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8438 - loss: 0.4509Test Accuracy after Epoch 107: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8457 - loss: 0.4094 - val_accuracy: 0.6375 - val_loss: 0.9975\n",
      "Epoch 108/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.4927Test Accuracy after Epoch 108: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.3907 - val_accuracy: 0.6875 - val_loss: 1.0751\n",
      "Epoch 109/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9375 - loss: 0.2418Test Accuracy after Epoch 109: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.3271 - val_accuracy: 0.6625 - val_loss: 1.0172\n",
      "Epoch 110/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8750 - loss: 0.3716Test Accuracy after Epoch 110: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.3818 - val_accuracy: 0.6875 - val_loss: 1.0003\n",
      "Epoch 111/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9062 - loss: 0.4476Test Accuracy after Epoch 111: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.3657 - val_accuracy: 0.6750 - val_loss: 0.9510\n",
      "Epoch 112/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8750 - loss: 0.4391Test Accuracy after Epoch 112: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8765 - loss: 0.3633 - val_accuracy: 0.6750 - val_loss: 1.0738\n",
      "Epoch 113/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9062 - loss: 0.2407Test Accuracy after Epoch 113: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.3813 - val_accuracy: 0.6375 - val_loss: 1.1448\n",
      "Epoch 114/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8125 - loss: 0.4224Test Accuracy after Epoch 114: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.3640 - val_accuracy: 0.6750 - val_loss: 1.0169\n",
      "Epoch 115/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8750 - loss: 0.3466Test Accuracy after Epoch 115: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.3585 - val_accuracy: 0.6625 - val_loss: 1.0437\n",
      "Epoch 116/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8438 - loss: 0.3938Test Accuracy after Epoch 116: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8658 - loss: 0.3549 - val_accuracy: 0.7000 - val_loss: 1.0295\n",
      "Epoch 117/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8438 - loss: 0.4665Test Accuracy after Epoch 117: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.3535 - val_accuracy: 0.6625 - val_loss: 1.0745\n",
      "Epoch 118/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.3741Test Accuracy after Epoch 118: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.3699 - val_accuracy: 0.6375 - val_loss: 1.1265\n",
      "Epoch 119/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8125 - loss: 0.4684Test Accuracy after Epoch 119: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.3441 - val_accuracy: 0.6750 - val_loss: 0.9596\n",
      "Epoch 120/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9375 - loss: 0.2207Test Accuracy after Epoch 120: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8832 - loss: 0.3388 - val_accuracy: 0.7000 - val_loss: 1.0080\n",
      "Epoch 121/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.5281Test Accuracy after Epoch 121: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.3372 - val_accuracy: 0.7000 - val_loss: 1.0514\n",
      "Epoch 122/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8750 - loss: 0.3737Test Accuracy after Epoch 122: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.2932 - val_accuracy: 0.6000 - val_loss: 1.1484\n",
      "Epoch 123/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8750 - loss: 0.3673Test Accuracy after Epoch 123: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8830 - loss: 0.3117 - val_accuracy: 0.6625 - val_loss: 1.1758\n",
      "Epoch 124/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.6150Test Accuracy after Epoch 124: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.3537 - val_accuracy: 0.6875 - val_loss: 1.0570\n",
      "Epoch 125/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7500 - loss: 0.5191Test Accuracy after Epoch 125: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8843 - loss: 0.3078 - val_accuracy: 0.6875 - val_loss: 1.0714\n",
      "Epoch 126/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9688 - loss: 0.2656Test Accuracy after Epoch 126: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.2977 - val_accuracy: 0.6875 - val_loss: 1.0752\n",
      "Epoch 127/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1985Test Accuracy after Epoch 127: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.3011 - val_accuracy: 0.6750 - val_loss: 1.1128\n",
      "Epoch 128/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8438 - loss: 0.3653Test Accuracy after Epoch 128: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8782 - loss: 0.3048 - val_accuracy: 0.7000 - val_loss: 1.0624\n",
      "Epoch 129/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8125 - loss: 0.3651Test Accuracy after Epoch 129: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.2951 - val_accuracy: 0.6500 - val_loss: 1.0259\n",
      "Epoch 130/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.3307Test Accuracy after Epoch 130: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9178 - loss: 0.2683 - val_accuracy: 0.6750 - val_loss: 1.0523\n",
      "Epoch 131/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9688 - loss: 0.1321Test Accuracy after Epoch 131: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9004 - loss: 0.2804 - val_accuracy: 0.6375 - val_loss: 1.2036\n",
      "Epoch 132/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9062 - loss: 0.2515Test Accuracy after Epoch 132: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.3146 - val_accuracy: 0.6875 - val_loss: 1.0974\n",
      "Epoch 133/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9688 - loss: 0.2432Test Accuracy after Epoch 133: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.2965 - val_accuracy: 0.6875 - val_loss: 1.0757\n",
      "Epoch 134/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.3855Test Accuracy after Epoch 134: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.2854 - val_accuracy: 0.6625 - val_loss: 1.1189\n",
      "Epoch 135/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9062 - loss: 0.2897Test Accuracy after Epoch 135: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.2987 - val_accuracy: 0.6125 - val_loss: 1.2495\n",
      "Epoch 136/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8750 - loss: 0.2520Test Accuracy after Epoch 136: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.3122 - val_accuracy: 0.6625 - val_loss: 1.0659\n",
      "Epoch 137/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8750 - loss: 0.2827Test Accuracy after Epoch 137: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.2830 - val_accuracy: 0.6875 - val_loss: 1.0776\n",
      "Epoch 138/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9375 - loss: 0.2005Test Accuracy after Epoch 138: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8853 - loss: 0.2863 - val_accuracy: 0.6625 - val_loss: 1.2232\n",
      "Epoch 139/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.2255Test Accuracy after Epoch 139: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9017 - loss: 0.2668 - val_accuracy: 0.6875 - val_loss: 1.1302\n",
      "Epoch 140/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9688 - loss: 0.1359Test Accuracy after Epoch 140: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9073 - loss: 0.2517 - val_accuracy: 0.7125 - val_loss: 1.0368\n",
      "Epoch 141/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9375 - loss: 0.2964Test Accuracy after Epoch 141: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.2929 - val_accuracy: 0.6750 - val_loss: 1.0877\n",
      "Epoch 142/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1573Test Accuracy after Epoch 142: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.2234 - val_accuracy: 0.6500 - val_loss: 1.0629\n",
      "Epoch 143/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9688 - loss: 0.1880Test Accuracy after Epoch 143: 52.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.2263 - val_accuracy: 0.6875 - val_loss: 1.0981\n",
      "Epoch 144/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0857Test Accuracy after Epoch 144: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9034 - loss: 0.2730 - val_accuracy: 0.6625 - val_loss: 1.2065\n",
      "Epoch 145/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1551Test Accuracy after Epoch 145: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.2188 - val_accuracy: 0.6750 - val_loss: 1.0671\n",
      "Epoch 146/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9375 - loss: 0.1369Test Accuracy after Epoch 146: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9202 - loss: 0.2151 - val_accuracy: 0.6750 - val_loss: 1.1823\n",
      "Epoch 147/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9375 - loss: 0.1833Test Accuracy after Epoch 147: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2275 - val_accuracy: 0.6875 - val_loss: 1.1610\n",
      "Epoch 148/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1356Test Accuracy after Epoch 148: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9341 - loss: 0.2198 - val_accuracy: 0.6875 - val_loss: 1.1631\n",
      "Epoch 149/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2423Test Accuracy after Epoch 149: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9082 - loss: 0.2561 - val_accuracy: 0.6750 - val_loss: 1.1681\n",
      "Epoch 150/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9375 - loss: 0.1612Test Accuracy after Epoch 150: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2330 - val_accuracy: 0.6250 - val_loss: 1.1419\n",
      "Epoch 151/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9062 - loss: 0.2708Test Accuracy after Epoch 151: 53.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9134 - loss: 0.2503 - val_accuracy: 0.6375 - val_loss: 1.2424\n",
      "Epoch 152/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8438 - loss: 0.3758Test Accuracy after Epoch 152: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9035 - loss: 0.2684 - val_accuracy: 0.6375 - val_loss: 1.3204\n",
      "Epoch 153/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8750 - loss: 0.3032Test Accuracy after Epoch 153: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9146 - loss: 0.2356 - val_accuracy: 0.6500 - val_loss: 1.1712\n",
      "Epoch 154/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9062 - loss: 0.2325Test Accuracy after Epoch 154: 53.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9230 - loss: 0.2091 - val_accuracy: 0.6125 - val_loss: 1.2301\n",
      "Epoch 155/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9062 - loss: 0.2582Test Accuracy after Epoch 155: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9108 - loss: 0.2620 - val_accuracy: 0.6625 - val_loss: 1.1239\n",
      "Epoch 156/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9375 - loss: 0.1827Test Accuracy after Epoch 156: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.1853 - val_accuracy: 0.6875 - val_loss: 1.2379\n",
      "Epoch 157/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0344Test Accuracy after Epoch 157: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9114 - loss: 0.2395 - val_accuracy: 0.6500 - val_loss: 1.1937\n",
      "Epoch 158/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9688 - loss: 0.0601Test Accuracy after Epoch 158: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9402 - loss: 0.2078 - val_accuracy: 0.6625 - val_loss: 1.1987\n",
      "Epoch 159/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1493Test Accuracy after Epoch 159: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.1770 - val_accuracy: 0.6625 - val_loss: 1.1960\n",
      "Epoch 160/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9688 - loss: 0.1809Test Accuracy after Epoch 160: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9449 - loss: 0.1885 - val_accuracy: 0.6500 - val_loss: 1.2024\n",
      "Epoch 161/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9688 - loss: 0.1644Test Accuracy after Epoch 161: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.1927 - val_accuracy: 0.6625 - val_loss: 1.3102\n",
      "Epoch 162/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0724Test Accuracy after Epoch 162: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9501 - loss: 0.1590 - val_accuracy: 0.6750 - val_loss: 1.2455\n",
      "Epoch 163/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9688 - loss: 0.1276Test Accuracy after Epoch 163: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1928 - val_accuracy: 0.6500 - val_loss: 1.3801\n",
      "Epoch 164/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9062 - loss: 0.2153Test Accuracy after Epoch 164: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.1796 - val_accuracy: 0.6375 - val_loss: 1.3093\n",
      "Epoch 165/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9688 - loss: 0.1271Test Accuracy after Epoch 165: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.1687 - val_accuracy: 0.6875 - val_loss: 1.0818\n",
      "Epoch 166/250\n",
      "\u001b[1m 9/23\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.1203 Test Accuracy after Epoch 166: 55.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1561 - val_accuracy: 0.6375 - val_loss: 1.2651\n",
      "Epoch 167/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9375 - loss: 0.1562Test Accuracy after Epoch 167: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9320 - loss: 0.1837 - val_accuracy: 0.6750 - val_loss: 1.2966\n",
      "Epoch 168/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9375 - loss: 0.1632Test Accuracy after Epoch 168: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.1504 - val_accuracy: 0.6500 - val_loss: 1.1944\n",
      "Epoch 169/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9688 - loss: 0.1298Test Accuracy after Epoch 169: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1842 - val_accuracy: 0.6125 - val_loss: 1.3268\n",
      "Epoch 170/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.1821Test Accuracy after Epoch 170: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9442 - loss: 0.1670 - val_accuracy: 0.6750 - val_loss: 1.1533\n",
      "Epoch 171/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9375 - loss: 0.2335Test Accuracy after Epoch 171: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9438 - loss: 0.1637 - val_accuracy: 0.6750 - val_loss: 1.2496\n",
      "Epoch 172/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9375 - loss: 0.1898Test Accuracy after Epoch 172: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.1600 - val_accuracy: 0.6750 - val_loss: 1.3237\n",
      "Epoch 173/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9688 - loss: 0.1580Test Accuracy after Epoch 173: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.1381 - val_accuracy: 0.6625 - val_loss: 1.2227\n",
      "Epoch 174/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1151Test Accuracy after Epoch 174: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9463 - loss: 0.1566 - val_accuracy: 0.6000 - val_loss: 1.4554\n",
      "Epoch 175/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9375 - loss: 0.1317Test Accuracy after Epoch 175: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1597 - val_accuracy: 0.6875 - val_loss: 1.3787\n",
      "Epoch 176/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9688 - loss: 0.1114Test Accuracy after Epoch 176: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9459 - loss: 0.1523 - val_accuracy: 0.6375 - val_loss: 1.3235\n",
      "Epoch 177/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9375 - loss: 0.1505Test Accuracy after Epoch 177: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9500 - loss: 0.1515 - val_accuracy: 0.6875 - val_loss: 1.3774\n",
      "Epoch 178/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0870Test Accuracy after Epoch 178: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9663 - loss: 0.1340 - val_accuracy: 0.6625 - val_loss: 1.3310\n",
      "Epoch 179/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0849Test Accuracy after Epoch 179: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.1893 - val_accuracy: 0.6500 - val_loss: 1.2464\n",
      "Epoch 180/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9375 - loss: 0.1287Test Accuracy after Epoch 180: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.1645 - val_accuracy: 0.6625 - val_loss: 1.3738\n",
      "Epoch 181/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0719Test Accuracy after Epoch 181: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9689 - loss: 0.1106 - val_accuracy: 0.6375 - val_loss: 1.3847\n",
      "Epoch 182/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0698Test Accuracy after Epoch 182: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9629 - loss: 0.1250 - val_accuracy: 0.6375 - val_loss: 1.4589\n",
      "Epoch 183/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9375 - loss: 0.1271Test Accuracy after Epoch 183: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.1547 - val_accuracy: 0.6625 - val_loss: 1.5500\n",
      "Epoch 184/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2034Test Accuracy after Epoch 184: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.1681 - val_accuracy: 0.6375 - val_loss: 1.5629\n",
      "Epoch 185/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9688 - loss: 0.1283Test Accuracy after Epoch 185: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9486 - loss: 0.1538 - val_accuracy: 0.6125 - val_loss: 1.5348\n",
      "Epoch 186/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1441 Test Accuracy after Epoch 186: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9548 - loss: 0.1485 - val_accuracy: 0.6375 - val_loss: 1.4127\n",
      "Epoch 187/250\n",
      "\u001b[1m11/23\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9446 - loss: 0.1469 Test Accuracy after Epoch 187: 60.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9458 - loss: 0.1447 - val_accuracy: 0.6750 - val_loss: 1.4195\n",
      "Epoch 188/250\n",
      "\u001b[1m14/23\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.1602 Test Accuracy after Epoch 188: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9500 - loss: 0.1481 - val_accuracy: 0.6125 - val_loss: 1.4530\n",
      "Epoch 189/250\n",
      "\u001b[1m18/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9612 - loss: 0.1155 Test Accuracy after Epoch 189: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9610 - loss: 0.1176 - val_accuracy: 0.6500 - val_loss: 1.4993\n",
      "Epoch 190/250\n",
      "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1115 Test Accuracy after Epoch 190: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9685 - loss: 0.1126 - val_accuracy: 0.6375 - val_loss: 1.4857\n",
      "Epoch 191/250\n",
      "\u001b[1m18/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.0990 Test Accuracy after Epoch 191: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9673 - loss: 0.1011 - val_accuracy: 0.6375 - val_loss: 1.4404\n",
      "Epoch 192/250\n",
      "\u001b[1m12/23\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9603 - loss: 0.1314 Test Accuracy after Epoch 192: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9535 - loss: 0.1396 - val_accuracy: 0.6625 - val_loss: 1.5823\n",
      "Epoch 193/250\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1268 Test Accuracy after Epoch 193: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.1266 - val_accuracy: 0.6375 - val_loss: 1.3887\n",
      "Epoch 194/250\n",
      "\u001b[1m12/23\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.1163 Test Accuracy after Epoch 194: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9668 - loss: 0.1135 - val_accuracy: 0.6625 - val_loss: 1.4435\n",
      "Epoch 195/250\n",
      "\u001b[1m16/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1356 Test Accuracy after Epoch 195: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9481 - loss: 0.1332 - val_accuracy: 0.6625 - val_loss: 1.4123\n",
      "Epoch 196/250\n",
      "\u001b[1m11/23\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.1083 Test Accuracy after Epoch 196: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.1035 - val_accuracy: 0.6250 - val_loss: 1.4957\n",
      "Epoch 197/250\n",
      "\u001b[1m16/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0715 Test Accuracy after Epoch 197: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9805 - loss: 0.0772 - val_accuracy: 0.6500 - val_loss: 1.5025\n",
      "Epoch 198/250\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0809 Test Accuracy after Epoch 198: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9811 - loss: 0.0812 - val_accuracy: 0.6500 - val_loss: 1.4094\n",
      "Epoch 199/250\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0906 Test Accuracy after Epoch 199: 61.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.0904 - val_accuracy: 0.6250 - val_loss: 1.6219\n",
      "Epoch 200/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9688 - loss: 0.1244Test Accuracy after Epoch 200: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0789 - val_accuracy: 0.6750 - val_loss: 1.4054\n",
      "Epoch 201/250\n",
      "\u001b[1m18/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0860 Test Accuracy after Epoch 201: 62.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9714 - loss: 0.0875 - val_accuracy: 0.6250 - val_loss: 1.5461\n",
      "Epoch 202/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.0906 Test Accuracy after Epoch 202: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9723 - loss: 0.0898 - val_accuracy: 0.6250 - val_loss: 1.4828\n",
      "Epoch 203/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0933 Test Accuracy after Epoch 203: 60.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9760 - loss: 0.0927 - val_accuracy: 0.6375 - val_loss: 1.4518\n",
      "Epoch 204/250\n",
      "\u001b[1m12/23\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9633 - loss: 0.1059 Test Accuracy after Epoch 204: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9588 - loss: 0.1125 - val_accuracy: 0.6375 - val_loss: 1.6900\n",
      "Epoch 205/250\n",
      "\u001b[1m20/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.1892 Test Accuracy after Epoch 205: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9299 - loss: 0.1843 - val_accuracy: 0.6875 - val_loss: 1.5358\n",
      "Epoch 206/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.9062 - loss: 0.2020Test Accuracy after Epoch 206: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.1281 - val_accuracy: 0.6375 - val_loss: 1.6640\n",
      "Epoch 207/250\n",
      "\u001b[1m20/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0893 Test Accuracy after Epoch 207: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9756 - loss: 0.0904 - val_accuracy: 0.6250 - val_loss: 1.4857\n",
      "Epoch 208/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0826 Test Accuracy after Epoch 208: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9760 - loss: 0.0836 - val_accuracy: 0.6375 - val_loss: 1.5933\n",
      "Epoch 209/250\n",
      "\u001b[1m14/23\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9621 - loss: 0.1024 Test Accuracy after Epoch 209: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.0998 - val_accuracy: 0.6000 - val_loss: 1.5577\n",
      "Epoch 210/250\n",
      "\u001b[1m20/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.0850 Test Accuracy after Epoch 210: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9760 - loss: 0.0844 - val_accuracy: 0.6500 - val_loss: 1.7064\n",
      "Epoch 211/250\n",
      "\u001b[1m11/23\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9750 - loss: 0.0774 Test Accuracy after Epoch 211: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9743 - loss: 0.0783 - val_accuracy: 0.6375 - val_loss: 1.4790\n",
      "Epoch 212/250\n",
      "\u001b[1m13/23\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0676 Test Accuracy after Epoch 212: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9821 - loss: 0.0703 - val_accuracy: 0.6500 - val_loss: 1.4714\n",
      "Epoch 213/250\n",
      "\u001b[1m16/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0762 Test Accuracy after Epoch 213: 56.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9787 - loss: 0.0799 - val_accuracy: 0.6000 - val_loss: 1.8163\n",
      "Epoch 214/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0685Test Accuracy after Epoch 214: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9715 - loss: 0.1007 - val_accuracy: 0.6250 - val_loss: 1.8712\n",
      "Epoch 215/250\n",
      "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0968 Test Accuracy after Epoch 215: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9654 - loss: 0.0968 - val_accuracy: 0.6500 - val_loss: 1.6007\n",
      "Epoch 216/250\n",
      "\u001b[1m14/23\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0681 Test Accuracy after Epoch 216: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9819 - loss: 0.0745 - val_accuracy: 0.6125 - val_loss: 1.6673\n",
      "Epoch 217/250\n",
      "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.0875 Test Accuracy after Epoch 217: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9716 - loss: 0.0867 - val_accuracy: 0.6625 - val_loss: 1.5649\n",
      "Epoch 218/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0324Test Accuracy after Epoch 218: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9790 - loss: 0.0718 - val_accuracy: 0.6125 - val_loss: 1.5896\n",
      "Epoch 219/250\n",
      "\u001b[1m20/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0467 Test Accuracy after Epoch 219: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9879 - loss: 0.0487 - val_accuracy: 0.6375 - val_loss: 1.5489\n",
      "Epoch 220/250\n",
      "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0553 Test Accuracy after Epoch 220: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0575 - val_accuracy: 0.6125 - val_loss: 1.6679\n",
      "Epoch 221/250\n",
      "\u001b[1m15/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0619 Test Accuracy after Epoch 221: 60.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0619 - val_accuracy: 0.6375 - val_loss: 1.6485\n",
      "Epoch 222/250\n",
      "\u001b[1m12/23\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0539 Test Accuracy after Epoch 222: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0560 - val_accuracy: 0.6375 - val_loss: 1.5153\n",
      "Epoch 223/250\n",
      "\u001b[1m13/23\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0565 Test Accuracy after Epoch 223: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9806 - loss: 0.0612 - val_accuracy: 0.6500 - val_loss: 1.6891\n",
      "Epoch 224/250\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0563 Test Accuracy after Epoch 224: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.0565 - val_accuracy: 0.6000 - val_loss: 1.7899\n",
      "Epoch 225/250\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0627 Test Accuracy after Epoch 225: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9840 - loss: 0.0626 - val_accuracy: 0.6500 - val_loss: 1.5996\n",
      "Epoch 226/250\n",
      "\u001b[1m15/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0530 Test Accuracy after Epoch 226: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9885 - loss: 0.0528 - val_accuracy: 0.6250 - val_loss: 1.7319\n",
      "Epoch 227/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0469Test Accuracy after Epoch 227: 57.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0475 - val_accuracy: 0.6375 - val_loss: 1.6941\n",
      "Epoch 228/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.9688 - loss: 0.0731Test Accuracy after Epoch 228: 58.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0683 - val_accuracy: 0.6000 - val_loss: 1.8798\n",
      "Epoch 229/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9688 - loss: 0.0570Test Accuracy after Epoch 229: 60.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0668 - val_accuracy: 0.6375 - val_loss: 1.8083\n",
      "Epoch 230/250\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0526 Test Accuracy after Epoch 230: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0523 - val_accuracy: 0.6375 - val_loss: 1.8173\n",
      "Epoch 231/250\n",
      "\u001b[1m18/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0458 Test Accuracy after Epoch 231: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9850 - loss: 0.0471 - val_accuracy: 0.6500 - val_loss: 1.6776\n",
      "Epoch 232/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0502 Test Accuracy after Epoch 232: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0530 - val_accuracy: 0.6000 - val_loss: 1.8378\n",
      "Epoch 233/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0252Test Accuracy after Epoch 233: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9872 - loss: 0.0497 - val_accuracy: 0.6250 - val_loss: 1.7012\n",
      "Epoch 234/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9688 - loss: 0.0647Test Accuracy after Epoch 234: 60.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9819 - loss: 0.0589 - val_accuracy: 0.6500 - val_loss: 1.8347\n",
      "Epoch 235/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9688 - loss: 0.0759Test Accuracy after Epoch 235: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9751 - loss: 0.0643 - val_accuracy: 0.6000 - val_loss: 1.7171\n",
      "Epoch 236/250\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0735 Test Accuracy after Epoch 236: 54.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9773 - loss: 0.0753 - val_accuracy: 0.6250 - val_loss: 1.7711\n",
      "Epoch 237/250\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.0873 Test Accuracy after Epoch 237: 61.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9727 - loss: 0.0881 - val_accuracy: 0.6000 - val_loss: 1.6706\n",
      "Epoch 238/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0427Test Accuracy after Epoch 238: 54.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9678 - loss: 0.0968 - val_accuracy: 0.6250 - val_loss: 1.7009\n",
      "Epoch 239/250\n",
      "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0777 Test Accuracy after Epoch 239: 61.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9757 - loss: 0.0792 - val_accuracy: 0.6250 - val_loss: 1.8702\n",
      "Epoch 240/250\n",
      "\u001b[1m18/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0627 Test Accuracy after Epoch 240: 60.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9805 - loss: 0.0622 - val_accuracy: 0.6500 - val_loss: 1.8219\n",
      "Epoch 241/250\n",
      "\u001b[1m17/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.0695 Test Accuracy after Epoch 241: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9819 - loss: 0.0668 - val_accuracy: 0.6000 - val_loss: 1.8910\n",
      "Epoch 242/250\n",
      "\u001b[1m12/23\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9864 - loss: 0.0462 Test Accuracy after Epoch 242: 60.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9878 - loss: 0.0447 - val_accuracy: 0.6375 - val_loss: 1.8418\n",
      "Epoch 243/250\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0540 Test Accuracy after Epoch 243: 58.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9872 - loss: 0.0543 - val_accuracy: 0.6125 - val_loss: 1.8615\n",
      "Epoch 244/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.0653Test Accuracy after Epoch 244: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0571 - val_accuracy: 0.6375 - val_loss: 1.8438\n",
      "Epoch 245/250\n",
      "\u001b[1m16/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0540 Test Accuracy after Epoch 245: 59.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0553 - val_accuracy: 0.6375 - val_loss: 1.8773\n",
      "Epoch 246/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.0399Test Accuracy after Epoch 246: 59.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.0708 - val_accuracy: 0.6625 - val_loss: 1.9749\n",
      "Epoch 247/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9375 - loss: 0.0886Test Accuracy after Epoch 247: 57.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0643 - val_accuracy: 0.6250 - val_loss: 1.8317\n",
      "Epoch 248/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0078Test Accuracy after Epoch 248: 56.00%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9760 - loss: 0.0777 - val_accuracy: 0.6375 - val_loss: 1.9207\n",
      "Epoch 249/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9688 - loss: 0.1506Test Accuracy after Epoch 249: 60.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0833 - val_accuracy: 0.5875 - val_loss: 2.1938\n",
      "Epoch 250/250\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8750 - loss: 0.2894Test Accuracy after Epoch 250: 55.50%\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1208 - val_accuracy: 0.6375 - val_loss: 1.6633\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming x_train_sc has shape (number_of_samples, number_of_features)\n",
    "# Make sure to replace 'number_of_features' with the actual number of features in your data.\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=128, input_dim=x_train_sc.shape[1], activation='tanh'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(units=len(y_train.unique()), activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Print the model summary\n",
    "# model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# Custom callback for logging test accuracy at each epoch\n",
    "class TestAccuracyLogger(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        super().__init__()\n",
    "        self.test_data = test_data\n",
    "        self.test_accuracies = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        _, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        self.test_accuracies.append(test_accuracy)\n",
    "        print(f'Test Accuracy after Epoch {epoch + 1}: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Assuming x_test_sc and y_test are your test data and labels\n",
    "# Also, replace 'num_classes' with the actual number of classes in your classification task.\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "test_accuracy_logger = TestAccuracyLogger(test_data=(x_test_sc, y_test_encoded))\n",
    "\n",
    "# Fit the model with the custom callback\n",
    "history = model.fit(x_train_sc, y_encoded, epochs=250, batch_size=32, validation_split=0.1, callbacks=[test_accuracy_logger])\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(test_accuracy_logger.test_accuracies, label='Test Accuracy', linestyle='dashed')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # Fit the model\n",
    "# # print(x_train_sc)\n",
    "# model.fit(x_train_sc, y_encoded, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# # # Evaluate the model on the test set\n",
    "# test_loss, test_accuracy = model.evaluate(x_test_sc, y_test_encoded)\n",
    "# print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae478df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "print(x_train_sc.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 568973,
     "sourceId": 1032238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 319.866664,
   "end_time": "2024-01-11T05:50:17.106287",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-11T05:44:57.239623",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
