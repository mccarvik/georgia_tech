{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbcb0642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:01.238455Z",
     "iopub.status.busy": "2024-01-11T05:45:01.237988Z",
     "iopub.status.idle": "2024-01-11T05:45:22.452939Z",
     "shell.execute_reply": "2024-01-11T05:45:22.451641Z"
    },
    "papermill": {
     "duration": 21.228331,
     "end_time": "2024-01-11T05:45:22.456076",
     "exception": false,
     "start_time": "2024-01-11T05:45:01.227745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 1 - music genre classification\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import pdb\n",
    "sys.path.append(\"C:\\\\users\\\\mccar\\\\miniconda3\\\\lib\\\\site-packages\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import validation_curve, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from utils import learn_curve, val_curve\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1deffdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:22.476225Z",
     "iopub.status.busy": "2024-01-11T05:45:22.475656Z",
     "iopub.status.idle": "2024-01-11T05:45:23.739387Z",
     "shell.execute_reply": "2024-01-11T05:45:23.736447Z"
    },
    "papermill": {
     "duration": 1.277192,
     "end_time": "2024-01-11T05:45:23.742359",
     "exception": false,
     "start_time": "2024-01-11T05:45:22.465167",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features_30_sec.csv']\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "file_path = \"data/gtzan_music_genre/\"\n",
    "print(os.listdir(f'{file_path}/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3bcf8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:23.769832Z",
     "iopub.status.busy": "2024-01-11T05:45:23.769185Z",
     "iopub.status.idle": "2024-01-11T05:45:38.438753Z",
     "shell.execute_reply": "2024-01-11T05:45:38.437541Z"
    },
    "papermill": {
     "duration": 14.686168,
     "end_time": "2024-01-11T05:45:38.441264",
     "exception": false,
     "start_time": "2024-01-11T05:45:23.755096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sound, sample_rate = librosa.load(f'{file_path}/genres_original/classical/classical.00005.wav')\n",
    "# print(sound[:5])\n",
    "# print(sample_rate)\n",
    "\n",
    "# plt.figure(figsize=(16, 6))\n",
    "# librosa.display.waveshow(y=sound, sr=sample_rate, color=\"darkred\")\n",
    "# plt.title(\"Waveform of classical.00005.wav\", fontsize=12)  \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aed6c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:38.472531Z",
     "iopub.status.busy": "2024-01-11T05:45:38.471893Z",
     "iopub.status.idle": "2024-01-11T05:45:39.554517Z",
     "shell.execute_reply": "2024-01-11T05:45:39.553259Z"
    },
    "papermill": {
     "duration": 1.10268,
     "end_time": "2024-01-11T05:45:39.557909",
     "exception": false,
     "start_time": "2024-01-11T05:45:38.455229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sound_rock, sample_rate_rock = librosa.load(f'{file_path}/genres_original/rock/rock.00017.wav')\n",
    "# print(sound_rock[:5])\n",
    "# print(sample_rate_rock)\n",
    "\n",
    "# plt.figure(figsize = (16,6))\n",
    "# librosa.display.waveshow(y = sound_rock, sr = sample_rate_rock, color = 'darkred')\n",
    "# plt.title('Wavefrom of rock.00017.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b1b9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.592249Z",
     "iopub.status.busy": "2024-01-11T05:45:39.591810Z",
     "iopub.status.idle": "2024-01-11T05:45:39.657703Z",
     "shell.execute_reply": "2024-01-11T05:45:39.655729Z"
    },
    "papermill": {
     "duration": 0.086344,
     "end_time": "2024-01-11T05:45:39.660995",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.574651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_fft = 2048 # FFT window size\n",
    "# hop_length = 512 # number audio of frames between STFT columns (looks like a good default)\n",
    "\n",
    "# # Short-time Fourier transform (STFT)\n",
    "# D = np.abs(librosa.stft(sound_rock, n_fft = n_fft, hop_length = hop_length))\n",
    "\n",
    "# print('Shape of D object:', np.shape(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e617f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.695494Z",
     "iopub.status.busy": "2024-01-11T05:45:39.695066Z",
     "iopub.status.idle": "2024-01-11T05:45:39.796498Z",
     "shell.execute_reply": "2024-01-11T05:45:39.795102Z"
    },
    "papermill": {
     "duration": 0.121206,
     "end_time": "2024-01-11T05:45:39.799409",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.678203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 60)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 60 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   filename                 1000 non-null   object \n",
      " 1   length                   1000 non-null   int64  \n",
      " 2   chroma_stft_mean         1000 non-null   float64\n",
      " 3   chroma_stft_var          1000 non-null   float64\n",
      " 4   rms_mean                 1000 non-null   float64\n",
      " 5   rms_var                  1000 non-null   float64\n",
      " 6   spectral_centroid_mean   1000 non-null   float64\n",
      " 7   spectral_centroid_var    1000 non-null   float64\n",
      " 8   spectral_bandwidth_mean  1000 non-null   float64\n",
      " 9   spectral_bandwidth_var   1000 non-null   float64\n",
      " 10  rolloff_mean             1000 non-null   float64\n",
      " 11  rolloff_var              1000 non-null   float64\n",
      " 12  zero_crossing_rate_mean  1000 non-null   float64\n",
      " 13  zero_crossing_rate_var   1000 non-null   float64\n",
      " 14  harmony_mean             1000 non-null   float64\n",
      " 15  harmony_var              1000 non-null   float64\n",
      " 16  perceptr_mean            1000 non-null   float64\n",
      " 17  perceptr_var             1000 non-null   float64\n",
      " 18  tempo                    1000 non-null   float64\n",
      " 19  mfcc1_mean               1000 non-null   float64\n",
      " 20  mfcc1_var                1000 non-null   float64\n",
      " 21  mfcc2_mean               1000 non-null   float64\n",
      " 22  mfcc2_var                1000 non-null   float64\n",
      " 23  mfcc3_mean               1000 non-null   float64\n",
      " 24  mfcc3_var                1000 non-null   float64\n",
      " 25  mfcc4_mean               1000 non-null   float64\n",
      " 26  mfcc4_var                1000 non-null   float64\n",
      " 27  mfcc5_mean               1000 non-null   float64\n",
      " 28  mfcc5_var                1000 non-null   float64\n",
      " 29  mfcc6_mean               1000 non-null   float64\n",
      " 30  mfcc6_var                1000 non-null   float64\n",
      " 31  mfcc7_mean               1000 non-null   float64\n",
      " 32  mfcc7_var                1000 non-null   float64\n",
      " 33  mfcc8_mean               1000 non-null   float64\n",
      " 34  mfcc8_var                1000 non-null   float64\n",
      " 35  mfcc9_mean               1000 non-null   float64\n",
      " 36  mfcc9_var                1000 non-null   float64\n",
      " 37  mfcc10_mean              1000 non-null   float64\n",
      " 38  mfcc10_var               1000 non-null   float64\n",
      " 39  mfcc11_mean              1000 non-null   float64\n",
      " 40  mfcc11_var               1000 non-null   float64\n",
      " 41  mfcc12_mean              1000 non-null   float64\n",
      " 42  mfcc12_var               1000 non-null   float64\n",
      " 43  mfcc13_mean              1000 non-null   float64\n",
      " 44  mfcc13_var               1000 non-null   float64\n",
      " 45  mfcc14_mean              1000 non-null   float64\n",
      " 46  mfcc14_var               1000 non-null   float64\n",
      " 47  mfcc15_mean              1000 non-null   float64\n",
      " 48  mfcc15_var               1000 non-null   float64\n",
      " 49  mfcc16_mean              1000 non-null   float64\n",
      " 50  mfcc16_var               1000 non-null   float64\n",
      " 51  mfcc17_mean              1000 non-null   float64\n",
      " 52  mfcc17_var               1000 non-null   float64\n",
      " 53  mfcc18_mean              1000 non-null   float64\n",
      " 54  mfcc18_var               1000 non-null   float64\n",
      " 55  mfcc19_mean              1000 non-null   float64\n",
      " 56  mfcc19_var               1000 non-null   float64\n",
      " 57  mfcc20_mean              1000 non-null   float64\n",
      " 58  mfcc20_var               1000 non-null   float64\n",
      " 59  label                    1000 non-null   object \n",
      "dtypes: float64(57), int64(1), object(2)\n",
      "memory usage: 468.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('display.max_columns', 60)\n",
    "train_df = pd.read_csv(f'{file_path}/features_30_sec.csv')\n",
    "train_df.head()\n",
    "print(train_df.shape)\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ebfd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:39.833663Z",
     "iopub.status.busy": "2024-01-11T05:45:39.832566Z",
     "iopub.status.idle": "2024-01-11T05:45:40.641774Z",
     "shell.execute_reply": "2024-01-11T05:45:40.640665Z"
    },
    "papermill": {
     "duration": 0.829401,
     "end_time": "2024-01-11T05:45:40.644815",
     "exception": false,
     "start_time": "2024-01-11T05:45:39.815414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# label_tempo_df= train_df[['label', 'tempo']]\n",
    "\n",
    "# f, ax = plt.subplots(figsize = (16,9))\n",
    "# sns.boxplot(x = 'label', y = 'tempo', data = label_tempo_df, palette = 'rocket' )\n",
    "\n",
    "# plt.title('BPM Boxplot for Genres', fontsize = 15)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.xlabel('Genre', fontsize = 20)\n",
    "# plt.ylabel('BPM', fontsize = 20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7497a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "train_df = train_df.drop(['filename', 'length'], axis = 1)\n",
    "y = train_df['label']\n",
    "X = train_df.drop('label', axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82a823f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:40.680821Z",
     "iopub.status.busy": "2024-01-11T05:45:40.680116Z",
     "iopub.status.idle": "2024-01-11T05:45:41.294675Z",
     "shell.execute_reply": "2024-01-11T05:45:41.292817Z"
    },
    "papermill": {
     "duration": 0.640956,
     "end_time": "2024-01-11T05:45:41.302621",
     "exception": false,
     "start_time": "2024-01-11T05:45:40.661665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cols = X.columns\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# np_scaled = min_max_scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(np_scaled, columns = cols)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components = 2)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "# finalDf = pd.concat([principalDf, y], axis = 1)\n",
    "# print('variance ratio : ', pca.explained_variance_ratio_)\n",
    "# print('sum : ', sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "341d4d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:41.411559Z",
     "iopub.status.busy": "2024-01-11T05:45:41.411130Z",
     "iopub.status.idle": "2024-01-11T05:45:41.744452Z",
     "shell.execute_reply": "2024-01-11T05:45:41.743084Z"
    },
    "papermill": {
     "duration": 0.382564,
     "end_time": "2024-01-11T05:45:41.747565",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.365001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pca = PCA(whiten = True).fit(X)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d078f89",
   "metadata": {
    "papermill": {
     "duration": 0.016425,
     "end_time": "2024-01-11T05:45:41.780771",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.764346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1efdb122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:41.816931Z",
     "iopub.status.busy": "2024-01-11T05:45:41.815973Z",
     "iopub.status.idle": "2024-01-11T05:45:42.199666Z",
     "shell.execute_reply": "2024-01-11T05:45:42.198158Z"
    },
    "papermill": {
     "duration": 0.405254,
     "end_time": "2024-01-11T05:45:42.202781",
     "exception": false,
     "start_time": "2024-01-11T05:45:41.797527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e63aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:42.240883Z",
     "iopub.status.busy": "2024-01-11T05:45:42.240160Z",
     "iopub.status.idle": "2024-01-11T05:45:42.716199Z",
     "shell.execute_reply": "2024-01-11T05:45:42.715014Z"
    },
    "papermill": {
     "duration": 0.498045,
     "end_time": "2024-01-11T05:45:42.718870",
     "exception": false,
     "start_time": "2024-01-11T05:45:42.220825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba895e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T05:45:42.756639Z",
     "iopub.status.busy": "2024-01-11T05:45:42.756172Z",
     "iopub.status.idle": "2024-01-11T05:45:42.776635Z",
     "shell.execute_reply": "2024-01-11T05:45:42.775324Z"
    },
    "papermill": {
     "duration": 0.042967,
     "end_time": "2024-01-11T05:45:42.779761",
     "exception": false,
     "start_time": "2024-01-11T05:45:42.736794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# More preprocessing\n",
    "scale = MinMaxScaler()\n",
    "scaled_data = scale.fit_transform(x_train)\n",
    "x_train_sc = pd.DataFrame(scaled_data, columns = x_train.columns).values\n",
    "scaled_data = scale.fit_transform(x_test)\n",
    "x_test_sc = pd.DataFrame(scaled_data, columns = x_test.columns).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e16493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "# Curve based on value of K - Validation curve\n",
    "val_knn = False\n",
    "if val_knn:\n",
    "    k_accs = {}\n",
    "    for k_val in range(1,24):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "        knn.fit(x_train_sc, y_train)\n",
    "        y_pred = knn.predict(x_test_sc)\n",
    "        k_accs[k_val] = accuracy_score(y_test, y_pred)\n",
    "        print(\"K val: {}   acc: {}\".format(k_val, k_accs[k_val]))\n",
    "    val_curve(list(k_accs.keys()), list(k_accs.values()), \"knn_music\", \"value for K\")\n",
    "\n",
    "learn_knn = False\n",
    "if learn_knn:\n",
    "    # Shuffle the data without replacement - Learning curve\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        # shuffled_data = shuffle(x_train, random_state=RANDOM_SEED)\n",
    "        x_percent_index = int(x_perc * len(x_train_sc))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "        knn = KNeighborsClassifier(n_neighbors=7)\n",
    "        knn.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = knn.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = knn.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"K val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"knn_music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9404c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - hyperparameter tuning - Validation curve\n",
    "dt_max_depth = False\n",
    "\n",
    "if dt_max_depth:\n",
    "    # Max Depth\n",
    "    # Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "    param_range = np.arange(1, 31)\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train, y_train, param_name=\"max_depth\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Max Depth\")\n",
    "    plt.xlabel(\"Max Depth\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_max_depth_music.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "058beef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min samples to split\n",
    "# Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "dt_min_split = False\n",
    "\n",
    "if dt_min_split:\n",
    "    param_range = np.arange(0, 15)\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train_sc, y_train, param_name=\"min_samples_split\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    print(test_scores_mean)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Min Samples Split\")\n",
    "    plt.xlabel(\"Min Samples Split\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_min_samples_split_music.png\", dpi=300)\n",
    "    # plt.savefig(\"pngs/validation_curve_dt_min_samples_leaf.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c30b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion\n",
    "crit = False\n",
    "\n",
    "if crit:\n",
    "    # Define the range of values for the hyperparameter (e.g., max_depth)\n",
    "    param_range = ['gini', 'entropy']\n",
    "\n",
    "    # Create a decision tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=13)\n",
    "\n",
    "    # Generate training and test scores using validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        dt_classifier, x_train, y_train, param_name=\"criterion\", param_range=param_range,\n",
    "        cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    print(test_scores_mean)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Decision Tree - Criterion\")\n",
    "    plt.xlabel(\"Criterion\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    # Plot the mean training scores\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # Fill the area around the mean training scores\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.xticks(['gini', 'entropy'])\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_dt_criterion_music.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "493883e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - Amount of data - Learning curve\n",
    "l_curve = False\n",
    "\n",
    "if l_curve:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        print(x_perc)\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "        dec_tree = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "        dec_tree.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = dec_tree.predict(x_test)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = dec_tree.predict(x_train)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"dec_tree_music\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1bdcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT - epochs - Learning curve\n",
    "dt_epoch = False\n",
    "\n",
    "if dt_epoch:\n",
    "    # Number of epochs\n",
    "    epochs = 5\n",
    "\n",
    "    # Initialize the decision tree classifier\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    # Loop through epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "\n",
    "        # Train the decision tree on the training set\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        x_accs[epoch+1] = accuracy_score(y_test, y_pred)\n",
    "        y_pred_train = dec_tree.predict(x_train)\n",
    "        train_accs[epoch+1] = accuracy_score(y_train, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(epoch+1, x_accs[epoch+1]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"dec_tree_epochs_music\", x_axis=\"Epochs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f82d2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Tree - Hyperparameter tuning - Validation curve\n",
    "boost_gscv = False\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "if boost_gscv:\n",
    "    # Create XGBoost classifier\n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    # Define hyperparameters to tune\n",
    "    param_grid = {\n",
    "        'n_estimators': [15, 50, 150, 200, 250],\n",
    "        'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "        'min_child_weight': [1, 5, 10, 15],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200],\n",
    "        'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "        'min_child_weight': [1, 5, 10, 15],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_classifier,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search.fit(x_train_sc, y_encoded)\n",
    "\n",
    "    # Display the best hyperparameters and corresponding accuracy\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    print(grid_search.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02457455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting tree - Validation curve - max depth\n",
    "bt_md = False\n",
    "\n",
    "if bt_md:\n",
    "    xgb_classifier = XGBClassifier(learning_rate=0.3, min_child_weight=1, max_depth = 7, subsample=0.9, colsample_bytree=1.0)\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": [10, 50, 100, 150, 200, 250]\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_classifier,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search.fit(x_train_sc, y_encoded)\n",
    "\n",
    "    # Display the best hyperparameters and corresponding accuracy\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    param_range = [10, 50, 100, 150, 200, 250]\n",
    "\n",
    "    # Calculate mean and standard deviation for training and test scores\n",
    "    # train_scores_mean = grid_search.cv_results_['mean_train_score']\n",
    "    # train_scores_std = grid_search.cv_results_['std_train_score']\n",
    "    test_scores_mean = grid_search.cv_results_['mean_test_score']\n",
    "    test_scores_std = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Validation Curve for Boosting Tree - N Estimators\")\n",
    "    plt.xlabel(\"N Estimators\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # Plot the mean training scores\n",
    "    # plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", marker='o')\n",
    "    # # Fill the area around the mean training scores\n",
    "    # plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "    #                 train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\")\n",
    "    # Plot the mean test scores\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", marker='o')\n",
    "    # Fill the area around the mean test scores\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"pngs/validation_curve_bt_n_estimators_music.png\", dpi=300)\n",
    "    # plt.savefig(\"pngs/validation_curve_dt_min_samples_leaf.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b710809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BT - Learning Curve - amount of data\n",
    "bt_lc = False\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "if bt_lc:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_encoded[:x_percent_index]\n",
    "        xgb_classifier = XGBClassifier(n_estimators=200, learning_rate=0.3, max_depth=7,\n",
    "                                       min_child_weight=1, subsample=0.9, colsample_bytree=1.0)\n",
    "        xgb_classifier.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = xgb_classifier.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test_encoded, y_pred)\n",
    "        y_pred_train = xgb_classifier.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_encoded, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"boost_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bf6b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Validation curve - C / kernel func\n",
    "hyper = False\n",
    "\n",
    "\n",
    "if hyper:\n",
    "    # Run through the kernel functions and get validation curves for each hyperparameter\n",
    "    for kern_func in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "\n",
    "        x_perc = 1.0\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_train[:x_percent_index]\n",
    "\n",
    "        # Define the hyperparameter values to be tested\n",
    "        param_range = np.logspace(-2, 6, 9)\n",
    "        svm_model = SVC(kernel=kern_func)\n",
    "\n",
    "        # Create a validation curve\n",
    "        train_scores, test_scores = validation_curve(\n",
    "            svm_model, first_x_percent, y_train_iter, param_name=\"C\", param_range=param_range,\n",
    "            cv=3, scoring=\"accuracy\", n_jobs=-1\n",
    "        )\n",
    "        # Plot the validation curves\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Validation Curve for SVM - {}\".format(kern_func))\n",
    "        plt.xlabel(\"C Parameter\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=2)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\", lw=2)\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.savefig(\"pngs/validation_curve_svm_{}_music.png\".format(kern_func), dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0542d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Learning Curve - amount of data\n",
    "svm_lc = False\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "if svm_lc:\n",
    "    x_accs = {}\n",
    "    train_accs = {}\n",
    "    for x_perc in range(1,11):\n",
    "        x_perc = x_perc / 10\n",
    "        x_percent_index = int(x_perc * len(x_train))\n",
    "        # Take the first X% of the shuffled data\n",
    "        first_x_percent = x_train_sc[:x_percent_index]\n",
    "        y_train_iter = y_encoded[:x_percent_index]\n",
    "        svm_model = SVC(kernel=\"rbf\", C=100)\n",
    "        svm_model.fit(first_x_percent, y_train_iter)\n",
    "        y_pred = svm_model.predict(x_test_sc)\n",
    "        x_accs[x_perc*10] = accuracy_score(y_test_encoded, y_pred)\n",
    "        y_pred_train = svm_model.predict(x_train_sc)\n",
    "        train_accs[x_perc*10] = accuracy_score(y_encoded, y_pred_train)\n",
    "        print(\"Perc val: {}   acc: {}\".format(int(x_perc*10), x_accs[x_perc*10]))\n",
    "    learn_curve(list(x_accs.keys()), list(train_accs.values()), list(x_accs.values()), \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f82e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x2120c477b90 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 391, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\__init__.py\", line 21, in <module>\n",
      "    from keras import models\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\models\\__init__.py\", line 18, in <module>\n",
      "    from keras.engine.functional import Functional\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 27, in <module>\n",
      "    from keras.dtensor import layout_map as layout_map_lib\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\dtensor\\layout_map.py\", line 27, in <module>\n",
      "    from keras.engine import base_layer\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 33, in <module>\n",
      "    from keras import initializers\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\initializers\\__init__.py\", line 23, in <module>\n",
      "    from keras.saving.legacy import serialization as legacy_serialization\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py\", line 22, in <module>\n",
      "    from keras.utils import tf_contextlib\n",
      "  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 20, in <module>\n",
      "    from keras.saving.legacy.serialization import deserialize_keras_object\n",
      "ImportError: cannot import name 'deserialize_keras_object' from partially initialized module 'keras.saving.legacy.serialization' (most likely due to a circular import) (C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py)\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 26, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 385, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 834, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 556, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 176, in submit\n",
      "    return super().submit(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1129, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\mccar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 391, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\__init__.py\", line 21, in <module>\n    from keras import models\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\models\\__init__.py\", line 18, in <module>\n    from keras.engine.functional import Functional\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 27, in <module>\n    from keras.dtensor import layout_map as layout_map_lib\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\dtensor\\layout_map.py\", line 27, in <module>\n    from keras.engine import base_layer\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 33, in <module>\n    from keras import initializers\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\initializers\\__init__.py\", line 23, in <module>\n    from keras.saving.legacy import serialization as legacy_serialization\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py\", line 22, in <module>\n    from keras.utils import tf_contextlib\n  File \"C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 20, in <module>\n    from keras.saving.legacy.serialization import deserialize_keras_object\nImportError: cannot import name 'deserialize_keras_object' from partially initialized module 'keras.saving.legacy.serialization' (most likely due to a circular import) (C:\\users\\mccar\\miniconda3\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mkeras_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (grid_result\u001b[38;5;241m.\u001b[39mbest_score_, grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\_base.py:26\u001b[0m, in \u001b[0;36mFuture._invoke_callbacks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done_callbacks:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception calling callback for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:385\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.__call__\u001b[1;34m(self, out)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:834\u001b[0m, in \u001b[0;36mParallel.dispatch_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdispatch_next\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    827\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Dispatch more data for parallel processing\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \n\u001b[0;32m    829\u001b[0m \u001b[38;5;124;03m    This method is meant to be called concurrently by the multiprocessing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m \n\u001b[0;32m    833\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_original_iterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:556\u001b[0m, in \u001b[0;36mLokyBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    555\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSafeFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m     future\u001b[38;5;241m.\u001b[39mget \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_future_result, future)\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:176\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock:\n\u001b[1;32m--> 176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1129\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mshutdown_lock:\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mbroken \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mbroken\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mshutdown:\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ShutdownExecutorError(\n\u001b[0;32m   1132\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "# Define a function to create the Keras model\n",
    "def create_model(optimizer='adam', activation='relu', neurons=16):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=4, activation=activation))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap Keras model into a function for compatibility with GridSearchCV\n",
    "keras_model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'neurons': [8, 16, 32]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=3, \n",
    "                    scoring='accuracy', verbose=9, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_result = grid.fit(x_train_sc, y_train, callbacks=[EarlyStopping(monitor='val_loss', patience=2)])\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Evaluate the model on the test set with the best hyperparameters\n",
    "best_model = grid_result.best_estimator_\n",
    "test_accuracy = best_model.score(x_test_sc, y_test)\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 568973,
     "sourceId": 1032238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 319.866664,
   "end_time": "2024-01-11T05:50:17.106287",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-11T05:44:57.239623",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
