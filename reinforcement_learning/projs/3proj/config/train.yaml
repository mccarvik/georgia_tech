defaults:
    - agent: maddpg

# Experiment Settings
# env: cramped_room
# env: asymmetric_advantages
env: forced_coordination
episode_length: 400
discrete_action_space: true

experiment: vanilla
seed: 0
num_seed_steps: 10000
# num_seed_steps: 100

# num_train_steps: 1000
num_train_steps: 4000000
replay_buffer_capacity: 40000

eval_frequency: 12000
num_eval_episodes: 1

common_reward: true

ou_exploration_steps: ${num_train_steps}
ou_init_scale: 0.3
ou_final_scale: 0

device: cpu

# Logging Settings
log_frequency: 100
log_save_tb: true
save_video: true
render: false

# Save Buffer
save_model: true
save_replay_buffer: false

# hydra configuration
hydra:
    run:
        dir: ./experiment/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}_${env}